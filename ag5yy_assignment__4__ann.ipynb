{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ag5yy_assignment _4 _ann.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-40VPC7MAGGB"
      },
      "source": [
        "# Assignment 4: Benchmarking Neural Nets with the XOR Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piFzh10hAGGE"
      },
      "source": [
        "### CS 4774 Machine Learning - Department of Computer Science - University of Virginia\n",
        "In this assignment, you will implement your own neural networks to classify non-linear data from the XOR dataset. For references, you may refer to my [lecture 13](https://docs.google.com/presentation/d/1otQfmMomWctLZKI3hHKAA4lLkbXFtagLaQov8gNh4LI/edit?usp=sharing) and [Colab Notebook 10](https://colab.research.google.com/drive/1x5biI3dP5YvvDEI0wapJcSgQNnATDzNe) if you need additional sample codes to help with your assignment. For deliverables, you must write code in Python/Tensorflow and submit **this** Jupyter Notebook file (.ipynb) to earn a total of 100 pts. Note that you must save your Notebook filename under this format: **yourUvaUserId_assignment_4_ann.ipynb**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "469YvvIzAGGJ"
      },
      "source": [
        "# You might want to use the following packages\n",
        "import sklearn\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-PtpH4xAGGG"
      },
      "source": [
        "---\n",
        "## 1. THE DATASET AND VISUALIZATION\n",
        "\n",
        "We will use the non-linear toy data called the XOR dataset. You may use the code snippet below to generate the train/validate/test set. Feel free to change the number of samples, and noise level. To keep the ratio between the sets consistent, please do not change the test_size and random_state parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6To8trtr3sLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "253f67dc-fb97-43f2-e383-a5b589bd29ee"
      },
      "source": [
        "def make_xor(n_points):\n",
        "    centers = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "    labels = np.array([0,1,1,0])\n",
        "    data = np.array([]).reshape(-1,3)\n",
        "    for center, label in zip(centers,labels):\n",
        "        points = np.random.normal(loc=center,scale=0.2,size=(n_points//4,2))\n",
        "        points_labels = np.hstack((points,label*np.ones(n_points//4).reshape((-1, 1))))\n",
        "        data = np.vstack((data,points_labels))\n",
        "    return (data[:,[0,1]],data[:,2])\n",
        "\n",
        "\n",
        "X, y = make_xor(1000)\n",
        "y=y.astype(np.int64)\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=49)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size= 0.1, random_state=49) \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 2)\n",
            "(200, 2)\n",
            "(80, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f36b6f06510>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikrzbrHG6Uj4"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uUeN8qXQPEO"
      },
      "source": [
        "\n",
        "---\n",
        "## 2. TRAIN A SIMPLE ANN FOR CLASSIFICATION TASK\n",
        "\n",
        "Use the standard libarary of Neural Net on the training data, and then test the classifier on the test data. You will create a simple ANN with 3 layers: an Input Layer, a Hidden Layer and an Output Layer. For each layer, you can specify the number of nodes appropriate for the XOR problem. Also, feel free to tune the network as you see fit. You have to report the accuracy of the network on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GopK02xaQXoH"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "my_model = keras.Sequential()\n",
        "# Your code here!\n",
        "my_model.add(keras.layers.Dense(2, activation=\"relu\", input_dim=2))\n",
        "my_model.add(keras.layers.Dense(180, activation=\"relu\"))\n",
        "my_model.add(keras.layers.Dense(2, activation=\"softmax\"))\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyasxepzKuMD"
      },
      "source": [
        "my_model.compile(loss=\"sparse_categorical_crossentropy\" ,\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHZ6DVD-Kygg",
        "outputId": "7745db4c-f022-4732-8ea1-7a5d9f4b482e"
      },
      "source": [
        "history = my_model.fit(X_train, y_train, batch_size=64, epochs=100,\n",
        "                    validation_data=(X_val, y_val))\n",
        "history"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 0.6883 - accuracy: 0.6639 - val_loss: 0.6852 - val_accuracy: 0.6625\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6972 - val_loss: 0.6766 - val_accuracy: 0.7125\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7028 - val_loss: 0.6696 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6972 - val_loss: 0.6631 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.6889 - val_loss: 0.6575 - val_accuracy: 0.7125\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.6875 - val_loss: 0.6510 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6764 - val_loss: 0.6455 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6722 - val_loss: 0.6418 - val_accuracy: 0.7250\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6833 - val_loss: 0.6367 - val_accuracy: 0.7250\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6847 - val_loss: 0.6308 - val_accuracy: 0.7125\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6792 - val_loss: 0.6261 - val_accuracy: 0.7125\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6806 - val_loss: 0.6226 - val_accuracy: 0.7125\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6833 - val_loss: 0.6185 - val_accuracy: 0.7125\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6847 - val_loss: 0.6141 - val_accuracy: 0.7125\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6847 - val_loss: 0.6111 - val_accuracy: 0.7125\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6889 - val_loss: 0.6069 - val_accuracy: 0.7125\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6903 - val_loss: 0.6022 - val_accuracy: 0.7125\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.6875 - val_loss: 0.5990 - val_accuracy: 0.7125\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6903 - val_loss: 0.5969 - val_accuracy: 0.7125\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.6889 - val_loss: 0.5942 - val_accuracy: 0.7125\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6903 - val_loss: 0.5908 - val_accuracy: 0.7125\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.6903 - val_loss: 0.5876 - val_accuracy: 0.7125\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6917 - val_loss: 0.5841 - val_accuracy: 0.7125\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6903 - val_loss: 0.5807 - val_accuracy: 0.7125\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5977 - accuracy: 0.6903 - val_loss: 0.5776 - val_accuracy: 0.7125\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6944 - val_loss: 0.5742 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6944 - val_loss: 0.5722 - val_accuracy: 0.7125\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.6958 - val_loss: 0.5696 - val_accuracy: 0.7125\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6944 - val_loss: 0.5673 - val_accuracy: 0.7125\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.6972 - val_loss: 0.5658 - val_accuracy: 0.7125\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6972 - val_loss: 0.5631 - val_accuracy: 0.7125\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.6972 - val_loss: 0.5603 - val_accuracy: 0.7125\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.6972 - val_loss: 0.5582 - val_accuracy: 0.7125\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.6972 - val_loss: 0.5567 - val_accuracy: 0.7125\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7000 - val_loss: 0.5541 - val_accuracy: 0.7125\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7000 - val_loss: 0.5514 - val_accuracy: 0.7125\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7000 - val_loss: 0.5492 - val_accuracy: 0.7125\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7000 - val_loss: 0.5470 - val_accuracy: 0.7125\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7000 - val_loss: 0.5445 - val_accuracy: 0.7125\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7000 - val_loss: 0.5422 - val_accuracy: 0.7125\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7014 - val_loss: 0.5396 - val_accuracy: 0.7125\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7014 - val_loss: 0.5378 - val_accuracy: 0.7125\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7014 - val_loss: 0.5367 - val_accuracy: 0.7125\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7028 - val_loss: 0.5342 - val_accuracy: 0.7125\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7042 - val_loss: 0.5324 - val_accuracy: 0.7125\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7069 - val_loss: 0.5290 - val_accuracy: 0.7125\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7014 - val_loss: 0.5258 - val_accuracy: 0.7125\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7028 - val_loss: 0.5238 - val_accuracy: 0.7125\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7042 - val_loss: 0.5212 - val_accuracy: 0.7125\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7056 - val_loss: 0.5192 - val_accuracy: 0.7125\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7056 - val_loss: 0.5184 - val_accuracy: 0.7125\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7069 - val_loss: 0.5159 - val_accuracy: 0.7125\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7069 - val_loss: 0.5140 - val_accuracy: 0.7125\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7111 - val_loss: 0.5117 - val_accuracy: 0.7125\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7083 - val_loss: 0.5106 - val_accuracy: 0.7125\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7139 - val_loss: 0.5080 - val_accuracy: 0.7125\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7125 - val_loss: 0.5070 - val_accuracy: 0.7125\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7153 - val_loss: 0.5051 - val_accuracy: 0.7125\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7153 - val_loss: 0.5026 - val_accuracy: 0.7125\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7153 - val_loss: 0.5011 - val_accuracy: 0.7125\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7153 - val_loss: 0.4989 - val_accuracy: 0.7125\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7153 - val_loss: 0.4982 - val_accuracy: 0.7125\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7139 - val_loss: 0.4959 - val_accuracy: 0.7125\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7153 - val_loss: 0.4937 - val_accuracy: 0.7125\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7153 - val_loss: 0.4908 - val_accuracy: 0.7125\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5094 - accuracy: 0.7153 - val_loss: 0.4897 - val_accuracy: 0.7125\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7153 - val_loss: 0.4889 - val_accuracy: 0.7250\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7167 - val_loss: 0.4866 - val_accuracy: 0.7125\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7153 - val_loss: 0.4844 - val_accuracy: 0.7125\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7153 - val_loss: 0.4822 - val_accuracy: 0.7125\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7167 - val_loss: 0.4804 - val_accuracy: 0.7125\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7153 - val_loss: 0.4791 - val_accuracy: 0.7250\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7153 - val_loss: 0.4780 - val_accuracy: 0.7250\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7181 - val_loss: 0.4749 - val_accuracy: 0.7250\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7167 - val_loss: 0.4730 - val_accuracy: 0.7250\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7181 - val_loss: 0.4717 - val_accuracy: 0.7250\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7167 - val_loss: 0.4690 - val_accuracy: 0.7250\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.4668 - val_accuracy: 0.7250\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7181 - val_loss: 0.4650 - val_accuracy: 0.7250\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7167 - val_loss: 0.4624 - val_accuracy: 0.7250\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7181 - val_loss: 0.4611 - val_accuracy: 0.7250\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7167 - val_loss: 0.4583 - val_accuracy: 0.7250\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7167 - val_loss: 0.4564 - val_accuracy: 0.7250\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7167 - val_loss: 0.4548 - val_accuracy: 0.7250\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7181 - val_loss: 0.4521 - val_accuracy: 0.7250\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7181 - val_loss: 0.4503 - val_accuracy: 0.7250\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7181 - val_loss: 0.4482 - val_accuracy: 0.7250\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7194 - val_loss: 0.4463 - val_accuracy: 0.7250\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7194 - val_loss: 0.4440 - val_accuracy: 0.7250\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7194 - val_loss: 0.4417 - val_accuracy: 0.7250\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7194 - val_loss: 0.4401 - val_accuracy: 0.7250\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7194 - val_loss: 0.4376 - val_accuracy: 0.7250\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7194 - val_loss: 0.4356 - val_accuracy: 0.7250\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7181 - val_loss: 0.4340 - val_accuracy: 0.7250\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7194 - val_loss: 0.4317 - val_accuracy: 0.7250\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7208 - val_loss: 0.4291 - val_accuracy: 0.7375\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7347 - val_loss: 0.4270 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7431 - val_loss: 0.4252 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7486 - val_loss: 0.4234 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7569 - val_loss: 0.4211 - val_accuracy: 0.7750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36b6ed7dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na4CpxLBAGGP"
      },
      "source": [
        "- - -\n",
        "## 3. IMPLEMENTING YOUR OWN SIMPLE NEURAL NETWORK\n",
        "\n",
        "Now that you see how the standard library ANN performs on the XOR dataset, you will attempt to implement your own version of the neural network. To help you, a template has been created including the backpropagation. Essensially, you will get the backward gradients for free. However, please note that the backprop implementation assume usage of tanh activation for the hidden layer and softmax for the output layer. There are some subtasks which you need to implement in order to get the network to work properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRRstnXAV77G"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class MyNeuralNet(BaseEstimator):\n",
        "    \"\"\"Your implementation of a simple neural network\"\"\"\n",
        "\n",
        "    def __init__ (self, n0, n1, n2, alpha=0.01):\n",
        "        \"\"\"\n",
        "        @param: n0: Number of nodes in the input layer\n",
        "        @param: n1: Number of nodes in the hidden layer\n",
        "        @param: n2: Number of nodes in the output layer\n",
        "        @param: alpha: The Learning Rate\n",
        "        \"\"\"\n",
        "\n",
        "        # SUBTASK 1: Initialize the parameters to random values.\n",
        "        np.random.seed(42)\n",
        "        self.W1 = np.random.rand(n1,n0)\n",
        "        self.b1 = np.random.rand(n1,1)\n",
        "        self.W2 = np.random.rand(n2,n1)\n",
        "        self.b2 = np.random.rand(n2,1)\n",
        "\n",
        "        # Configure the learning rate\n",
        "        self.alpha = alpha\n",
        "        # One-hot encoder for labels \n",
        "        self.encoder = OneHotEncoder(sparse=False)\n",
        "        \n",
        "    def forward_pass(self, X):\n",
        "        \"\"\"\n",
        "        Pass the signal forward through the layers.\n",
        "        @param: X: feature\n",
        "        @return: A1: saved value of the output of the hidden layer\n",
        "        @return: A2: activated return value of the output layer.\n",
        "        \"\"\"\n",
        "        # SUBTASK 2: Implement Forward propagation.\n",
        "        # Note: that you must implement tanh activation for the hiden layer \n",
        "        # and softmax for the output layer\n",
        "        \n",
        "        # print(self.W1.shape)\n",
        "        # print(self.b1.shape)\n",
        "        # print(X.shape)\n",
        "        Z1 = np.dot(self.W1, X) + self.b1\n",
        "        A1 = np.tanh(Z1)\n",
        "        Z2 = np.dot(self.W2, A1) + self.b2\n",
        "        e = np.exp(Z2)\n",
        "        A2 = e/np.sum(e, axis=0)\n",
        "\n",
        "        \n",
        "        return A1, A2 \n",
        "\n",
        "\n",
        "    def loss(self, X, y):\n",
        "        \"\"\"\n",
        "        Evaluate the total loss on the dataset\n",
        "        @param: X: features\n",
        "        @param: y: labels\n",
        "        @return: L: the loss value\n",
        "        \"\"\"\n",
        "        \n",
        "\n",
        "        # SUBTASK 3: Calculate the loss using Cross-Entropy\n",
        "        # You will need to return the average loss on the data\n",
        "        # Hint: Use A2 to calculate the loss\n",
        "        A1, A2 = self.forward_pass(X)  \n",
        "        # Another Hint: First, you may want to convert the lable y into a one-hot vector\n",
        "        Y = self.one_hot(y)\n",
        "        probs = np.multiply(np.log(A2),Y) + np.multiply(np.log(1 - A2),1 - Y)\n",
        "        L = - np.sum(probs) * (1 / (X.shape[0])) #avg loss\n",
        "        return L\n",
        "\n",
        "    def backward_pass(self, A1, A2, X, y):\n",
        "        \"\"\"\n",
        "        @param: X: feature\n",
        "        @param: y: label\n",
        "        @param: A1: saved value of the output of the hidden layer\n",
        "        @param: a2: activated return value of the output layer.\n",
        "\n",
        "        @return: dW1: the loss gradient of W1\n",
        "        @return: db1: the loss gradient of b1\n",
        "        @return: dW2: the loss gradient of W2\n",
        "        @return: db2: the loss gradient of b2\n",
        "        \"\"\"\n",
        "\n",
        "        # You DO NOT CHANGE this function, ...\n",
        "        # unless you are advanced and want to use different activation function for your forward pass\n",
        "        # This is an elegant partial derivative of cross entropy with softmax\n",
        "        # Ref document: https://deepnotes.io/softmax-crossentropy\n",
        "        m   = y.shape[0]\n",
        "        dZ2 = A2 - self.one_hot(y) \n",
        "        dW2 = np.dot(dZ2, A1.T)/m\n",
        "        db2 = np.sum(dZ2, axis=1, keepdims=True)/m\n",
        "        dZ1 = np.multiply( np.dot( self.W2.T, dZ2), 1-np.power( A1, 2))\n",
        "        dW1 = np.dot(dZ1, X.T)/m\n",
        "        db1 = np.sum(dZ1, axis=1, keepdims=True)/m\n",
        "\n",
        "        return dW1, db1, dW2, db2\n",
        "\n",
        "\n",
        "    def fit(self, X, y , epochs, X_val, Y_val):\n",
        "        \"\"\"\n",
        "        Learns parameters for the neural network and returns the model.\n",
        "        \n",
        "        @param: X: the training feature\n",
        "        @param: y: the train label\n",
        "        @param: epochs: Number of passes through the training data for gradient descent\n",
        "        @param: X_val: the feature of validation set\n",
        "        @param: y_val: the label of validation set\n",
        "        \"\"\"\n",
        "\n",
        "        # Input checks: X and X_val needs to be in the form of n0 x m\n",
        "        if (X.shape[0] > X.shape[1]): X = X.T\n",
        "        if (X_val.shape[0] > X_val.shape[1]): X_val = X_val.T\n",
        "\n",
        "        # Gradient descent\n",
        "        for i in range(0, epochs):\n",
        "            \n",
        "            # SUBTASK 4: Compute the forward, backward, and gradient descent parameter update\n",
        "            # Step 1: Forward pass\n",
        "            A1, A2 = self.forward_pass(X)\n",
        "            \n",
        "            # Step 2: Backward pass\n",
        "            dW1, db1, dW2, db2 = self.backward_pass(A1, A2, X, y)\n",
        "\n",
        "            # Step 3: Gradient Descent \n",
        "            self.W1 = self.W1 - (self.alpha * dW1)\n",
        "            self.b1 = self.b1 - (self.alpha * db1)\n",
        "            self.W2 = self.W2 - (self.alpha * dW2)\n",
        "            self.b2 = self.b2 - (self.alpha * db2)\n",
        "\n",
        "            # Print the loss and validation accuracy every 10 epochs.\n",
        "            if i % 10 == 0:\n",
        "                print(\"Epoch %i/%i - loss: %f - accuracy: %f - val_loss: %f - val_accuracy: %f\" \n",
        "                      %(i,epochs, self.loss(X, y), self.evaluate(X, y),\n",
        "                        self.loss(X_val, y_val), self.evaluate(X_val,y_val)))\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict label vector y\n",
        "        \"\"\"\n",
        "        # check X for the form of n0 x m\n",
        "        if (X.shape[0] > X.shape[1]): X = X.T\n",
        "        \n",
        "        # SUBTASK 5: Implement the prediction process. \n",
        "        # Hint: It should include a forward pass, and then use the class with higher probability.\n",
        "        A1, A2 = self.forward_pass(X)\n",
        "\n",
        "        y_hat = []\n",
        "        for i in range(A2.shape[1]):\n",
        "          if(A2[:,i][0]>A2[:,i][1]):\n",
        "            y_hat.append(0)\n",
        "          else:\n",
        "            y_hat.append(1)\n",
        "\n",
        "        return np.array(y_hat)\n",
        "\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"\n",
        "        Evaluate the accuracy of the model\n",
        "        \"\"\"\n",
        "        m = y.shape[0]\n",
        "        y_hat = self.predict(X)\n",
        "        correct_y = (y_hat == y).astype(int)\n",
        "\n",
        "        return sum(correct_y)/m\n",
        "\n",
        "\n",
        "    def one_hot(self, y):\n",
        "        \"\"\"\n",
        "        Utility function: Convert a label vector to one-hot vector\n",
        "        \"\"\"\n",
        "        Y = self.encoder.fit_transform(y.reshape(len(y),1))  \n",
        "        return Y.T # Transpose to get into same shape 1 x m\n",
        "\n",
        "\n",
        "    def plot_decision_boundary(self, X, y):\n",
        "        \"\"\"\n",
        "        Utility Function: Plot a decision boundary for visualization purpose.\n",
        "        If you don't fully understand this function don't worry, it just generates the contour plot below.\n",
        "        \"\"\"\n",
        "        # Set min and max values and give it some padding\n",
        "        x_min, x_max = X[:,0].min() - .5, X[:,0].max() + .5\n",
        "        y_min, y_max = X[:,1].min() - .5, X[:,1].max() + .5\n",
        "        h = 0.01\n",
        "        # Generate a grid of points with distance h between them\n",
        "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "        # Predict the function value for the whole gid\n",
        "        data_grid= np.c_[xx.ravel(), yy.ravel()]\n",
        "        Z = self.predict(data_grid)\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "        # Plot the contour and training examples\n",
        "        plt.contourf(xx, yy, Z, cmap=plt.cm.Pastel1)\n",
        "        plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.Spectral)        "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaZo2uu7Q6zn"
      },
      "source": [
        "---\n",
        "## 4. REFLECT ON THE COMPARISON BETWEEN YOUR IMPLEMENTATION TO THE STANDARD LIBRARY\n",
        "Now that you have implemented your own Neural Net class, let's use it! Create at least 3 instances of your Neural Net class, each with a different number of nodes in the hiden layer, tune it with the appropriate learning rate and number of iteration. You will test their performance in the Xor dataset and report the test accuracy metrics for each instance of your neural network.\n",
        "\n",
        "Based on the test accuracy, compare your models with the standard library version. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEgYtO8-SPqr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc8bae8e-8ce0-43a4-ba8e-bab36a06db1d"
      },
      "source": [
        "# MODEL 1 here - NEURAL NET CLASS\n",
        "n0 = 2# input layer dimensionality\n",
        "n1 = 280# hiden layer dimensionality\n",
        "n2 = 2# output layer dimensionality\n",
        "alpha = .001# learning rate for gradient descent\n",
        "epochs = 570 # number of iteration/epochs\n",
        "\n",
        "# Build a model with 3 layers\n",
        "myModel1 = MyNeuralNet(n0, n1, n2, alpha);\n",
        "myModel1.fit(X_train, y_train, epochs, X_val, y_val)\n",
        "print(\"Accuracy on the test set is \", myModel1.evaluate(X_test, y_test))\n",
        "\n",
        "# Plot the decision boundary\n",
        "myModel1.plot_decision_boundary(X_test, y_test)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/570 - loss: 1921.328966 - accuracy: 0.487500 - val_loss: 181.066200 - val_accuracy: 0.587500\n",
            "Epoch 10/570 - loss: 1479.611173 - accuracy: 0.493056 - val_loss: 139.502639 - val_accuracy: 0.587500\n",
            "Epoch 20/570 - loss: 1083.323137 - accuracy: 0.509722 - val_loss: 102.244008 - val_accuracy: 0.587500\n",
            "Epoch 30/570 - loss: 776.403496 - accuracy: 0.551389 - val_loss: 73.866274 - val_accuracy: 0.600000\n",
            "Epoch 40/570 - loss: 595.635486 - accuracy: 0.616667 - val_loss: 58.190190 - val_accuracy: 0.675000\n",
            "Epoch 50/570 - loss: 519.398180 - accuracy: 0.590278 - val_loss: 52.693742 - val_accuracy: 0.637500\n",
            "Epoch 60/570 - loss: 493.838720 - accuracy: 0.509722 - val_loss: 51.618523 - val_accuracy: 0.550000\n",
            "Epoch 70/570 - loss: 485.428793 - accuracy: 0.490278 - val_loss: 51.655112 - val_accuracy: 0.525000\n",
            "Epoch 80/570 - loss: 481.914313 - accuracy: 0.493056 - val_loss: 51.784493 - val_accuracy: 0.525000\n",
            "Epoch 90/570 - loss: 479.720313 - accuracy: 0.488889 - val_loss: 51.820646 - val_accuracy: 0.525000\n",
            "Epoch 100/570 - loss: 477.890350 - accuracy: 0.490278 - val_loss: 51.773436 - val_accuracy: 0.525000\n",
            "Epoch 110/570 - loss: 476.176806 - accuracy: 0.490278 - val_loss: 51.676194 - val_accuracy: 0.525000\n",
            "Epoch 120/570 - loss: 474.516131 - accuracy: 0.490278 - val_loss: 51.553022 - val_accuracy: 0.525000\n",
            "Epoch 130/570 - loss: 472.891701 - accuracy: 0.490278 - val_loss: 51.417855 - val_accuracy: 0.525000\n",
            "Epoch 140/570 - loss: 471.298749 - accuracy: 0.490278 - val_loss: 51.278095 - val_accuracy: 0.525000\n",
            "Epoch 150/570 - loss: 469.735489 - accuracy: 0.490278 - val_loss: 51.137516 - val_accuracy: 0.525000\n",
            "Epoch 160/570 - loss: 468.200890 - accuracy: 0.491667 - val_loss: 50.997985 - val_accuracy: 0.525000\n",
            "Epoch 170/570 - loss: 466.694124 - accuracy: 0.491667 - val_loss: 50.860393 - val_accuracy: 0.525000\n",
            "Epoch 180/570 - loss: 465.214419 - accuracy: 0.491667 - val_loss: 50.725138 - val_accuracy: 0.525000\n",
            "Epoch 190/570 - loss: 463.761035 - accuracy: 0.493056 - val_loss: 50.592377 - val_accuracy: 0.525000\n",
            "Epoch 200/570 - loss: 462.333248 - accuracy: 0.494444 - val_loss: 50.462144 - val_accuracy: 0.525000\n",
            "Epoch 210/570 - loss: 460.930351 - accuracy: 0.494444 - val_loss: 50.334413 - val_accuracy: 0.525000\n",
            "Epoch 220/570 - loss: 459.551652 - accuracy: 0.494444 - val_loss: 50.209131 - val_accuracy: 0.525000\n",
            "Epoch 230/570 - loss: 458.196478 - accuracy: 0.498611 - val_loss: 50.086233 - val_accuracy: 0.525000\n",
            "Epoch 240/570 - loss: 456.864169 - accuracy: 0.500000 - val_loss: 49.965647 - val_accuracy: 0.525000\n",
            "Epoch 250/570 - loss: 455.554082 - accuracy: 0.501389 - val_loss: 49.847299 - val_accuracy: 0.525000\n",
            "Epoch 260/570 - loss: 454.265590 - accuracy: 0.501389 - val_loss: 49.731117 - val_accuracy: 0.525000\n",
            "Epoch 270/570 - loss: 452.998081 - accuracy: 0.501389 - val_loss: 49.617030 - val_accuracy: 0.525000\n",
            "Epoch 280/570 - loss: 451.750959 - accuracy: 0.501389 - val_loss: 49.504967 - val_accuracy: 0.525000\n",
            "Epoch 290/570 - loss: 450.523643 - accuracy: 0.502778 - val_loss: 49.394860 - val_accuracy: 0.525000\n",
            "Epoch 300/570 - loss: 449.315567 - accuracy: 0.502778 - val_loss: 49.286643 - val_accuracy: 0.525000\n",
            "Epoch 310/570 - loss: 448.126179 - accuracy: 0.502778 - val_loss: 49.180252 - val_accuracy: 0.525000\n",
            "Epoch 320/570 - loss: 446.954944 - accuracy: 0.504167 - val_loss: 49.075624 - val_accuracy: 0.525000\n",
            "Epoch 330/570 - loss: 445.801339 - accuracy: 0.504167 - val_loss: 48.972698 - val_accuracy: 0.525000\n",
            "Epoch 340/570 - loss: 444.664858 - accuracy: 0.505556 - val_loss: 48.871416 - val_accuracy: 0.537500\n",
            "Epoch 350/570 - loss: 443.545006 - accuracy: 0.506944 - val_loss: 48.771721 - val_accuracy: 0.537500\n",
            "Epoch 360/570 - loss: 442.441305 - accuracy: 0.508333 - val_loss: 48.673557 - val_accuracy: 0.537500\n",
            "Epoch 370/570 - loss: 441.353287 - accuracy: 0.508333 - val_loss: 48.576872 - val_accuracy: 0.537500\n",
            "Epoch 380/570 - loss: 440.280501 - accuracy: 0.511111 - val_loss: 48.481613 - val_accuracy: 0.537500\n",
            "Epoch 390/570 - loss: 439.222506 - accuracy: 0.513889 - val_loss: 48.387731 - val_accuracy: 0.537500\n",
            "Epoch 400/570 - loss: 438.178876 - accuracy: 0.515278 - val_loss: 48.295177 - val_accuracy: 0.537500\n",
            "Epoch 410/570 - loss: 437.149195 - accuracy: 0.519444 - val_loss: 48.203905 - val_accuracy: 0.537500\n",
            "Epoch 420/570 - loss: 436.133063 - accuracy: 0.522222 - val_loss: 48.113869 - val_accuracy: 0.550000\n",
            "Epoch 430/570 - loss: 435.130088 - accuracy: 0.525000 - val_loss: 48.025025 - val_accuracy: 0.550000\n",
            "Epoch 440/570 - loss: 434.139893 - accuracy: 0.527778 - val_loss: 47.937333 - val_accuracy: 0.550000\n",
            "Epoch 450/570 - loss: 433.162110 - accuracy: 0.538889 - val_loss: 47.850750 - val_accuracy: 0.562500\n",
            "Epoch 460/570 - loss: 432.196382 - accuracy: 0.544444 - val_loss: 47.765237 - val_accuracy: 0.562500\n",
            "Epoch 470/570 - loss: 431.242366 - accuracy: 0.554167 - val_loss: 47.680757 - val_accuracy: 0.562500\n",
            "Epoch 480/570 - loss: 430.299727 - accuracy: 0.558333 - val_loss: 47.597273 - val_accuracy: 0.562500\n",
            "Epoch 490/570 - loss: 429.368140 - accuracy: 0.562500 - val_loss: 47.514750 - val_accuracy: 0.562500\n",
            "Epoch 500/570 - loss: 428.447291 - accuracy: 0.572222 - val_loss: 47.433153 - val_accuracy: 0.587500\n",
            "Epoch 510/570 - loss: 427.536877 - accuracy: 0.587500 - val_loss: 47.352451 - val_accuracy: 0.612500\n",
            "Epoch 520/570 - loss: 426.636603 - accuracy: 0.600000 - val_loss: 47.272610 - val_accuracy: 0.625000\n",
            "Epoch 530/570 - loss: 425.746184 - accuracy: 0.606944 - val_loss: 47.193601 - val_accuracy: 0.625000\n",
            "Epoch 540/570 - loss: 424.865342 - accuracy: 0.618056 - val_loss: 47.115395 - val_accuracy: 0.662500\n",
            "Epoch 550/570 - loss: 423.993811 - accuracy: 0.626389 - val_loss: 47.037963 - val_accuracy: 0.662500\n",
            "Epoch 560/570 - loss: 423.131332 - accuracy: 0.630556 - val_loss: 46.961278 - val_accuracy: 0.662500\n",
            "Accuracy on the test set is  0.645\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhU1fnHP/fe2bKTjWyEhCUJ+ya7CKioCNS9bq0/q23tot21rV3Utm6tttpqN/darbuiAoKICMi+QyAkgUASyE72ZDLLvef3xyQhk7lJJmSyEO7nefJA7nbOZGa+99z3vOf7SkIIDAwMDAwGP3J/d8DAwMDAoG8wBN/AwMDgPMEQfAMDA4PzBEPwDQwMDM4TDME3MDAwOE8w9XcHOiI6OlqkpKT0dzcMzgJXk4rF1dDf3TAwOC/Zc/RYhRAiVm/fgBX8lJQUNmzY0N/dMOgBFdm1HJIFi4t39ndXDAzOG8zLrsvvaJ8R0jHoNWIywlmQFoGcPr+/u2JgYMAAHuEbDB4a4i0QvwiA0OIVnKidT3Lpjn7ulYHB+YcxwjfoU+oTlhGTEY59/iIK42b2d3cMDM4rejzClyQpGXgViAME8JwQ4q/tjpGAvwJLgEbgG0KIPT1t2+DcJiYjHHuGZ+S/IbcGwIj3Gxj0IoEI6biBnwkh9kiSFAbsliRprRDicJtjrgTSmn9mAf9s/tfAAIAFaREAyGHz0XI29nNvDAwGJz0O6QghiltG60KIOiALSGp32NXAq8LDNmCIJEkJPW3bYPDREG/BPn8R9vmLUNKaWJ0wo7+7ZGAwaAhoDF+SpFRgKrC93a4koLDN7yfxvSkYGHhRn7CMBWkRRrzfwCBABCxLR5KkUOA94MdCiNqzvMZdwF0AycnJgeqawSCgbbw/aONn/dwbA4Nzk4AIviRJZjxi/7oQ4n2dQ04BbRV8WPM2L4QQzwHPAUybNs0w6jfQxT7fI/xhYTmInBzUXFs/98jA4NygxyGd5gycF4EsIcRfOjjsI+D/JA+zgRohRHFP2zY4v6mrS6c+YVlrvN/AwKBzAjHCvxC4DTgoSdK+5m2/AoYDCCH+BazCk5J5FE9a5h0BaNfAoJX6hGXQnAZgLO4yMNCnx4IvhPgSkLo4RgB397QtAwN/qE9YRkwCXjn+Rn6/gYFhrWBwHrAgLQJ72iJCSpxI4lMj5m9w3mIIvsF5Q0O8BfCEfkKLVxjCb3DeYQi+wXlJ25h/RbYni9iI+RsMdgzBNzjvickIBzwx/5ASJ6vq7EbM32BQYgi+gUEbGuItLIi3tMb8DV8fg8GEIfgGBh3Q4uMfUuJETjuBe2VBf3fJwKBHGIJvYNAFDfEWqEuH+emAUbrR4NzFEHwDg24SkxHOAsCetoiwsByO74o3JnwNzgmMilcGBj2gri6dmIxw5PT5hpWzwYBnwI7wpbpaL1dE09LhaLmpQEs+tYHBwKHtZG9YWA6AEfM3GHAMWMFvj+fL4/kCBeXQ6o8+YnoJdXXp/dgzAwNvWj+PzTF/Y5GXwUDhnBH89rTETN0rIQjvkZTxNGAwkGi7yMuI+Rv0J+es4HdGR08DAKnhGz1fQAODfsAT8/cs8jIKuRj0NYNS8NvTdjSlltoIyvWeGzBCQgb9gVHIxaCvOS8EvzPcKwu8QkLG3IBBX1NXlw4J6V5hH2PC16A3OO8Fvz0dzQ0YTwIGfUVdm0VeRjEXg0BiCL6ftH8SUNKaENLlxqSwgS5C0yj9fB+l6/djjY0g5aaFBCVEdfs6bYu5GDF/g55iCP5Z4om3biQo58y2lpiswfmN5nKz6brfUbk7F7WhCdlqJuuPbzH39fuJu2TKWV+35fMVUuIkv6bJGPUbdBtjpW0ACdr4GUEbP2NDbg2hxSv6uzsG/cSJ19dRuSsHtcFTWF1zuFAbHWy780k0t9rj6zfEW4jJCMc+fxFy+nxMS4f3+JoG5wfGCL8XWFy8E5Uz2UCFcTNbPdcNBj/5b3yB2ujw2S5cKlV7jxI9IyNgbbU3djNi/gadYQh+H5BcugNKPf9X0pqMdQCDHNnS0ddKIJuUXm27bczfCP0YtMcI6fQxaq6tNewTUuLs7+4Y9AIjbr8MJdjqs90UFsyQySP7rB8toR/D2M2gBUPw+4nFxTvRcjayIbem1WzLYHCQfN08kq6agxJkQbaaMYXaMEcEc+Ebv0KS+/4r1xBvYUFahBHzN0ASQvR3H3S5IG202P70E/3djT7FCPcMLqozT1CxORNLVBiJS2dj0hn19zehxStYWX+RUcxlEGFedt1uIcR0vX1GDH8Aoeaemeg1Fnqd+wyZkMqQCan93Y1OqU9YZhRzOY8IyPOlJEkvSZJUJklSZgf7F0qSVCNJ0r7mnwcC0e5gxr2ywFhoY9CntBRzsc9fhH3+IiPuPwgJVEDxFWBxF8dsEkJMaf75fYDaHfQEbfzMyOk36BeMuP/gIyCCL4TYCFQG4loGvrRk9lRk1xoTvAZ9TkO8hbq69NaRvyH+5y59GcOfI0nSfqAIuFcIcagP2x4UJJfuaDV1M2wcDPqL9uZuQJ9aO2uqRs3JKizBFkJiw/qs3cFAXwn+HiBFCFEvSdISYDmQ1v4gSZLuAu4CGB4b20ddOzcJ2viZkdVj0O+0fv4SYENuTa9n++RvPsq2Z9ejuTWEqhE5MoYFv1pCcFRIr7Y7WOiTpGAhRK0Qor75/6sAsyRJMTrHPSeEmC6EmB4TYVgRdEVLqOdcRNME9kYXmjYw04INuk9LzN8+fxFKWlPAr195vILNT32Gs96Bu8mF6lI5nVvGugc+ZKCmlw80+mSEL0lSPFAqhBCSJM3Ec6M53Rdtnw9UZNeeM149Qgg+/+Qoqz/MwelwY7WZWHrdGBZcPqq/u2bQQzSni6PPr+LEq58hVI3hNy0g7e6riaiV0HI29vj62R/vR3N5m88JTVBfWktVXgVRo4yoQFcERPAlSXoDWAjESJJ0EngQMAMIIf4F3AB8T5IkN2AHbhbGLTlgtHj1nAu5+xvX5rHyvSM4nZ4vbmODiw/fOozFamLOgpR+7p2BHkII6o8WoTldhI8drrtaWAjB5psfoWLLYVS7xzIk68l3KVq5g0vW/REp3jPn1BNzt/qyOoTOE6EkyzRWNhiC7wcBEXwhxC1d7H8WeDYQbRl0TEuRlt6a0D1VUENebiURQ2yMmxyHydT9iOAnH+a0in0LTqfKqg+OGII/AKnNLmTLrY9hLzqNJEkoITZmvfgzhs6f6HVc5c5sKrZmtYo9gNbkpC7nJMVrdpO4xFM6tCfmbonThlOeVYLqdHttV10q0WlDe/hKzw+MlbaDkKCNnwXUkrmq0s6//ryVklN1SLKEoshYrAo//vVFxCWE+n0dTRPU1/raBgPUVAU+5mvQMzSniw1LfoPjdC00P5C7G5rYfNPDLN7zT68KXqd35uh6/bsbmqjYntUq+G1piLcQE2/BnnFmgFKRXQugexNIu2I82SsOYq9uQHNpAJisJjKWTSJoSHDPXux5gmGeNkhJLt3R+uXpCbu2nuTBn6zhVEEtqipwuzQcTW7qax28+LfuPZbLskRUjP4XMzbeyLIYaBR/uhu1ydkq9i0IVePE6+u8tgXFR6Ho2EIrQRaCk87kZ2hOF03l1QhVvxBMTEa4V3GXtqt9LSFWlv71JsZePZXwYZHEjIlnzo8uZertc3ryMs8rjBH+AKe4WuPdHQ5yilVCbRKLJ5mZP8aMJEldnptcuoPV8gwWpEWcVdsN9U5ef34Pmua7TwgoL63ndHkD0bH+i/W1t4zn1X/vwdUmrGO2KFx3y4Sz6qNB7yCE4OTyLbgb7D77NIcLe5F3zkXi0pnsvc8CDQ6vG4RkUhh+w3yEqpL5+9c5+txKhKphCrEx4aHbGHn75R32oSHewoJ4C/Y0T/hnVZ2dxexk2u1zmGaI/FlhCP4AprxW4+HljThcIIBGp+DNbU7K6wQ3zPTPeXFx8U4oPrsJ3UP7S5EVCVz6+yVZwu3WuRt0wtSZSZgtCh+/fZiKsgZi40O5+qbxjJ1oxGAHEvvvf4lTH2/1fPDaoYTYGLpgkvc2m4WFnzzCtv/7E/UnSpEksMVFMuule7FEhXHwwVfJ/dcKtCZPjN/pcLHv3uewRoaRdFXX4t1e/OW0E7hXFgTktZ5PGII/gFm134nT7f2dc7rhs0wXS6ZYCLZ0Pcpvwb2ygJD0VE9JPD8RQrR/mvciOMTM0Hj/Y/gtTJgSz4Qp8d0+z6BvcJyuJe+l1WgO3zu9pCiEpSWRuHSWz77wjGQu3/4MDQVlCFUjJDUOSZLQXG5y/31G7FvQnG723PucX4LfFr2yjobFs38YMfwBzLFSFb11SSYZSmu6N7IG0HI2dsuIbfzkON00OACzWeaO78/wK7RkcG5Rczgf2WrW3WeJCefi1Y92WqoxZPhQQkfEt342XLWNujcPAEdpFe6Gnk3Y1ycsa130ZVo6nMI43wliAw+G4A9g4iL03x6XBlEhZye0Latz/SmvGBpm5eY7pmA2yyiKhCSBJMPI9Ch+95fLGZURfVZ9MBjYhCQPRbRLfWzBeboWR2Vdt65niQyFjgYGikxNVuBCM3oWz4bN8xmMkM4AZukUC5kn7bT97pkVmJSsEBHcs3t1fk0TMX6Ed2ZdNJy0sTHs3XEKl0tj4tR4koaf3SSwwblBSGockdNGU7HlsM8+4VbZfc+zXPjOb/0uyC7JMhFjkqk5lO+zT1ZkbEOH9LjPHdGSsGDE/j0YI/wBTGqswncvtREZImGSwaTArFEmvnVxz50Jk0t3ELTxM7/slqNigrl0SRqLr84wxP48If1H1yF1IOilX+xn69ce65Z/zZQ/fRu5XdqmZFKInjmGkOF9M2Hf3uZZTp/fJ+0OJIwR/gBn8nATk25RqHeAzQRmU2Bj5iv2xLHAx7fU4FzBVWenYushlCArMXPG+T3qbo9QVaoPHEe2mAgfl0LE2GQkk4LQWUyFJijblEnFlsPEXjjer+vHzpvA1L98h/33vwQCNJebmDljmf3yfWfV30DQEG+BNpYP0Lc2z/2BIfh9zJEiN5uyXbg1mDXKzJQUBbmLiU9Jkgjrpc9hS9qmYbV87nHitc/Ye+9zSGYTaALFZmHeew8QOaV7RnSl6/ez/Zt/RnO4EJqGNTaCuf/7FUMvmkDp5/sQqm+CgNrYRPmXmX4LPsCI2y5j+I0Lqcs9hTU63Gulbn/T1ua5hdDiFYPuBmAIfh/yznYHnx92tcbkDxaoTBim8L1Ftn7PdlFzbV4f9sFK4Ylqtm8qwOlUmToziTETYvv9b3821BzOZ++9z3m8a5r9a9z1djZd8yDLcl5GtphxNzrI/cdHFLy1AckkM+L2yxn1zcXI5jNfe3vRabbc+ihq4xnLi8b8MjYu+w1X7P4Hm29+hMod2T7tKzYLlqjuFx9RrOYBX9i9hfqEZa3fiZ6Yvg0kDMHvI8pqNdYdctHW3dXhhsyTKtnFKmMS+/+tCLQHz0Bj7cocVr2fjdulIoTHNmLStARu/94F55zoH//PWh8TMQDNrVK6fj9xl05lw5JfU5NV0Jr/nvnQfyn9fC/z3v5t6/H5b673sRwGcNU1Urx6Fxe9+wArx30Td3271ElZJvn6eYF9UQOYtqZv0DfFXnqD/leZ84RDJ/W9Qxxu2Jff+4JfZxesz3KSV6qRFCVzyXgz0aG+c/bJpTuQI+Z3a4FWd7A3uljxXhZ7tp0CCWZemMySa8dgtfXO6y8trufzT3I5cayKosJar4VkTofKgT3F5ByuIGP82VnrFq/dTfaf36OxqIKYOeMY94ubCB3Z+49Kzqo60Am1IMBV20DJml3U5Zz0Wuyk2h2Ub8qkcncuURd4Jm4aT1UgXL43DuHW2Hf/CyR9ZTbz3n+IrV97rNUJU7aamfPqz7FGDc6BgT8sSIvAnuZt+nYujP4Nwe8jbGaQdQaRigxBvaOtrZTXavxheSNON7hUOFyksv6wi58vCyI11neST8vZSAiBF31V1fjz7zdSXlqP6vYo74ZP88g5XM59v1uIrPcH6gEnjlXxt8e+xO1Sdf2AwCP6+3cVnZXg572yhv2/fAnV7gmHFJysoGjldhZt/Euvi37iklmcWrEdtd2iJc3lJvaiieQ886HugibV7qD8y0yiLkhDaBquWl+vnBbc9XbyXl5Dxo+uZVn2S1TtO4YQEDV1FJLi/+Sw5nQhmucYBisxGeGtls9AQAq+9AZGWmYfMSVF/94qSzA3TX9VY6B4a5uDRget4SRV8zxZvLSh4xWOWs5Gv1I2u0Pm3hKqTttbxR7A7dYoK64n+1B5QNsCeOuV/TgdHYs9gCyDxdr9zBbN6eLAb//TKvYAqBruhiYOP/6m97FulUOPvsFHI27j/dgb+GLpb6jOPNHtNtuSuGwWUVNHowSfmVRUgq2M+dn1BMVHEZQUDXr3TwFVB47RVFbNmhn3cHL55o4bUQXFn+4GPJYKURekEz093W+xbyqrZvNND/NBws0sT7yZ9Zf/krrcUz7HVWee4Ojzqzj54RbUDlbk1h8rZtvtT/DRiNtYPe175L28ZkCWNWyIt9AQb2lN/Rxoq3+NEX4fEWSR+OEVNp79tKnVG0fT4Pb5VmLDA3vfFULg1jwWDJIkcfiUqueBxakqwa48F9NH6t9w3CsLCE3LCVj2TsGJahxNvuEDl0vjZH5NQA3UNE1QeKK66wMlCZdLo+RUHfFJ/k9CNhSW62avoAmfBUu77nmGU8u3tIZEKr7M5IvLf8llW/5KSGqc3222RTYpXLT8IQrf/5LC977EFGpj5B1XMPQiT2GSmNnjdI3PAKr35rHze3+j4USpftplG4ISu86kEUJQtuEAxat2YAoPJuXmhYSOiOeLxffTkF/W2sbpHdl8ftkvuHLfv7AMCUWoKju+/RRFq3YghOc1yVYzC1Y+TMTY4a3XbzxZzrqL78VVZwdNw1lZx/5fvUTd0SImP3KHn3+x/sOz+vdM0RdJfNpv2T+G4PchYxJNPHVbCEeKVFQNMhIUgrphgNYVQghWH3Cxap8TuxMiQyRunG3BavKM6PV48QsHE5NNWM36/VBzbYSyIiCiHzM0BKtVweHwFhmzRSY6NrAFLCTJM3J3OvQFTTFJqG6B0ASb1h1ny/oTXH5VBldek+HX9a1R4R2KZVDiGcsJe3ElJ9/f7OMlozpd5Dy7nKlPfsfPV+SLbDaRctNCUm5a6Nu/mHAki0nXIkFSJMo27O9S7GWbhbTvdv6+C01j+51/9njnNzQhmRRyn/mQkd9aTFNplXcbQqA5XBS8vYHRdy3lxP/WU/TJztYboQZQb2fLrY+yeM8/WyfSc575EHejg7aPamqjg2MvrGLsz244q2yh/sITJl3mlRFXkV3LIVn0ySSwEdLpY8yKxMRkE1NSTAEVe4AVe518tMdJo9MzuKtsELy0wcGYRKVDKxNZhqyizr/4aq6Niuxa3G6N/buKWL/6KHk5p7v9SD1tZhIms29frDYTE6cF1j1TkiTmXZyK2ez9ETebZcZNGto6+hUCNFXgcml8+lE2xaf8KxpjiQwlceksH5MxT1jlhtbf646e0jUiEy6Vyr3HuvWaTu/K4eDv/svhx9+k7qhvaKQtHgMz33kEJcjK8JsXdjj6B5AsJpQQK9Oe+i5RF3RuqV386e5WsQeP9YLa5OTov1ai6Vhnq40Ojr24mr0/+zc5zyz3Sgdtoamkyiv0U7EtS3diWbaYqc0u7LR/5wIxGeGt5m9y+nzk9Pm9FgIyRviDBFXzjO7bD+icbk8RlSHBUNVw9te35W7jN0+7cbk1VLeGrEikjozke/fNwWz2L6ZrtZn46QPz+e9zuynIq2odsLmcGp9/cpTLlqX7TNw6mtzs3FJI4YkakoaHM+PCZIKC/JvzuOqm8VRV2Tm4pwSzScbl1pg6M4lhqRHkZFWA6q16qirYt7OIhCT/sk+m//0H7BKColU7PCtcZYmJD/0fCVdMbz0mdGSCvs2wSfY7H10Iwd57nyP/9c9Rm5xIisyRp95n8mN3MurOxV7H2ksqyX/zC5pKqhh91xIyH34d4XKjOt3IJoWY2WPJ+ME1nFq+leoDed59MiskLplJxo+uJWJ8ql+TrIXvbvKZOAaQzUqHTqt1RwqpyznZ4U1HkiS0Nh/ksNGJnr62u57mcBE8bHAVLm9JlGhb+nFDbk3r/p4+BRiCP0hodEJHtUgq6gXfvcTG39c20a5+OELA2MSuBfvfnzfRUK+d+Y664fjRStatPMpiP8MgAHEJodzwtYn89dEv0ZoV397oYs1HOTQ2urj25jOVr6pON/LEgxtoanLjdKhYLAqr3j/CvQ8tIGZo11W2TCaZb94zk+pKO2Wl9cQlhBExxMaGtXn6J0gdmzrqXj/YyuxX7sNZWYfjdC0hKUORLd43o+CkGBIWz6BkzS5PucBmZIuZ9B9c7Vc7p7dlkf+/z1sniIVbRbhV9t//IknLZreaj5Wu38+WWx9FqBqaw4UpxEb42OHYEqKoOXicsDHJTHjg68gWM9P/+UM2XPkrNJcb1e5ECbFhiQxl6p+/gy3WfzMzxWr2/NHaP+0pCsHDomgsKNO3Ru7gZgCeAisR487E8NN/eC1FK3d4TZDLVjNDF0wiOHlwCb4ebSvW2dMWERaWc9YGcEZIZ5AQYgFLB7qdOERm/DCF2WkmLCZPZpBZ8Rx/1yW2DuP3LdQ1CQpPaz4DMpdLY+tGXwfErlj1wRFcLu+7k9OhsvHTPK9J3Xf+e5C6OkdrHN7pVGmod/LWK/u61d6QqCDSx8YSMcQzUTbpggTdBBZFlpgyI6l7LwawRIURlpbkI/YtzHz+J4y44wqUYCtIEkMmj2T+x38gbLR/bZ38YHNrnLstkqJQstaTRaO5Vbbf+SRqo6NVYN0NTVTuyqFo1Q4aTpRSunYP6y/9BcVrdzNkQiqL9/2LcfffQupti5j82De5YuffuyX2AKlfvxRFJ69YAi5e/SijvnUllqgwH+O0MwdKSM37ZKsZJdjGrJd+hiSfkabIySOZ/d+fEzQsBtlqRraYSLpqDrNf6T8fnv6krQGcXu3fzjBG+IMEWZa4+gIL7+10+tgpXz/TiiRJ3H6RjYVjVTILVWxmmD7S5JfNstbJaExVu58aV3xK309dE4JTBTWMTPdMeh4+UIpo99QiBBw5VI4Q4qxXx0ZGBXH91yfy7msHmy/qGaQuvX4s8YmBnwBUrGamPP5NJj92J2hat3LYAY9XjoRPCESSaHW0rN6f5xUG8aI5m0ioGqrdwe57/s7SrBewRoeT8aNru/tyvIiZM470e64m+68fIMkykiIjhGDu/+7HGhPB5EfvZPKjd5L15DscfvxNRPtVvRLEXjSB0FGJBCdGk3rrJdjiIn3aSbjsApZkPo+jogZTSBCmYP9KfJ4PtC3/2FUqtSH4g4hFEyzYLPDxHhfVjYLEITJfnWUhI+GMwKTEKKTEdE9wIoJlIoIlTtf7ivuINN8vZ1ckDAun6rTvgh/VLXj2T1v4yW8uIjl1SIcLsboym/OHeZeMYPzkOPbtKkbTBJMvSPArTNQTJEmCboo9wPAbF5D34mrvnH9Ac6mt8wWyWfF7Et1VU0/jyYqA2RKP//WtpH79Uko/34cp1EbC4pmYw4K8X8MN88l64h1fwW9OY42ZOYYxP7m+03YkSer2E8j5Rld1q42QziBjXrqFP94cwr/vDOXB64IZl9Sze7oQgg1ZTl2xByg65keuezuWXDsGcwfxJ6dD5bXn9gAwfc4wlHZ20JIE46fEB8T7JjI6mIuvGMWlV47udbHvCZGTR5L2/a/4bBeaoHjNLgAiJo7wEdmOEKqGOdS/Y/0lJCWOkXdcwfCvLtDtR0hqHNOe+g6SyVdyNLuTI0+9j7O6PqB9MvDFEHyDDrE7BQ8vt/Pqlx2XQyytaOw05KNH6qhIvnfvbKQOPn0lRXU0Nji59tYJDIn0Fg8hICernNPlPUg5OgcRquqJz7Xd5nKz797n0JwuXFX1uO2+KY7tkSwmhi6YFNDc9aayarKefJe1837CivQ7+PKrf6Bqn2/KaeqtlxI+YYR+v8wKFVsOk/fyGnL/8VGXaacGZ0dAQjqSJL0ELAPKhBATdPZLwF+BJUAj8A0hxJ5AtG0QGFyqAOFdYOW9nQ4KKzsvlh5kgfDSld1emJU+NpbwCBs1Vfr2DooiYzLL2Bt9MzwcTW5WvX+E275zQbfa7A0qKxo5sKcYSZKYdEECkVGBHTm3UPTJLtBxtRSaoPZIISWf70PTW12nyMiKjGyzIFwqERNSmfj72yn9fB8hqXE98vwRQrD/ly9y9PlVXkZuJWt3U74pkwUrHybqgjQ0l5v8N7+g4J2NOIorda+l1tnZctvjKBYzQtU4+LvXSPveMiY+9H9n3T8DXwIVw38FeBZ4tYP9VwJpzT+zgH82/2vQz1TWa7y80cGR5sVXafEyd8y3ERsus+2oW9eQsQUJuGyCGTXXSlDuZ8jp3TNcu3BhCmtX5Hpl7MiKRPq4GCxWhdPljbh1ck2FBtmHA++90102rM1j+RuZrb9/8EYmN3x9IvMu0R/F9gRrdBh6U92aW8USGUbVrhwvZ8wWTMFWJv3udoJT4rDFR5L79w9Zt/BeZKsZzekmdt4E5rz6c0wh3V/qf+K/n5H3n099XTuFx6Tt4IP/Yf6Hv2PTNQ9RuSdXd5GVF24N1X3mmKP/XknC4hnEzB7b7b4Z6BOQkI4QYiOgf+v2cDXwqvCwDRgiSdJ5UG5jYONWBY9+ZCerSEUTntTonBKNRz+043CLTsUeYEySzFemnhH4/JqOzdj0uPyqDNLGxmC2KFisCmaLgqLIHMks5yff/JiV72WhdrC4oK7GwUM/W8unH+fo3hR6m4qyBpa/kYnLpbX+uF0a7752kMqKxoC3l37P1Z60zjZIJoXIKaMITo4lfFyK/opeVSNy2mjiF02lZM0uTn6wBc3hwl3biNbkpHzTQfb94gWvc0o+28PaeT/mg4SbWDPrBxSt3K7bp9x/fIymky7aQtX+PIrX7KZq79GuxV4H1e4k/8313T7PoGP6KoafBLRdA32yeZsXkiTdJUnSLkmSdlXU+LfE3eDs2UcpPYwAACAASURBVFegYncKrzUzQoDDLdiV52bScEXX0lkC0uNlfrw4yCuTJrl0BxXZ/r9vJpPM9++by88emM/VN45DlqXW4iRul8beHUVYbSZMOhN9qiqoKGvgk+XZ/Psv27rzsgPC3h1FHc5d7N9VFPD2EpfOYsxPrke2WTCFB6MEWYmYkMqc//4CgJF3XuGT6y5bzESMSyFy6mjAM2L2yfRp9rbRmj1vij/dxdavP07NwROojQ7qjhSy/Zt/puBdX7tfV03n8yhBcZGUfLpb16bZL4RA9MPNfDAzoCZthRDPCSGmCyGmx0Scv8UVOqMla+be/zXw7Rfq+c07DRwo6CD/ugvKajQfKwbwGK2V1WjcPNtKeJCEtVlHFNkzb3j7RRbuWxaESedukFy6w2spuD8MS4nA6VTRNO+bj9vtGTUnJofpW/0CLqfKsZzT5OdVdavNniKE0HcGEJ2vW+gJY39+I8uyX2Lua7/k0i+eZNGGP7eusg2Kj2LhJ48SNT0dZNmzOOmaOVz0/oOt57vq9L3vhVttzeH3WD57j9pVu5ODD/pGa+Mvm9a6DkCPyBnpWGMjkPy03miPEmJj+Ffnn9W5Bvr0VR7+KSC5ze/DmrcZdJPPMl28v+vM4qriasE/P2vinsttjB/WvbczOVrGrPg6aVpNkBytEBki8+iNwWw/5ia/QiUpUmZ2mpngLkzfFhfvxDRteGtOcEO9k307i2iyuxgzcShJyRE+5xSeqMHV3vcBkJotnhVZ6nCRl6YJThyrImVk99cEnC2TLkjgkw+OoLXvkwSTLkjstXYtQ0IZumCS7r4hE0dwybo/oTpcyCbZZ4HX0PkTKF6z28cGISxjWOtCpvpj+k8n9pMVaG7V4xnUzLj7b6Fo1Q4cp2t1rRJOLd/Cxev+5DFJazfhLFvNSIrsE+qRzArCraEEWRh+w0XEzp/YwV/C4GzoK8H/CLhHkqQ38UzW1gghivuo7UGDpgk+2uP0NUhT4f2dzm4L/vgkhdhwmZJqrdWHR5FhSLDElFTPF9tqlpg/xgx0r0jLij1xLEiDI5llPPf0ds9Enqqx4r0jzLwwmZvvmOyVS5+cGsHBvcW4nN6P8KoqKDxR0+moWWiCkNDO+1dwvJrN60/QWO9k0vQEps1MQtEJFflLfGIYl1+VwacfZ7cWdFEUiSXXjiE27uxy+t0NTRS+u4nqzONEjE9h+A3zMZ1FvryiE8sHmPTIHVRsOYza5ERzupFMMrLFzLSnvtd6TFBCNI0FZT7nWmPCvcTec2wUl29/hrVzf0RTie8TlqQoqPV2Zjz3E3Z972+tnjumEBtz3/o11QfyyH7qfRwVNURPz2D0979CzaETqA1NJFw5o0unToPuIwWiaowkSW8AC4EYoBR4kGaFEEL8qzkt81lgMZ60zDuEELs6u+YFaaPF9qef6HHfBhMNDsFPXmvQnUy1meHv3wjt9jXtTsH7Ox1sP+ZGCI/dwvUzrITaer6wyaUKfvyGgya79x3KYlX45j0zGD/ljCVyQ72T39+3lsYGl48Plz8MjQ/hl49cgqV5QdeRzDLee/0gJafqsFhNuJpDRi3tD0uJ4If3z9OdH+gOxSdr2bezCCSYOiOpW0VU2tJ4spzPL/k5rno7akMTSrAVU4iNSz5/ImArYgHsRafJ/cdHnN6VQ8TY4aTdfZWXp0/+G+vZ89N/eY28lWArEx66jbTv6Kfefnnjw5Ss8f06K0EWFm1+mrBRiahNTk7vzEaxWYi6IM3LK8cgsISHh+8WQkzX2xeQEb4Q4pYu9gvg7kC0dT4TZAaLCfQSI4aeZdWsIIvE1y608bULe9g5HbKLVXD7ThI4HSrbNhV4CX5IqIV7H1rI26/uJzuzvNtx8MrTdnZvPcmcBSnk5Zzm309tbw0Rta+y5XSonMyvYc+2k8ycN1zvcn6TMCychGE9n2/ae9/zNFXUtKY4tpig7b3338x7+7ednqu5VY7+awV5L61GtTtJ+socxv7yRt0i40GJ0aTdfTXRO7OxDh1C6Cjv8FPKLRfjbnJy+OHXcVY3YAoNYtzPb2T0XUs7bD/t+1+hfNNBr5uEZJIJHzOcsObrKzZLazUug/7D8NI5h5BliWVTLXy42zusY1HguhkDr0B0ZyP1ijLfDI/YuBDuvm8ur7+wl+2bCrol+m6XRs7hcuYsSGHFe1m68wFtcTpU9mw/1WPBDxQla/f45LMLVaN03d4ujeK23/kkJZ/uac3AyXt5NUWrd3D51r955dcLITjw65c59sInnoweIbDGDmH+R7/3eooYdccVjPzG5a1PGl2NxuMWTmbCQ7eR+dB/kUwKwuUmLCOZC9/69dn8KQx6EUPwzzGumGjGJMOKvS7qmgSxYRI3zrIwMXngvZUZCUqHBcQLT9Twyj93cft3L/ARs9LiOl2xl2U6LUheeKKaN17ay6kC/1JDg4IHzk1SVmRUHdt4SVY6FfvaI4WUrNnt5bWvOd04ymsoeGcDI79xRev2U8u3kPfyGjSH64yFcn0Jn0z+DsOunsvE39/eKvySJPk9fyCEIHbueC567wGEAFvcEL+tnw36loGnEgadIkkSiyZYWDTB0iOL4L7AYpK4MN3E+iz9tNF9O4qYNjOJSRd4r8EblRFNQV61z4IqSZYwmySfid0WSorqKSnyz4DLYlGYd0mqX8f2BcOum0fBOxu9SvnJFhPDrp3b6XlVe496ZtrboTY6KN98yEvwc/+9Un8BlCY4+eEWyjYc4Ipdf0eoGjnPfkjZhgMEJ8eS/oNriJk1Rr/9fcfYcutjuKrrQZKQbWZmv3RvtwX/xP/Wcfixt7AXVxKWlsSkP3yD+EVTu3UNg64xZk7OYQay2LfQmd++261fQOXiy0dhtSle5moWi8LchaksWpKG2XJ2H1tFkbDZTJjMMldel8GojOiuT+ojJj92J+HpwzCF2jyLq0JthI5KZMrj3+r0vKBhMbpVumSrmbCR3vF5d20nC6U0gbvRQfZfP+DT2T/k6D8/pnrfMYpWbGfT1Q9Q8PYGn1PcjQ42XvUA9lMVuBuacNfbcVbUsvnmR2kq9X9dxNHnV7H3Z8/RWFCGcLmpPZzP1q8/RukX+/2+hoF/GCN8g14lPUHBLIOrg1CMXpw/fIiNX/zhYj5+5zBZB8sICjZz8eJRXh41n68+hrs5t7urIiyhYRYuXTKapOEROBxuRmfEEBY+sApoWIaEsujLv1C+KZPa7ELC0ocxdP7ELuPnsReOxzo0Ere91GsOQDYpjLj9Mq9jk66aQ92xIrQmndgRoDU5KXz/S1w1DYjmlbcIgWp3sve+5xl23Tyv1MyiVdsROiljQlXJf3sDGT+4psvXLTSNw4/8z+fJQ7U7yfzdf4lbOLnLaxj4jyH4Br1KerxMeqLMoZO+wmCxKsyad2Y9ntrkpKm0CltcJFExwdx8xxQOHyzF7dIYM2Foq43D0uvHsviaDJrsbla8d5hNn53QbVtWJK6+cRyXLknrldcWaCRZZuiCSR0urOronIWrHmH7t/5M5Y5skCWCEqKZ8e8fE5To/QQz4huXc+zF1TjctboFkCWLyVvs2yBcburziglPH9a6zVFeg+byDddpDpffI3xXbSOuen3rhbocY21moDEE36BXqGrQeGOLg/2FKpKA+HAobZ5LFYBilpkwOY7J0xMRQnDo4f+R+4+PWs8PvuNaPi0PoaW2n6oKrrtlAvMvGwl47JNDQi3MXZDK5s/zdSd5FUXC0lEt1UFEUEIUC1c+gqOyFq3JhS0hyifcV5d7ivVX/NJjm9CBP41iNhGSGkfNgeM++zyunN7rPGIvHK/7BKKE2Py+aZnDgjAFWXDp3DhCUuP8uoaB/xgx/HMUtyrIPOlmX74bu7N3vFvOFqdb8MiHdvbmq7hVTzinvB6GhsONsy1cNc3Mz6+0MvKKdGRZIueZ5eT+4yPURgdqowOHQ2XVcQVHk4qjyY2jScXt0vjgzUMUFXpn4CSnDmHx1Rn6HREwecb5Y8pqjQonKDFad25nx11P4ays9w6dyJKnDq1JIXxcChd99HvG3XejjyunbDERO2+CT3nBIZNGkrhkptfxSrCVqKmjib/UvwlXSVHI+NkNPm0qQRbG//Zrfl3DwH8G//BnEJJbovK3NfZW+xJNg9susjI3rXv2B73FruNuGh3Cy15F1aDaDolDZCY0p5COLtnFamkGNU9/4CVElXHDdIP7qltlx5cFXHOLd42dJdeNwRZs4sM3DyHJErIsITTB1++aRnhE933ez3UcFTXkPLOc4jW7scUNYcTtV1B98Ljv31QTWOIiWLz7n15lCcdkF3Lkz+8imU1oTjfR09OZ9eLPdNua+cJPKHh7A8dfWYvmcpNy68WMuG2Rz8i/au9RKnfnEpQUTfyiacjmM9KT8aNrUcwmsp58B2dVHcHDYpn48DdIXDwjcH8UA8AQ/HMOh1vw9Go77efdXt3kYGSsQvyQwD201dkFm3NdlNdqpMUrXDDChFnpOjPo5GnNx5ANwK3CqSqNCW1s9K4o2sFrld6jdlUxIXRGqZoGTXoXBi5ZPJoZc5LJ3F+CLEtMmBJPSOjAybPvKxyVtay98Mc4KusQTje1WQWc3n5Ed3IVPHMA7WvQjr3vRkZ/Zxk1WQUExUUSnBxD/fESNJe71Z2z7fkpN19Mys0X615fc7nZcsujlG8+hNAEsknBFBbEwk8eJXSEZ6W1JEmk3X0VaXdf5WPQZhBYDME/xziQry94mgabc11cPyMw2ScnylWeWGlH1TyV9bbmuvloj5PfXB1MsLVz0Q/uoAtmBRIjvW9IkiQRMSySmsIzk3xR5UUInYK3FqvClOmeVMOSU3Xs23UKkJgyI5H4xDDCIqzMmZ/SvRc6yDj6zxU4q+oRbZZiq3YnyFLLdEgrstVMys0Lda9jDg8mZtYYTn68jXWX3Iva5EK4VaJnj2X2y/dijfbPTiL3nx9T/uWh1lXAGp50zu13Psml65/0Od4Q+97FiOGfY9hduk60qAIaHYGL5T+/vokm15kyqg43nK4TfLy34wpH4HH0XHdIP+0vxOpx6GzP9G9dhNJmctXa1MjIYwcwKVJrjrnFqjBhSjwZ42NZ/VE2f/ztela9n82q94/wx9+sZ+2KnLN7oYOM4rV7WlfRtsUUbMUcEYIp1AaKjCnERsS4FMbed2OH16o+kMfObz+F83QdakMTmsNFxZZDfHnDH/zuz/FX1voUXUHTqDmU361cfYPAYIzwzzHGJSm6uetWE0xNCczbWd2oUVHv24hbg515bm6a3fFTxJFiVbeoCsDYRJNXhawWEqcNZ9Efrmb/69upKa4nbNxwFv76FhqHxrNtUz4uh8rUWUmMnTiUspJ61izP9qqDq2mCVe8fYcqMpLO2Jh4sBCdGU733qM92oWpcvPaP1B4uoKGgjMgpoxi6cFKnef5H/vIeapO3WAuXSm1WATVZBUSM7dqHSNMxzwNAknRTOg16F0PwzzFiwmQum2jms0xXq7BaTTAmUWHcsMA8DiuyhH45J+jKTbihqeOnDLur431DxyVw2SPXUBg3k5iMM+GC4SO8Y8YHdhfrpmBqAg7sLjpncu57i7R7rqJ0/T5v50qzQsSEVCLGpRAxzr+Ql9rkpGjVDt3PgWRWaCqu9Evwk6+7iNx/fOTz1BGcFE1QUoxffTEIHIbgn4NcP8PK+CSFjUdcuFSYNcrMtFQFOUBWC2E2iZQYmePlmlf4yKzA/DGdf2TSEhTdNG+rCab48QSSXLoDSsG09EzFrLZIkqRb7lDi3LCa6G1i545n8uPf4sCvXmweRatEThnF3Nd/2a3rnFy+GdGBU51qdzBk0gjdfW1pKq2iIb/EayQv2yzIJoWZz//UeL/6AUPwz1HGJJoYk9h7b99dl9j448d2Gp0CVfMUK0qPV7h8YueZL0OCZRZPNPNpmycQiwLxQ2RmjvS/vy0Vs9ozeXoiK9/LQm039JQkmDKj90oLnkuMvP0yUm5aQO2RQixRYWdVQKVqXx7CpW8xHTN3HNYY3zKVbXE3Oli38F6ayqrPTDrJEtbYCC5d/4RPTr9B32AIvoEuMWEyj98cTOZJlap6QWqsTGqsfyGja2dYGR2vsP6wC7tTMGOkiXkZZkx+pHS2sLh4J0poE/UJ3lWWYuNCuPrm8Xz45qHWbQK47msTiYoJ9vv6gx3FZiFyyqizPj88fRhKsNXH40a2mkm7+6ouzy98dyPO9jYNmsBZWUfD8RJD8PsJQ/ANOkSRJSYPP7uPyMRkU489+tVcGxW1tV4xfYCFl49i0rQEDuwuBgkmX5BAZLQh9oEk+YaLyPzDa56UzuYsAckkE5QQTcKiaV2eX7k7F7VBxyNH06g+eILomfp2ywa9iyH4BgOa5NIdKOG+I/2omGAWXnFmBCuE4FjOaXIPVxASZmHarGGEhp1/C68ChTk8mIs/+yO7736W0zuOgCQRd8kUpj97D5LS9ZNe+JhklCCrT0qmpMiEjjp/7C4GGobgGwx41FwbdKIRmiZ47qlt5GRV4HSqmM0yy988xPfvncPoMUYmyNkSNiqRhasfRW1yeiwrLP5bd6TcfDGHH3/LU4mr5QnBrGBLiGbofKO2bX9hLLwapDQ4BO/vdPCbdxp45MNGth9zITorMjvA2ZBb0+G+HV8WeMTeoYIAl1PD6VB5/m87ul0M3cAXxWbpltgDWCJDuXjt40TPzEBSPAZt8ZddwMJPHunS49+g9zBG+IMQu1Pw+w8aqW4QzSmSglc2OjhepnHznMAX/ig5cJKcTzJxNjhImZfGyIszUMyBXSK/uHgnFIN9/iKffds2FnjEvh1ul0ZBXhWpo6MC2hcD/whPH8bFnz5+Vk8IBr2DIfiDkC9zXNQ2Cq98eKcb1me5WDzZzJBOyg52lwNv7STznd2ozaZmZYeLObrmEJc/fl3ARR+gItt3ElcvL//MPiPXu79RbMZcykDBeLYahBw6qeLUSaE2y3C8rINag2eBvbqRg2/tahV7ANXhprrgNPmbfZf3B4Lk0h2ElHj7+cxdkILF6ntzsVgUn5W6Bp2Tfaicv/9pC4/cv473XjtITbV+NSqDcxNjhD8IiQ71mI7p2J8TERy4EW/ZoSIUk4zWboGOu8lN4dY8Ri7soDBJD9FyNhLCfBriPSPH6XOT2b+7mKyDZbhdGiazjCRJfPtHM3W9ewz0+fLz47z/eibO5tFCWXE9O7cU8stHLmZIpLeFshCC7EPl7NtZhMksM2vecJJTjZvrQCcggi9J0mLgr4ACvCCEeLzd/m8ATwAtRSqfFUK8EIi2DXy5ZJyZLTlur1G+LEFkiMSI2MA91FlC9OcDJFnCGhGkuy9QaDkbCUvz2C/IssS3fjiT/GNV5GRVEBpmYerMJIKCjZixv7hcKh+8cahV7MFTHN7e6GLtxzl89f/OFBMXQvDqv3azf3cxToeKJMHm9fksvX4Mi85zL6OBTo+//ZIkKcDfgSuBccAtkiSN0zn0LSHElOYfQ+x7kaQohbsusRFi9XjYmBVIiZG5d2lQQP1L4iYmoVh9RVU2K6QvHh+wdjpixZ4zNU8lSSJ1dBSXfyWduQtTDbHvJmXF9brbVVWQlVnutS3ncEWr2IPnSdLlVFnxbpYRAhrgBGKEPxM4KoTIA5Ak6U3gauBwAK5tcJZMTTUxaXgIxdUaQRaJ6NDAT9fIisyih69m3YMf4Wp0IkkSmqox466LiBoZG/D22tOR/YJB9wkNt6J2UBUrYoh3mcj9u4p0s6IUWeLwgdLzvgjNQCYQgp8EFLb5/SQwS+e46yVJmg/kAD8RQhS2P0CSpLuAuwCGx/a+YAx2FFliWFTvVhCKTInm+pe+QXl2CW67k9ixCZiD+i4rQ821EcoKQ/R7SMQQG6MzYsg9UoHaJr3LYlVYtNQ7TGO2KEgyiPb3B0nC3AuZWQaBo6+ydD4GUoUQk4C1wH/0DhJCPCeEmC6EmB4T4V8JNYP+R5Ilho5NIHFaSp+KfQtqro3Q4hV93m5/UHf0FPt//TI7vv0UBe9uRHPqVxc7G+68ZzqjM6IxmWVsNhMWq8JXvjqO8ZPjvI6bOS8Zk05hBCEEE6bE+Ww3GDgEYoR/CmhTlpphnJmcBUAIcbrNry8AfwpAuwYGrXRlvzAYOPnhFnZ+52k0l4pwq5xauZ3cZz9i4epHA5LrHhxi4Qe/vJCqSjt1NQ7iE0OxWH0lIik5gqtvGs/yNw+hKBIgIYTg2z+ahS3ImDsZyARC8HcCaZIkjcAj9DcDt7Y9QJKkBCFEcfOvVwFZAWjXwMCLDbk1LEjr3Kf9XEV1uNh19zMe98qWbQ1N1B4p5Ph/1jL6O0sD1lZkVBCRUZ1nWS28fBTTZiWRdbAMs1lh/OQ4rLbAZ3lnHSzjgzcyKSuuJyLSxtLrxjBzXteVtgz06XFIRwjhBu4B1uAR8reFEIckSfq9JEktxtk/lCTpkCRJ+4EfAt/oabsGBu1ZXLyzU8+dc5mqvUfRW1Ks2h0Uvrep7zsEhEfYmDVvONNmJfWK2GcfKue5p7dTVFiL261xuryRN1/ez6Z1xwPe1vlCQN4lIcQqYFW7bQ+0+f/9wP2BaMvAoDMWF++kUJvpa79wjqMEWTssOWgKteluP9f58K1DuNotGXc2p39eeHGqsajuLDCsFQwGHcmlOwgLy+nvbgSUIZNGYI0O9/EGUoKtjPrmlf3Uq96ltIO1AU12F44mt+4+g84xBN9gUOJeWeDjuXMuI0kS8975LdbYCExhQZhCbMhWMyPvuIKEJTP7u3u9QnSsfhUzi1XplRDS+YDxVzMYtLS1XxgMhI9JZmnWi5R9sR/H6Vpi544nOPnMehUhBFs35LP6w2xqqx0kDAvj2lsnkD624zUtLZ44uUcqCI+wccHsJELDum+h7Why8/nqY+zaWojJJDPvklQuvHhEj8Iuy24Yy8t/3+UV1rFYFC5flm6Ec84SaaAWxbggbbTY/vQT/d0Ngz5CUzVO7cqnMq+c0LhwUuaOwmQLTIqfnof+YOSzVbmsev+I1ypYs0Xhnl/MZVR6tM/xqlvjH09u5fjRSpwOFbPFYzr3/fvmMDrD/0phqlvjTw9+QVlxPS6XZ57BYlUYNymOb/3Qv6cPTRNs/CyP9auPYW90MWbCUK66cRwnjlWx/M1MaqqaCAo2c8XVGVyyeFRALUIGG+Hh4buFENP19hkjfIN+x9noZM3P36W+tA53kwuTzczulzaz+E/XE57YcwfG0OLBvxJXdWusXp7tY3ngcqqseCeLH/16ns85Wzbkczy3stUwzeX0iPWLz+zkkb8t9nsUvX93MRWlDa1iD+B0qBzaX8rJ/BqGpXSdKvv2q/vZsamwtS97d5wiK7OM3zx+KQ//dTFut4aiSIbQ9xAjhm/Q7+x/bRu1p6pxN3lWjbqbXDhqm9jy9GcBuf75sBK3vt7pZYnQlqKTtbrbt20q8HLHbMHpcHOqwP/01tysChw63joIwfGjlV2eX1vT5Kla1qYvQnhuGutXe+oqmEyyIfYBwBB8gz7FUd/EsXVZ5HySSUNZHQAnNuaitRcrITidU4arMTATr4Nd9ENCLUgdjMhj4kJ0t3c4ghd0S1wjo4MwmX2lRFZkH+M1PYpP1mHWsWpQ3Rp5OV3fMAz8xwjpGAQUza1ycscJak5WEZEcxbCZqciK58t8cucJNv5xNZLkWYq/6/lNTLplRoclCgM9u6Tm2giRnK2FUwYTJpPMJYtH8fknx7xGymaLwrLrx+qeM3dhCqcKanzCQEEhZpKG+7+OYfZFw1n9YbbXNknyxPHb+/DoERUTjFvn6USWJYYmhPrdjxacDjeqKgyLbB0MwTcIGPaqRj65710ctfbWWLxtSDBXPnEDsllh4x9Xe5VDBDjw1i6SZ4+gYEued+UsCWLHxGEODqw459c0ETMIBR9gyXVjMZkV1q06SpPdRWR0ENfdOoGxE4fqHj9r3nAy95aQdaAMVW1bKWxWt0b44UNs3H3fXF7+x04aG1xoqsBiVUgbE0NebiWjx0R3er3YuBBGpkdzLPu0l/CbTDKXXjna737U1zl47fm9ZB0oBSAuMYyvf3uaUeayDUaWjkHA2PDYJxRuz0OoZz5TkiKTMm80w2aksu3v63Hb27k7SpB+5QTKj5RQU1jlJfrJc0Yy76eXBSxbp4XVCTMGrecOeFIt3W7NL6tiIQT5edUcPVJBaLiVqTMSzzrHXQjBa8/vYc+2U7jdGkJ4Rvmz5w/nxjYVs/Rosrt446V97N9VjACGRNq49ZtTyRjvn026EILHfrWe0uI61DafP6vNxANPLPIrtDRYMLJ0DHodIQSF2497iT2AUDUKtx4jcdrwDmM0QsDsey5hzS/e89petDufL5/8lIW/CZwxGHjsF1bTuehX7jnKsedW0lRaRfwV0xlx2yJMIeeGaEjd8KWXJInUUZGkjorscbslRXXs2V7kk62zdUMBcxekMCyl45G2LcjMHXfPwOlUcTrcnjmJbjxl5OVWcrq8wUvswTMPsHn9CZZcO6b7L2gQYgj+eYa9uhFJkrAFsOZsWVYx+17bhuigYpLq1kiYPEx3v8lqIvWi0Rx+fw+a2zuWrDpVTu0poPF0PcHR3Y/ldsbi4p2Ypukvyjrxv3Xs/elzqA4naIKKrVkce+ETLl3/JOaw3q3VG2hUt0Z+XhWyIjN8xJBeXbB0aF8pms57rLpVMveWdir4LVgsChZL94uonC5v1J0Lcrs1Sovqun29wYoh+OcJNYWVbHriU2oKPVkPQ1Kiuei+ywlP6tnIrnhfIev/sBLV2bm3ybF1R5j+rXnsevFLNFVDaAKTxUTKvDTiJiSx6/kvdZ8AFLNCQ3ldwAUfPPYLQRR4LcxS7Q723fs8qt3hta2xsJy8l1aT8aNrA96P3iLrYBkv/X0nQhUIwGpV+M5PZ5My0r/3XNMEmiZ0i53oYbYoyLLkbUbJhQAAIABJREFUM8qWZRmztXcrYQ0bHoGet5zFojBidFSvtn0uYQh+H2OvauDg27sp2p2PNdzGuGunknKh/xNTZ4PL7mT1L97DWe9oFdXKvHJW//w9rnvpG5h0ilz4y87nN3Up9miC7JUHueE/dxA3cRjHN2TjdrgZPnskseMSkCSJ2LHxVBdU+jwFaG6V8GE9Dzd0RtuFWVX780BnFKw1OTn10dZzRvBrqpt4/untXhk7jiY3zzy+mUf+trjTOH1jg5O3/3OAvTtOoWmClFGR3HLnFJKSO5/3mDojkeVvZPpslySYNivp7F+MHyQmh5MxLobsw+WtC8hkWcIWbGLWfMM/vwVD8PuQpho7K374Js46B5qqUVdcw5anPqO6oJLJt/SeAVb+5qOeydC2Ay8BqkulYOsxRi7MOOtrtzwxdIWruXBHRHIkU74+22f/+OuncfyLHM9xzf1UrCYylkzE2sv2v2qujbD0HOrq0jFHhHQYmrJEhfVqPwLJzs2FaDoJGUIIDuwuZsaFyTpnefY/+8ctnCqoaR2pnzhaxVN/2MQDTywiPML3vThVUMNb/9lP4fHq1vi92SIjyzKaqnHrt6Z2WVAlEHzrR7NYuyKHzZ+fwOlUmTg1nqtuGk+QUYWrFUPw+5Csj/bhbHB4xTndDjeH3t3N2K9MxhLafdMqf6gvqcWtYyfrdrhbFz+dLdbwIBw19s4PkiQSJg/r9JDQoeEs+ctX2fPKVkozT2EN8zz9pC0e36P++Yt7ZQFhS0GMSSN4+FDqck7RNkagBFsDWlWqt6mrdeB26cXTBQ31HS9my8+rpqSozics43ZrbF6fz5XXnBkc2O0u3n/9INs2FtD+3uJyaqSMiuC7P51NWHjXn2uXU2XjuuPs+LIAWZa58OIU5ixIQVH8XxtqMslcec0YrrzGmKDtCEPw+5DifSfRdL6Eskmh6kQFcRMC/9grhKDkwEndfYpZISa9Z0Wnx183lf3/2+GTX48ECJDNMorFxLQ7LuzyWuFJkSz89ZIe9acnuFcWEJqeyry3f8O6hffirDxzMzRHhDBk4oh+61t3yRgfy5frjvtYHgghOs3IKS+p182Ocbs0igvP2C1kHyrnX3/Z2ho+0aPgeBXrVuVyzc0TOu2rpgmeeXwzhfnVrdd77/Vadm09yT2/uNDvOQSDrjH+kn1IaGyobiaB5tYIitJf/t5TTueWUZlX0UF/wghPGkJV/mnd7Ap/GHftVMZeMwXFasJkM2GymkhfOpH0KycQNyGJsVdP5ap/fC0gJmi9hdAEznrPk1d+TRN1uUW420zaAjjKq9ly62P91MPuM2bCUFJHR/lYHggheOnZndTXOXTPS0wOR9N8Q0Fmi0LKKM/kp9Op8tzT2zsVewChwcbPjuteD0BVNerrnBzaX8qpghqv67mcGkePnObn313Jrq36AxaD7mOM8PuQsddO5eSufK/RsGySiRoV02uCWHrwlK9PTTOupv9v77zD46jO/f85M1vUq2UVW5aL5N4xNrbBDWNsqqkBQkJIuBASSG5uEkJCyu9yQ4CUm0BCCglJILmh12BjgzFgjLEt996Lere6tGXm/P5YedFqZ1WsldXO53n0aLRzZuYc7e47Z973Pd/XzZv3/BNh8/lb53x9ESMvyenS+YUQzLj9IqbePIvGqkaikqLQbDquumbsUQ70TuaD9waeRjeH3t7Ngdd34W32oDtsTL5pJycP1mI2Bbo9pNekZt8p6k+WEDMqLex9MU2fb33P9mKiYuzMXZjVYZC0PTRNcO+3L+IH968JcO2YJtTUuFj75hFuuH1K0HH7d5fi9QQ+FQjhy/CZu9AX/Dy8v7xt4a2QeD0mXo+Bo1VigGlKVr92iA/WHvcJvgks3U/gy+P/v7/spLK8kX07i2lq8jJtVjqXrsgmKnpgrpjuSZTBP4+kjEtj7v1L2PrHjzC9JqZhMnRiOgseuLzHrumMi0C3a3gtZvCNlQ2+AGnLF3zTE+8Tmx5Pcrb1Uvz20B02YtPiOP7+QXb8bRPuRjdCE4y7Ygoz7piLp8HFnhdyydt0HN1hI2f5JCZcO92vs3M+8TZ72PzUB5z6+GjAQjHT62bPC7nYQxgSYbfhrqqFMBt8wzB56uebOH38DC6XgabBJx+c5qYvTGHeopHnfN7aGldQTVjw5eZv2ZjHylsmobdyl+zZUcyaNw4H+eOjYhw88PAiv4HtytOgEPCLn3zEnEtGsPCy0dgdOu+8foj1a44FafiEwuM2WPXqAX9IpaKsge2fFvL9RxarylddRP23zjOjFo4l6+Js6oqqccQ4iUzsGVfOWUbMG0Punz+23tnmi224DQ6+uYuLv73snK5VkHuKLX/4KOAJ5vDqvb4FVNtO0VhZ73/a2P2vrZQfLOkVn/2m36yjIPdU0KpgwNd3UyJsGrLtk5FpEj8xK+z92bm1iFPHz/gNoGmC6TZ4+bk9zJgz7JyzTOwOPch4n6WxwcP373uH+7433681s371MUu5ZFezN2DB1thJKSGlmNtiGJLiwjpWvXaQPduLuf/781m/5ninjf1ZWufYez0mtdXNbP44j4WXje7SeQY7yoffC2i6RnxmUtiNvWmY5G06zoE3dlKTfwYAR7STpQ9fgyPWiebQ0Z027FF269x7KWko/6xwtNflZf9rO3j7my/wzndf4fj6Q8gQ/liAPRbBW8Pl5cjafTRXNwa4lgyXl6IdeVSfruzmqLtGc00T+VtPYVgYtrMYXpOIuAhwfGZo9SgnU392J3pk+DOptm8usDSAuk3j2EHr+EtniI1zkjY8dCppY4OH3z32id+FU1tr7dfXdS0gsycy0s6tX5mB3a6htbIgQoCmCyIidUQby+JxmxTm17BvZ0mQy+hccLsNtm3KDxkfUFijZvgDhKqTFaz5zst+Q7b9mU9InTKMJT++in0vb8dw+WZpptckZXImJbvzg86hO3QyZvjys02vwdoHX6Umr8p/zjMnKyjMPcWcexfijAvOq64PkeIpTYnXa7E4S/iCyglZweX3eoqmMw1oNi1QmbMNkQmRXPXbWzm8ai+F207hHDuanK9fTcq8nkkRjWjHLeHoxqI48CliFpzaG3J/Y6OHH33rXe66fzaTpqZSWRasRyOET3myNbPnZzIqO4nfPraRM5VNSOnTRJKGxOM2zyZpBeBqNsg/XUNktIN6i5tLVIydxgZPwIG6LjBMabkKO+9kNQ/dv4Z7vzNXKWJ2EjXDHyCs/d6rQbPW0r2FvPuD1ynelY/hNvA2ezG9JqV7C0gckxIwy9dsGo7YCMZe6Qvk5W8+SW1BdcA5DZeX0xuP8fIX/8qa775CfVlgJaWkMdZ1UDVdQ7MI3gpNEJXS/cVMzTVNHHxrNzue3UTRjrx2n0Ji0xOgg1mh4TVwRDmYdutsrvjVzVx6z6weM/YA8xePtNSP0XWN7PHduxl2JqWxrsbFU7/YxIXzhxMV40C3fea+cTh0bvzCVMvzCOE7tq3byDCkpSvJ7tBJTIxk5ecmBo1X0wXuZiPIsA9NjyF5SJSlBpBhSOpqXfzu8U/whOGpYTCgDP4AoOxgcbDscAuVR8uCbgSG26A2/wzzvrWUlPFpxA1LYPzVU7nqiVv8q1qLdub5Sw62RRqSiiOlrP3eawEBvBlfnIveZkaqO21MvWVWUHBWaIKI+CjSpnRv7UHp/iJev+s5dj67if2v7OCjR9/hvR++gRHCANicNqbeNrtdOQl3nYt1P3oTT6vx92S1rOzxQ7js6hxsdg1nhE5EhI2oaDtf++7cLi08smLfzuJOtTMMk525RfzgZ0u4dEUOmSPjmXpBOl//3jwuusRamqC2ujkg6NsaK4OvCbhg7jAuWpDFHfdeQEZmHJGRNsaMTSYyym5ZBKWspIH7vjeP4VnxITODTENyaG9Zp8Y52AmLS0cIsRx4AtCBv0gpH2uz3wk8B1wAVAKfk1KeCse1BzumYXJ07f4uH+dt9pA1Pzukjk9UcrTP9REiOCdNibvBRdGOPIZfOBKA5OyhLPvZdex89lMqj5cRlRzDtFtnk3VxNmlTM/nk1+/RWF6PlJIh49K45LvLQpbl6wzSlGx4bE3Ajcnb7KHiSClH393P+CunWh436fqZxAyNI/fpDTSdabRsU3agmI2/WMviH/k0dnqyWlZdjYvROcl848H5VJY3EhFpY/yUoZ2WOG6PyvIOVkG3YHgl5SUNxMY5uebmiVxz88QOj0nPjOt08BZgxpxh/kyfabMymDYrw7/vO3db31ClKYmNc/LAw4v48xNb2L0t+AYmkTQ1daDnBJypamLNG4c5tK+M2DgnS6/MYfqFGR0eN5DotsEXQujAU8BlQAGQK4R4S0p5oFWzrwBnpJTZQohbgMeBz3X32gpfKmXeJ8dD7rdF2C1n6kMnplu2l6Zk3yvbOfD6rpDG3t/WkEHSDEPGpnLZIyuD2qaMT+PaP95OU1UDmk2neLdPZdNV20zGzBFMueVCooeEVsR017vI33oSw+UlY+YIYlLjOHOqwnJshsvLifcPhTT4AFkX+250m5583/LpSJqS4p35NFTU+/tlHtlAbI61pPK5YJqSV/6xh00fncZu0/B6TUaPTeI/vjknLMYeIHt8MmUl9R0GNx1Ovcvuo8hIO8uuGcuqVw91qv2+nSUh942blMKe7cVBTwap6TFEtGQpzZo3nIN7y4IC3IYhGTvB505savSwcf1J9u8uJSEpkkXLxjByTCI11c089tB6mhq9mKaksryR5/60ndLiei6/JjzvZ38gHC6d2cAxKeUJKaUbeAG4tk2ba4FnW7ZfAS4VqgR9t6krriHvk2Oh1SoFzPvPpdgi7Ggtj96aTcMWaefCexZYHrLnxVz2vrQtpDun7fmTczqfsy+EICo5hkNv72Hzk+upOl5OQ3kdx9YdYNU3X6DpTIPlcUU7TvPKl/7G1j98xLZnNvLWvf/Hnue3tvt00Jknh+FzRuGMDS3MprVIM7fGuyqP6JLwFFb/+P2TbN6Qh9dj0tTkxeMxOX64in89swvwrYo9driCN17YzztvHKKizPr/0x7Lrh6Lw6kHuEM0TQT4xDUNoqLtIV037bFi5XiGDI3qVNu2Mg+tue7WyURG2f0rgzVd4HDq3PqVGf42U2emkzU6EUcrqWWHU2fpFTkkJEXS2ODm0YfWs/q1Qxw7VMn2Twt44mcb2fJxHutWHaW5yRtw43O7DNa8eZjmEO7QgUg4XDrDgNYpHwXAnFBtpJReIUQNkAwE5JwJIe4G7gYYkdK50maDmYqjpQhdA4K/SI4YJ5f//AYSMpNIzknh0Fu7qTpRQVJ2ChOunka0RbDUNEwOvL4zWBfHAt1hY+iE9C5r8bjrXRx4bUdAXEEaEk+jm4Nv7ArS3PE0ufno0XeC+rTv1R2kzcjEEesMujnpThs5l3ccZNXtOit+eSNrHniV+pLaoP2mxyDeQpo5XHVxP1hzPCjv3es12bO9mOZmDy/+bTe7txfjdhnouuDdt45w21dmhFS6tCIhKZIbb5/K+jXHOFPZSEJSFJddlUNxYS3rVx/zZeQIn4Z93qlqxk4I/b0zTWkZPF1x3Xhe/PvudnPrhYDx7ZQrHDI0mh8+fikb1p3k5NEq0obFsmjZGFJSP0td1nWN+x6Yx/YthWz7tICICBvzF4/0l0Fcv+Y4tdUufyxASt+irZef20NSSlRQ9pHvnIKSwjpGDhLN/D6VlimlfBp4Gnw1bXu5O32e6JRYy3Q1zaaRs2wiCZm+D3HM0Dhm3XVJh+dz17s6dOOcZeSCHOZ8bVFXugtA9elKNJseFEg2vSYlewqD2hftyLMU8zLcBic/OMyiH1zBez98A2lITK+B0DWGzRzB6CWdU0yMTIxm2SPX8e/7n8fT5PFHG3WnjbHLJ1s+AWSWbkWPa/Zr6J8rTY2hZ5Z7d5T4jT343BaGIfnXX3cxeWZapxZjuZq9PPnoRkqK6nC7fPIGdTXNZGbF88bz+/yzXdOQ1NW4+OOvNvPjny8loY2U8c6thbz+/H6qKhqJiXWwfOU4Fl422v++zJ6fyZED5Wz9JB8hBEJIDAP0lmIoNruGw6Fz/efbF1GLi4/gqhsmtNtGt2nMnp/JbIub3t7txZaBX4DIKOv/l9drEjeI6t2Gw+AXAq3/+8NbXrNqUyCEsAHx+IK3im6QMj6N6JQYagurA1IRNV1j7BXBOikd4YhxYnPacHcixa1oR945ySJEJkcHlTIEQEBMqsVTh9e0LoUrJYbHIDl7KDf8/U7yPz1Bc3UjqZMzSM7p2lNH9NBYrvj1zez8+yZK9vqkmSesnM7YFaEN1KnaBQyxDoN0mvGTU9ixpTDIbx2X4GT/rhLrxVia4PC+8qBgY12ti08+OEXeiWqGjYjjkktH8dF7JyjMr/Xr1Liavbhd8PQTW3C5jKDrmoZk84Y8lreSQN63q4Tn/rTDL9FQX+fmrRcP4PWaLL3Cp7tUcLqG3duK0XUNr8fE7tBITo5kwrRUyorrGTkmkUuWjrLU0g8n0bHWT12GYbJg6SjyTlYHSE3YbBpjxiaTNKRzLqmBQDgMfi6QI4QYhc+w3wLc1qbNW8AdwKfAjcB6KUMt+lZ0FiEElz2yko9/8S7lh0oQAiISopj/n0uJSY3r8vk0XWPa5+ew7ZmNwbICbfA0uKgrru5yicTYtHiGjEul/GBJwNOE7rAx8fqZQe0zZmRa18KNsPmF3uwRdkYvPvciLgBxGQks/EHnZR4yS7eSz2yGjOv6//ksV980kYN7y3C5DAyviaYJbDaNW788g+3tKERqeuATT3lpPb/4yUd43AYej8mBPaV8sPY4drseJEomJVSWNaLrwU9NXq/JmarArKV/v3QgSI/H7TZY++YRlizPRtMEf//9NppbZcl43CZVlU04HDpff2Bep/8fnUFKSXOzF6fTFuReWrw8O0CiAnzxifThcVxw0XAMwxck93pNTEMybnIKd3z1grD2r6/TbYPf4pO/D1iLLy3zr1LK/UKIh4FtUsq3gGeAfwghjgFV+G4KijAQmRjNsp9dR3NNE4bLS1RKjKULpLOMv2oqmk1jy+8/tHQXnUWaElvEuWm8LPrBlWz4+RpK9hb6jFyEndn3LrSMBzjjIrnwngXk/mkDpiGRponNYWPE3DGkT++8L7sn6K7RHzI0moceu5QP1x7n2OFKUtNiWLIim4zMOOx2jR1bC4Nm+RLJ+MmBgfKX/7GXpkaPf8bu9Zp4vWbIxUhCWL+1DqdOThsffkW5ddqq2+WlucmD22VQWRHcxus12fZpAdd+ruNYiqvZy4mjVb76szlJIQutb9mYxxsv7Kex3o3drrPkimyWXzvO337KjDQuu2os7751GN2mYZqSIUOjuftbvpDi7PmZXHDRMCrKGoiKdnSqMMtAIyw+fCnlamB1m9d+3Gq7GbgpHNdSWBMRH74ScmOXTyYhK5kPf7oKT6M7yK8vNEHiqCHnVFjc2+xhyx8/pHRfkc/YO30ZQyMvDi3LnLNsEqmTMjjx4WG8TV4yLxrF0EkZ3bqxhYvu+vPjEyIsjWL2+CEsvGw0H671pdwKzWel7/rGnKBVqkf2l1sudDK8Et0mMLyf7RQCho2IJyUtmr07PnMb2e0aKanRQa6ioWnR5J+qoS3OCBsRkS2LpUJMDDqzynfrxjz+9cwuXzlG6Tvv/Q/OY8SowCfHPduLefFvu/1BbsPwsu7to0hTcmUrv/+KleP87pu4eCcZmXEBnxNd10hN7z+lKsNNnwraKvoOQyekc+NzX6bsQDH7X9lO6d5ChE0D6XMbLXhweUD72qJqzpysIDYtnqQxobMxNv7qPYq2n/Zr2Rhug0+fXE90SixDJ4R2iscNS2T654Nr4fYFjKMR0E1/vhXXfm4ScxdmcXBvGU6nztQL0i014O0OzTJYabNppGbEUFHWgKvZwOHUsdt1vvjVCxiaFsOnH51m4/qTeDwms+YOZ/HlYwKMtKvZy5SZ6RQV1AUssHI4dK68YQKaJoiLj2DYiDjyTlYH3HTsDo25C9tXFi0urOUfT+8IOK6p0cP/PryBX/756oC+rHr1YFBGk9ttsP6dYyxfOS5gRXJ0jIMJU7ou8T0YUAZfERJN10ibMoy0KcOoK6mh4kgpUUnRDJ2Y4c9zN70GH//yXQpzT/lW5hqShKxklv73NUE1epvONFDYytifxXB52ffydpb8uHtZL71J5IZ1NC1YGvbzDk2LYWha+09Scxdk8fH7J/0FxMFn7C+cn8mtX57OgT2l5J2oJmlIJDNmD/NryE+alkr2+CGkpEYHuVF2bSviuT9u9+fsmwIQkJAYyYqV4wJ0+u/8+oX8+n8+prnZi2H4YhGjc5JYssJ6FfdZrLT3AbxeySfrT7Jw2Rj/a1UWbiPwZS81N3mJjlHFUDqDMviKThGbFk9sWnAFpn2v7qAw9zSG2/hMVfNEOZ/+bj0XfHk+ZfuKcMZFkD49k8bKBnS7bqlUWV8S7Dbob/SU0e+Iq2+aSFFhHccPV6JrAtOUZI5K4Mbbp6BpgsnT05g8/bOiLWeqmnjmt1spOF2DpgkiImx84Z4L/LPi6qomnv3DtqAShna7zvf+ZzExbbJhhgyN5uFfL2P/7lLOVDWRNTqRrNEJHbrciguD1z6c5cSxKr/BP7y/HE+IJAJnhB4y5VIRjDL4im5xZPW+oJW+ptck75Pj5H96At1h8+mkO2ws+fGVlnn+QhcMnTQwNE0qDtd2K3PnXLA7dO57YB7FBbUUF9YxNC2G4VnW5RGllPz20Y1UlDX68/DdLoM/P7GF7z+ymJTUGLZbpIqCz/+/K7eQi5cEF3PXdEFUjJ3amuZO690Pz0qgKN9aUnv4CF//C07X8Mf/3WxZAtHh0Ln6pokhg7yKYJTBV3QLryv04iFpys9WwTZ52PD4WibdMIP9r322mle0BG4n3zgw0uMyS7eixS/oEZG1jkgfHkf68PZvNieOVFFT3RykrWN4TT5+/yTX3zaF5iaPpSia4TUD0i/P0tTo4clHN1JWXO8LvgJJyVF8+ycL2q07e+X148n9JD/o5qLpwu8yeu/tIyFvINfdNtny5qMIjZJHVrRLdV4VHz6ympe/+FdW/eeL5H0aKNQ2bGaWT/e2E7hqmxk2exRz71tMQlYyEQmRjJg3hit+ffM5rRvoq5hHNhAbe6S3u2FJTXUzYK0tX9mSgjlpaqqleJuma0ycGpw6++o/91JUUIvLZeBxm3jcJqXF9fzwm2spyg/ttklOiebOr81Ct2n+WIHdoXHvt+f6ffIlRXWWTxsRkTaGjTj3Iu+DFTXDH8TU5FdRV1JLQlYSMUODDW5NfhXvfPtl3yxeQvOZRjb+6j1m3lHP+KunATDzznkU7863TN9si9B8AdpRi8YxalH3Fkr1dbyr8oi9krApa4aLrNEJGBYL2RwO3a9JkzUmkRmzM9iZW+RP23Q4deZcMoKMzODPyfbNBQGpn2dxuwyefHQjP31yecgUzZkXDWfS9DSOHChH0wRjJ6Zgb5V2OnJMEsUFdUFPJF6v2WEwWxGMMviDEE+jmw9++jYVh8vQbBqGxyBr/hjm/efSALmE3f+3Ba/LG5Bnbbi87PrnFnKWT0a360SnxHL54zew8X/fo+poB0UoJF0WW5NScuit3ex/dQeuumYSRw1h1l2XhJR37ku8vSOVhaGXF/QKySnRzJ6fybZNBf40R90miI13Mudin1qmEILb757JjDnDyP0kH6EJ5lw8gvGTrdNtjXakl91ug4N7Spky0/r9Ki+t5+1XDnL4QDmxsU4uvTKbOReP8Ad8L7sqh22fFuBq/syV5HDozFuUFRQ8VnSMMviDCHe9i2PrDnDo33torKhHmhKjRek3b9MJEkbsYPJNs/ztyw+XWpYukqaksaKe2PR4qk5W8O6Dr2F4QitsCk2g2XTmfvNS9C7qvO/652YOvrnb7/OvPFrGuh+/yeWPXU9ydt/OtV5enIse032Rta5ScLqawwcqiI62M+3CjCChtVvunM6o7CQ+eu8Ezc1eZlyYwWVX5fjTNcFn9Ntm94RiwpSh7N9VGnJ/fb21nHRVRSOP/+hDXM1epIT6WjcvPbuHitIGrrrRV4BlyNBovvOTBbz+/D6OH6kiKtrOkuVjAlI2FZ1HGfxBQn1pLav/6yU8zR5Md3AQzHB7OfjWHupKa6k8UkZ8ZiLO2AgaK+qD2pqGibNlZe+nT7yPp9HiCy18hj4uI4GMWVmMvXxSl3V3vM2eAGPfuq97XtjK4h/2/bx942gEFbXnJ3NHSsk/nt7Bzq1FmKaJrmu8/I+9fOHumWzfXMCBPWXY7RrzFo1kxXXjOlwY1Vlu/uJUHj38gWVA1zQl2eOsax2/9/ZR3O5AETe3y+D91ce49Moc/40qfXgcX/tueDV5BivK4A8Stv5pA+56V7sFvpurGzn+3kGkKTlzqhLNJtDa5M3rDhtZl2TjiHLgaXRz5lSF5bl0h42rf3cbsWnnbugaKuqtc7klnDlhfd2+SLjklDtiV24Ru3KL/GJnRosq6V+e3OrTz5HgaoYP1hyj4HR12Ixocko0//2ry3j8xx9ypqoJ2RIiOOv3P6tpL6XkxJEqKisaGTEygeNHKjGtNOptGqWDSKP+fKIM/iCheFd+u8b+LP42UmJ6JI5YJzhtvkVVUjJq4Vhm37sQoKX4isBKTMUR5eiWsQdfXV1pWgeC4zL7lzHoKfmF1mz68HTIIiStZ9Eej8nRQ5UU5ddaBmHPhehYJz96fCmbPjrNtk35aJpg3uKRft36uhoXv/nZx1RVNPluPqYkMjq0Rn1Ccvi0oRSfoQz+IEGzaZYrXIGgWXxr3HUurvr9bTgi7DhiI7C3Usi0OW1kzBxB0Y68AAlj3WEje1nHRbA7wh7pIGf5ZI6u3R/g1tEdNqbdemG3z3+++ehoDQtzei6VsDM39LNomqAwvyauqWvKAAAPjUlEQVRsBh98C8BSUqM5U9VEQ52bUyd2sXtbMV+4eya/eeRjSosD3YOy3uOTbWjVb5tdY8LkoSQkKoPfE6g8/EHC6MXj0NoGTAVEJkYx6foZOONCF6c4se4g0SmxAcb+LHO/sYS4jHhskXZsETZ0p42UiWlM+Vx4DPIFX57PpOtnYI9ygIC4YQkseugKUsb3/SydtiwvziVyw7oeO//sS0YE1HttDyklKanhTWsszK/hz09spbqqGY/HxPCaHNhdyi//+6MgYw++mXxUtJ24eCd2u4bNpjF9VgZf+tosi7MrwoGa4Q8SZt45nzOnKqk6Xu73i8dnJrL0f67FEe2k6UwDx949aHlsZTvplpEJUVz91G2U7iukvrSWxJFDOpU9Y3gM8jefoGRvIdEpMYy5dAJRSdFB7TRdY9ptc5h662ykKc+pylZfo6fkF2bNHc6OzQUcOViB22Vgs2u+JVZCBBQx0W0aaRmxZI1OCOv1168+FrRC1+s1KS0KNvZnkRJ++uRyaqubiYyyB2QKKcKP+u8OEuwRdpY/fgOVR0upPl1F3PBEhoxL9Rv/idfN5Pi6Q0FuAaFrJI5MbvfcQgjSpgyHTlZV9DS5/YXDvc0eNLvOvpe2cen/uyakpo4QAmFRpak/0lPyC5omuOe/LuLooQoO7ysnOsbBrLnDqa1x8a9ndlJwugahCaZdkM4td04Lez2B8tKGoAVSgD9gbEXOhGQ0TQTV0VX0DMrgDzKSc1Ita77GD08kfXomJXsLA7Ny7Drjr5ke1j4ceGMXtYXV/uuYHgPTAx//8l2u/+sdfaKwSU9jHtlANOE3+kIIxk5IYWyrylVxCRE88PAi3G4DXRPonShMci5kjx9C3slqS21+oeHP3mnN9Z/veu1lxbnT/5+PFWFj4fdXMGbJeHSHDgKSslNY9rOV3c62OcuZ05Wsf/ht9jyfaxkkdtU1U1dUHZZrKYJxOPQuGfvmJg/r1xzjqZ9v4l/P7KQwv30J60WXj8YZYUNrdQmHU2fOxSOIirIHvK5pgus/P5mk5MFTQLwvIPpqLfELcrLllt/8ore7MeBoqKhn70vbKNmV7wvY3jCT4bMDFQel6asdq9m6tiq2PWoKzrD6Wy/5dXms0B061/zh85a6PgMV25Uj+pzeDkBjg5vHf/ghtbXNeNy+oia6TeOOr85k+oXDQh5XVdHIqlcPcmBvWcuq2GzmLcqi5kwz7759hMP7y0lIjGTplTmqKlUPERcXt11KaRn5Vi6dQURjZT1vf+MFPI0upCGpK66h8vhapt9+ERNXfua2EZpAaOEz9gB7X8j16eaHml8IiM1IGFTGHs5dZK2pyUPBqRpi45ykDQt/jdZ1q45RU93sd8+YpsR0G/zrmV1MmZkeUFKwNUlDovjCPcFS1wlJkdz8xWlh76eiayiDP4jY/+oOvI1uZKvVjYbLy+5/bmbs8knYLNIuw0X54ZKQeeK604Y9ysHC76/osev3Zboqsvbev4+w+vVD6DYNw5CkZcRy73cuIi4+dGptV9mzo9jSF28YJiVFdQzLVNLE/RHlwx9EFO8uwLSQxhW6Rk3BmR69dmy6tYEQuuCi+xdzw1/vIC4jvGmC/YXlxbnEFL/dqbb7d5XwzpuH8Xh8xUg8boPCvBqe/s2WsPYpMtJ6LmgaMkiMTdF/UAZ/EBE9xHqhjekxiEzs2eDZlM9diO4MNCK6w8bIBWMZvXBcWOMF/RHjaAQVh0MXCznL+jXHg+QTTFNSeLqGirKGsPVn8fLsoEVcQoOMzDiShqhAa39FGfxBxKQbZgYZXc2mMXRyBlHJPVtMInVSBvO/tZTIxCg0u47u0Bm9ZBxz71/So9ftT2SWbu1wpl9X67J8XdM1GhtCl5vsKjNmZ7Bg6Shsdo2ISBtOp05qeiz/8c05YbuG4vyjfPiDiLSpw7nw7gVsf2YjUkpMr0na1OFc8t1l5+X6WfOzGTF3DM21TTiiHOgO9fFrS0cia5Onp1FWXG/pX08PY/BWCMHKWyazZEU2p4+fIS4hghGjEgbFGomBTLe+cUKIJOBFYCRwCrhZShnkDBZCGMDelj/zpJTXdOe6inMnZ9lERi8eR11RNc64yB535bRFaILIBOUSaI/2RNaWrMhm6yd51Ne58Xp8Rt/u0LnxC1MCSgO2pby0nvLSBtKHxZLYhdz3uPiIkNWqFP2PbuXhCyF+DlRJKR8TQjwIJEopv2fRrl5K2SWfgcrDVwx2mhYstXy9od7NhnUn2L+rlMTkSBZfPobRY63lL1zNXv7y5FaOHapAt2l4vSYzZmdw+3/MDJlaqejf9GQe/rXAopbtZ4EPgSCDr1Aouk4okbXoGAcrVo5nxcrxHZ7j5X/s4eihCrweE0/LE8Hu3GJS04+y/NqBXUheEUx3b/GpUsrilu0SIFSF6gghxDYhxGYhxMpQJxNC3N3SbltFTccZCwrFQCazdGu3jjcMk22bCvyun7O43QYb1p3o1rkV/ZMOZ/hCiHWAVSXjh1r/IaWUQohQ/qEsKWWhEGI0sF4IsVdKebxtIynl08DT4HPpdNh7hWKA052iKYbXtFSvBCzrz4abvJPVrP33EcqK6sganciya8YyNK1ns8EU7dOhwZdSWjsSASFEqRAiXUpZLIRIByyF06WUhS2/TwghPgRmAEEGX6FQBLK8OBfbzHPT23E4baRmxFBcUBfwuhAwbmJKiKPCw8G9ZTz9my14Pb4i5aXFdezcWsh//WSBWqXbi3TXpfMWcEfL9h3Am20bCCEShRDOlu0hwHzgQDevq1AMGryr8oiNPXJOx9765Rk4nDqa5kun1G2+vPqVt04OZxcDkFLy4t9343Ebfh180wSXy+CN5/f12HUVHdPdoO1jwEtCiK8Ap4GbAYQQs4CvSinvAiYAfxJCmPhuMI9JKZXBVyi6wLmKrI3OSeL7jyzmgzXHKSqoZVR2EguXje7RmrFul0FVRaPlvhNHqnrsuoqO6ZbBl1JWApdavL4NuKtlexOdroWkUChC4V2VBwu67tpJSY3h5jvOn1Klza6h68IyfhAdE96CL4quoRJxFYp+RGdF1noTXde4aGEWdnugeXE4dJZckd1LvVKAMvgKRb+isyJrvc31t01m6qwMvxaP3a5xydJRLLxsdG93bVCjxEwUin5GZulW8pltuSirr2C369z5tVnU1bioqmwkJTWaqGjlzult1AxfoeiHZJZuJbrE3dvd6JDYeCdZoxOVse8jKIOvUPRTVtc19XYXFP0MZfAVin7K8uLcfjHLV/QdlMFXKPox5pENvd0FRT9CGXyFop8TuWGdmukrOoUy+ArFAED58xWdQRl8hWIAsLw495z1dhSDB2XwFYoBQndE1hSDA2XwFYoBhHdVXr+QX1D0DsrgKxQDDONoRG93QdFHUQZfoRiA9Ae9HcX5Rxl8hWIAklm6VRl9RRDK4CsUCsUgQRl8hWKAklm6lY+O1vR2NxR9CGXwFYoBzPLiXGX0FX6UwVcoBjhqUZbiLMrgKxSDAO+qvN7ugqIPoAy+QjFIUCJrCmXwFYpBhJJTHtwog69QDDKU9MLgRRl8hWKQYRyNUEHcQYoy+ArFIESJrA1OumXwhRA3CSH2CyFMIcSsdtotF0IcFkIcE0I82J1rKhSK8GAcjVBB3EFGd2f4+4DrgZCRICGEDjwFrAAmArcKISZ287oKhSIMnK5p7u0uKM4j3TL4UsqDUsrDHTSbDRyTUp6QUrqBF4Bru3NdhUIRHpTI2uDifPjwhwH5rf4uaHktCCHE3UKIbUKIbRU16kOoUCgU4aRDgy+EWCeE2GfxE/ZZupTyaSnlLCnlrCHxceE+vUKhsECJrA0ebB01kFIu7eY1CoHMVn8Pb3lNoVD0EZYX57KGC1mYE9/bXVH0IOfDpZML5AghRgkhHMAtwFvn4boKhaILKJG1gU930zKvE0IUAHOBVUKItS2vZwghVgNIKb3AfcBa4CDwkpRyf/e6rVAoegIlsjawEVLK3u6DJUKIcuB0q5eGABW91J2eZiCPDdT4+jMDeWwwMMeXJaVMsdrRZw1+W4QQ26SUIRd39WcG8thAja8/M5DHBgN/fG1R0goKhUIxSFAGX6FQKAYJ/cngP93bHehBBvLYQI2vPzOQxwYDf3wB9BsfvkKhUCi6R3+a4SsUCoWiGyiDr1AoFIOEPmvwB7LWvhAiSQjxnhDiaMvvxBDtDCHErpafPr86uaP3QgjhFEK82LJ/ixBi5Pnv5bnRibF9SQhR3ur9uqs3+nkuCCH+KoQoE0LsC7FfCCGebBn7HiHEzPPdx+7QifEtEkLUtHrvfny++3jekFL2yR9gAjAO+BCYFaKNDhwHRgMOYDcwsbf73omx/Rx4sGX7QeDxEO3qe7uvXRhTh+8F8DXgjy3btwAv9na/wzi2LwG/6+2+nuP4FgAzgX0h9l8BvAMI4CJgS2/3OczjWwS83dv9PB8/fXaGLwe21v61wLMt288CK3uxL+GiM+9F63G/AlwqhBDnsY/nSn/9nHUKKeUGoKqdJtcCz0kfm4EEIUT6+eld9+nE+AYNfdbgd5JOa+33MVKllMUt2yVAaoh2ES31ATYLIfr6TaEz74W/jfRpLNUAyeeld92js5+zG1pcHq8IITIt9vdX+uv3rCvMFULsFkK8I4SY1Nud6Sk6lEfuSYQQ64A0i10PSSnfPN/9CSftja31H1JKKYQIlRubJaUsFEKMBtYLIfZKKY+Hu6+KsPBv4HkppUsIcQ++J5klvdwnRefYge+7Vi+EuAJ4A8jp5T71CL1q8OUA1tpvb2xCiFIhRLqUsrjl0bgsxDkKW36fEEJ8CMzA50vui3TmvTjbpkAIYQPigcrz071u0eHYpJStx/EXfHGagUKf/Z6FAyllbavt1UKI3wshhkgpB5qoWr936fRXrf23gDtatu8Agp5mhBCJQghny/YQYD5w4Lz1sOt05r1oPe4bgfWyJWrWx+lwbG182tfgkwIfKLwFfLElW+cioKaVS7LfI4RIOxtLEkLMxmcX+8NEpOv0dtQ41A9wHT5foQsoBda2vJ4BrG7V7grgCL6Z70O93e9Oji0ZeB84CqwDklpenwX8pWV7HrAXX0bIXuArvd3vTowr6L0AHgauadmOAF4GjgFbgdG93ecwju1RYH/L+/UBML63+9yFsT0PFAOelu/cV4CvAl9t2S+Ap1rGvpcQWXN99acT47uv1Xu3GZjX233uqR8lraBQKBSDhP7u0lEoFApFJ1EGX6FQKAYJyuArFArFIEEZfIVCoRgkKIOvUCgUgwRl8BUKhWKQoAy+QqFQDBL+P7QytbBrd/GmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xca5c1ayata8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3264a720-3ba4-4b41-e114-a622b2c5baa9"
      },
      "source": [
        "# MODEL 2 here - NEURAL NET CLASS\n",
        "\n",
        "n0_2 = 2# input layer dimensionality\n",
        "n1_2 = 280# hiden layer dimensionality\n",
        "n2_2 = 2# output layer dimensionality\n",
        "alpha_2 = .006# learning rate for gradient descent\n",
        "epochs_2 = 800 # number of iteration/epochs\n",
        "\n",
        "# Build a model with 3 layers\n",
        "myModel2 = MyNeuralNet(n0_2, n1_2, n2_2, alpha_2);\n",
        "myModel2.fit(X_train, y_train, epochs_2, X_val, y_val)\n",
        "print(\"Accuracy on the test set is \", myModel2.evaluate(X_test, y_test))\n",
        "\n",
        "# Plot the decision boundary\n",
        "myModel2.plot_decision_boundary(X_test, y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/800 - loss: 1695.176917 - accuracy: 0.490278 - val_loss: 159.798916 - val_accuracy: 0.587500\n",
            "Epoch 10/800 - loss: 485.962679 - accuracy: 0.490278 - val_loss: 51.803771 - val_accuracy: 0.512500\n",
            "Epoch 20/800 - loss: 473.769458 - accuracy: 0.490278 - val_loss: 51.507358 - val_accuracy: 0.525000\n",
            "Epoch 30/800 - loss: 464.521623 - accuracy: 0.493056 - val_loss: 50.660173 - val_accuracy: 0.525000\n",
            "Epoch 40/800 - loss: 456.218326 - accuracy: 0.501389 - val_loss: 49.905704 - val_accuracy: 0.525000\n",
            "Epoch 50/800 - loss: 448.712021 - accuracy: 0.502778 - val_loss: 49.231464 - val_accuracy: 0.525000\n",
            "Epoch 60/800 - loss: 441.875575 - accuracy: 0.508333 - val_loss: 48.622508 - val_accuracy: 0.537500\n",
            "Epoch 70/800 - loss: 435.600945 - accuracy: 0.522222 - val_loss: 48.066365 - val_accuracy: 0.550000\n",
            "Epoch 80/800 - loss: 429.797355 - accuracy: 0.561111 - val_loss: 47.552789 - val_accuracy: 0.562500\n",
            "Epoch 90/800 - loss: 424.389220 - accuracy: 0.625000 - val_loss: 47.073468 - val_accuracy: 0.662500\n",
            "Epoch 100/800 - loss: 419.314043 - accuracy: 0.670833 - val_loss: 46.621723 - val_accuracy: 0.712500\n",
            "Epoch 110/800 - loss: 414.520422 - accuracy: 0.708333 - val_loss: 46.192240 - val_accuracy: 0.750000\n",
            "Epoch 120/800 - loss: 409.966232 - accuracy: 0.733333 - val_loss: 45.780823 - val_accuracy: 0.787500\n",
            "Epoch 130/800 - loss: 405.617043 - accuracy: 0.743056 - val_loss: 45.384180 - val_accuracy: 0.812500\n",
            "Epoch 140/800 - loss: 401.444744 - accuracy: 0.761111 - val_loss: 44.999750 - val_accuracy: 0.825000\n",
            "Epoch 150/800 - loss: 397.426396 - accuracy: 0.787500 - val_loss: 44.625548 - val_accuracy: 0.825000\n",
            "Epoch 160/800 - loss: 393.543262 - accuracy: 0.811111 - val_loss: 44.260051 - val_accuracy: 0.837500\n",
            "Epoch 170/800 - loss: 389.780015 - accuracy: 0.823611 - val_loss: 43.902090 - val_accuracy: 0.850000\n",
            "Epoch 180/800 - loss: 386.124089 - accuracy: 0.836111 - val_loss: 43.550781 - val_accuracy: 0.862500\n",
            "Epoch 190/800 - loss: 382.565142 - accuracy: 0.854167 - val_loss: 43.205453 - val_accuracy: 0.862500\n",
            "Epoch 200/800 - loss: 379.094628 - accuracy: 0.872222 - val_loss: 42.865603 - val_accuracy: 0.862500\n",
            "Epoch 210/800 - loss: 375.705453 - accuracy: 0.881944 - val_loss: 42.530857 - val_accuracy: 0.862500\n",
            "Epoch 220/800 - loss: 372.391687 - accuracy: 0.890278 - val_loss: 42.200935 - val_accuracy: 0.887500\n",
            "Epoch 230/800 - loss: 369.148344 - accuracy: 0.897222 - val_loss: 41.875630 - val_accuracy: 0.887500\n",
            "Epoch 240/800 - loss: 365.971199 - accuracy: 0.905556 - val_loss: 41.554789 - val_accuracy: 0.900000\n",
            "Epoch 250/800 - loss: 362.856641 - accuracy: 0.912500 - val_loss: 41.238299 - val_accuracy: 0.912500\n",
            "Epoch 260/800 - loss: 359.801560 - accuracy: 0.925000 - val_loss: 40.926075 - val_accuracy: 0.912500\n",
            "Epoch 270/800 - loss: 356.803247 - accuracy: 0.929167 - val_loss: 40.618051 - val_accuracy: 0.912500\n",
            "Epoch 280/800 - loss: 353.859327 - accuracy: 0.937500 - val_loss: 40.314176 - val_accuracy: 0.925000\n",
            "Epoch 290/800 - loss: 350.967691 - accuracy: 0.938889 - val_loss: 40.014406 - val_accuracy: 0.925000\n",
            "Epoch 300/800 - loss: 348.126453 - accuracy: 0.943056 - val_loss: 39.718704 - val_accuracy: 0.925000\n",
            "Epoch 310/800 - loss: 345.333910 - accuracy: 0.945833 - val_loss: 39.427035 - val_accuracy: 0.937500\n",
            "Epoch 320/800 - loss: 342.588509 - accuracy: 0.947222 - val_loss: 39.139367 - val_accuracy: 0.937500\n",
            "Epoch 330/800 - loss: 339.888825 - accuracy: 0.950000 - val_loss: 38.855664 - val_accuracy: 0.937500\n",
            "Epoch 340/800 - loss: 337.233537 - accuracy: 0.952778 - val_loss: 38.575891 - val_accuracy: 0.937500\n",
            "Epoch 350/800 - loss: 334.621415 - accuracy: 0.955556 - val_loss: 38.300013 - val_accuracy: 0.950000\n",
            "Epoch 360/800 - loss: 332.051305 - accuracy: 0.956944 - val_loss: 38.027991 - val_accuracy: 0.950000\n",
            "Epoch 370/800 - loss: 329.522121 - accuracy: 0.961111 - val_loss: 37.759783 - val_accuracy: 0.950000\n",
            "Epoch 380/800 - loss: 327.032830 - accuracy: 0.962500 - val_loss: 37.495348 - val_accuracy: 0.950000\n",
            "Epoch 390/800 - loss: 324.582454 - accuracy: 0.962500 - val_loss: 37.234641 - val_accuracy: 0.950000\n",
            "Epoch 400/800 - loss: 322.170054 - accuracy: 0.963889 - val_loss: 36.977616 - val_accuracy: 0.950000\n",
            "Epoch 410/800 - loss: 319.794736 - accuracy: 0.962500 - val_loss: 36.724224 - val_accuracy: 0.962500\n",
            "Epoch 420/800 - loss: 317.455637 - accuracy: 0.962500 - val_loss: 36.474416 - val_accuracy: 0.962500\n",
            "Epoch 430/800 - loss: 315.151929 - accuracy: 0.962500 - val_loss: 36.228142 - val_accuracy: 0.962500\n",
            "Epoch 440/800 - loss: 312.882812 - accuracy: 0.962500 - val_loss: 35.985350 - val_accuracy: 0.962500\n",
            "Epoch 450/800 - loss: 310.647515 - accuracy: 0.963889 - val_loss: 35.745987 - val_accuracy: 0.962500\n",
            "Epoch 460/800 - loss: 308.445291 - accuracy: 0.963889 - val_loss: 35.510000 - val_accuracy: 0.975000\n",
            "Epoch 470/800 - loss: 306.275417 - accuracy: 0.963889 - val_loss: 35.277336 - val_accuracy: 0.962500\n",
            "Epoch 480/800 - loss: 304.137192 - accuracy: 0.965278 - val_loss: 35.047941 - val_accuracy: 0.962500\n",
            "Epoch 490/800 - loss: 302.029935 - accuracy: 0.966667 - val_loss: 34.821761 - val_accuracy: 0.962500\n",
            "Epoch 500/800 - loss: 299.952988 - accuracy: 0.966667 - val_loss: 34.598741 - val_accuracy: 0.962500\n",
            "Epoch 510/800 - loss: 297.905708 - accuracy: 0.966667 - val_loss: 34.378828 - val_accuracy: 0.962500\n",
            "Epoch 520/800 - loss: 295.887472 - accuracy: 0.966667 - val_loss: 34.161968 - val_accuracy: 0.962500\n",
            "Epoch 530/800 - loss: 293.897675 - accuracy: 0.966667 - val_loss: 33.948109 - val_accuracy: 0.975000\n",
            "Epoch 540/800 - loss: 291.935727 - accuracy: 0.966667 - val_loss: 33.737196 - val_accuracy: 0.975000\n",
            "Epoch 550/800 - loss: 290.001055 - accuracy: 0.968056 - val_loss: 33.529177 - val_accuracy: 0.975000\n",
            "Epoch 560/800 - loss: 288.093099 - accuracy: 0.968056 - val_loss: 33.324002 - val_accuracy: 0.975000\n",
            "Epoch 570/800 - loss: 286.211318 - accuracy: 0.969444 - val_loss: 33.121618 - val_accuracy: 0.975000\n",
            "Epoch 580/800 - loss: 284.355180 - accuracy: 0.969444 - val_loss: 32.921975 - val_accuracy: 0.975000\n",
            "Epoch 590/800 - loss: 282.524171 - accuracy: 0.969444 - val_loss: 32.725024 - val_accuracy: 0.975000\n",
            "Epoch 600/800 - loss: 280.717789 - accuracy: 0.968056 - val_loss: 32.530715 - val_accuracy: 0.975000\n",
            "Epoch 610/800 - loss: 278.935544 - accuracy: 0.968056 - val_loss: 32.338999 - val_accuracy: 0.975000\n",
            "Epoch 620/800 - loss: 277.176958 - accuracy: 0.969444 - val_loss: 32.149831 - val_accuracy: 0.975000\n",
            "Epoch 630/800 - loss: 275.441568 - accuracy: 0.969444 - val_loss: 31.963161 - val_accuracy: 0.975000\n",
            "Epoch 640/800 - loss: 273.728919 - accuracy: 0.970833 - val_loss: 31.778946 - val_accuracy: 0.975000\n",
            "Epoch 650/800 - loss: 272.038570 - accuracy: 0.970833 - val_loss: 31.597140 - val_accuracy: 0.975000\n",
            "Epoch 660/800 - loss: 270.370090 - accuracy: 0.970833 - val_loss: 31.417698 - val_accuracy: 0.975000\n",
            "Epoch 670/800 - loss: 268.723059 - accuracy: 0.970833 - val_loss: 31.240578 - val_accuracy: 0.975000\n",
            "Epoch 680/800 - loss: 267.097066 - accuracy: 0.970833 - val_loss: 31.065737 - val_accuracy: 0.975000\n",
            "Epoch 690/800 - loss: 265.491712 - accuracy: 0.970833 - val_loss: 30.893133 - val_accuracy: 0.975000\n",
            "Epoch 700/800 - loss: 263.906607 - accuracy: 0.972222 - val_loss: 30.722725 - val_accuracy: 0.975000\n",
            "Epoch 710/800 - loss: 262.341370 - accuracy: 0.972222 - val_loss: 30.554473 - val_accuracy: 0.975000\n",
            "Epoch 720/800 - loss: 260.795629 - accuracy: 0.972222 - val_loss: 30.388339 - val_accuracy: 0.975000\n",
            "Epoch 730/800 - loss: 259.269022 - accuracy: 0.972222 - val_loss: 30.224284 - val_accuracy: 0.975000\n",
            "Epoch 740/800 - loss: 257.761195 - accuracy: 0.972222 - val_loss: 30.062269 - val_accuracy: 0.975000\n",
            "Epoch 750/800 - loss: 256.271803 - accuracy: 0.972222 - val_loss: 29.902260 - val_accuracy: 0.975000\n",
            "Epoch 760/800 - loss: 254.800508 - accuracy: 0.972222 - val_loss: 29.744218 - val_accuracy: 0.975000\n",
            "Epoch 770/800 - loss: 253.346981 - accuracy: 0.972222 - val_loss: 29.588110 - val_accuracy: 0.975000\n",
            "Epoch 780/800 - loss: 251.910901 - accuracy: 0.972222 - val_loss: 29.433900 - val_accuracy: 0.975000\n",
            "Epoch 790/800 - loss: 250.491954 - accuracy: 0.972222 - val_loss: 29.281556 - val_accuracy: 0.975000\n",
            "Accuracy on the test set is  0.97\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WT7kZ4VazUL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52a7b884-4d4a-44e8-988f-068fc64beed1"
      },
      "source": [
        "# MODEL 3 here - NEURAL NET CLASS\n",
        "\n",
        "n0_3 = 2# input layer dimensionality\n",
        "n1_3 = 500# hiden layer dimensionality\n",
        "n2_3 = 2# output layer dimensionality\n",
        "alpha_3 = .004# learning rate for gradient descent\n",
        "epochs_3 = 800 # number of iteration/epochs\n",
        "\n",
        "# Build a model with 3 layers\n",
        "myModel3 = MyNeuralNet(n0_3, n1_3, n2_3, alpha_3);\n",
        "myModel3.fit(X_train, y_train, epochs_3, X_val, y_val)\n",
        "print(\"Accuracy on the test set is \", myModel3.evaluate(X_test, y_test))\n",
        "\n",
        "# Plot the decision boundary\n",
        "myModel3.plot_decision_boundary(X_test, y_test)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/800 - loss: 1080.696623 - accuracy: 0.486111 - val_loss: 96.645485 - val_accuracy: 0.587500\n",
            "Epoch 10/800 - loss: 583.258137 - accuracy: 0.476389 - val_loss: 60.757053 - val_accuracy: 0.537500\n",
            "Epoch 20/800 - loss: 542.794717 - accuracy: 0.480556 - val_loss: 57.341651 - val_accuracy: 0.537500\n",
            "Epoch 30/800 - loss: 510.417227 - accuracy: 0.498611 - val_loss: 54.492034 - val_accuracy: 0.537500\n",
            "Epoch 40/800 - loss: 484.699851 - accuracy: 0.540278 - val_loss: 52.206677 - val_accuracy: 0.562500\n",
            "Epoch 50/800 - loss: 464.278692 - accuracy: 0.570833 - val_loss: 50.381351 - val_accuracy: 0.587500\n",
            "Epoch 60/800 - loss: 447.969863 - accuracy: 0.609722 - val_loss: 48.920585 - val_accuracy: 0.612500\n",
            "Epoch 70/800 - loss: 434.811075 - accuracy: 0.627778 - val_loss: 47.743369 - val_accuracy: 0.637500\n",
            "Epoch 80/800 - loss: 424.049673 - accuracy: 0.644444 - val_loss: 46.783997 - val_accuracy: 0.675000\n",
            "Epoch 90/800 - loss: 415.109539 - accuracy: 0.673611 - val_loss: 45.990657 - val_accuracy: 0.675000\n",
            "Epoch 100/800 - loss: 407.554684 - accuracy: 0.713889 - val_loss: 45.323215 - val_accuracy: 0.687500\n",
            "Epoch 110/800 - loss: 401.056927 - accuracy: 0.777778 - val_loss: 44.750940 - val_accuracy: 0.712500\n",
            "Epoch 120/800 - loss: 395.369707 - accuracy: 0.862500 - val_loss: 44.250495 - val_accuracy: 0.787500\n",
            "Epoch 130/800 - loss: 390.307747 - accuracy: 0.887500 - val_loss: 43.804254 - val_accuracy: 0.887500\n",
            "Epoch 140/800 - loss: 385.731634 - accuracy: 0.895833 - val_loss: 43.398971 - val_accuracy: 0.887500\n",
            "Epoch 150/800 - loss: 381.536237 - accuracy: 0.912500 - val_loss: 43.024724 - val_accuracy: 0.887500\n",
            "Epoch 160/800 - loss: 377.642074 - accuracy: 0.916667 - val_loss: 42.674109 - val_accuracy: 0.900000\n",
            "Epoch 170/800 - loss: 373.988868 - accuracy: 0.920833 - val_loss: 42.341620 - val_accuracy: 0.900000\n",
            "Epoch 180/800 - loss: 370.530758 - accuracy: 0.922222 - val_loss: 42.023172 - val_accuracy: 0.900000\n",
            "Epoch 190/800 - loss: 367.232721 - accuracy: 0.925000 - val_loss: 41.715753 - val_accuracy: 0.900000\n",
            "Epoch 200/800 - loss: 364.067907 - accuracy: 0.927778 - val_loss: 41.417142 - val_accuracy: 0.900000\n",
            "Epoch 210/800 - loss: 361.015635 - accuracy: 0.930556 - val_loss: 41.125719 - val_accuracy: 0.900000\n",
            "Epoch 220/800 - loss: 358.059903 - accuracy: 0.933333 - val_loss: 40.840301 - val_accuracy: 0.900000\n",
            "Epoch 230/800 - loss: 355.188256 - accuracy: 0.934722 - val_loss: 40.560034 - val_accuracy: 0.912500\n",
            "Epoch 240/800 - loss: 352.390941 - accuracy: 0.934722 - val_loss: 40.284303 - val_accuracy: 0.925000\n",
            "Epoch 250/800 - loss: 349.660269 - accuracy: 0.934722 - val_loss: 40.012672 - val_accuracy: 0.925000\n",
            "Epoch 260/800 - loss: 346.990126 - accuracy: 0.934722 - val_loss: 39.744833 - val_accuracy: 0.912500\n",
            "Epoch 270/800 - loss: 344.375607 - accuracy: 0.936111 - val_loss: 39.480569 - val_accuracy: 0.912500\n",
            "Epoch 280/800 - loss: 341.812742 - accuracy: 0.938889 - val_loss: 39.219732 - val_accuracy: 0.912500\n",
            "Epoch 290/800 - loss: 339.298274 - accuracy: 0.940278 - val_loss: 38.962219 - val_accuracy: 0.912500\n",
            "Epoch 300/800 - loss: 336.829507 - accuracy: 0.943056 - val_loss: 38.707962 - val_accuracy: 0.912500\n",
            "Epoch 310/800 - loss: 334.404174 - accuracy: 0.943056 - val_loss: 38.456912 - val_accuracy: 0.912500\n",
            "Epoch 320/800 - loss: 332.020346 - accuracy: 0.943056 - val_loss: 38.209035 - val_accuracy: 0.912500\n",
            "Epoch 330/800 - loss: 329.676360 - accuracy: 0.943056 - val_loss: 37.964307 - val_accuracy: 0.912500\n",
            "Epoch 340/800 - loss: 327.370760 - accuracy: 0.944444 - val_loss: 37.722707 - val_accuracy: 0.912500\n",
            "Epoch 350/800 - loss: 325.102256 - accuracy: 0.944444 - val_loss: 37.484218 - val_accuracy: 0.912500\n",
            "Epoch 360/800 - loss: 322.869689 - accuracy: 0.947222 - val_loss: 37.248823 - val_accuracy: 0.912500\n",
            "Epoch 370/800 - loss: 320.672007 - accuracy: 0.950000 - val_loss: 37.016501 - val_accuracy: 0.912500\n",
            "Epoch 380/800 - loss: 318.508246 - accuracy: 0.951389 - val_loss: 36.787234 - val_accuracy: 0.925000\n",
            "Epoch 390/800 - loss: 316.377510 - accuracy: 0.951389 - val_loss: 36.560999 - val_accuracy: 0.925000\n",
            "Epoch 400/800 - loss: 314.278963 - accuracy: 0.951389 - val_loss: 36.337770 - val_accuracy: 0.925000\n",
            "Epoch 410/800 - loss: 312.211818 - accuracy: 0.952778 - val_loss: 36.117521 - val_accuracy: 0.925000\n",
            "Epoch 420/800 - loss: 310.175331 - accuracy: 0.955556 - val_loss: 35.900223 - val_accuracy: 0.925000\n",
            "Epoch 430/800 - loss: 308.168791 - accuracy: 0.955556 - val_loss: 35.685843 - val_accuracy: 0.925000\n",
            "Epoch 440/800 - loss: 306.191521 - accuracy: 0.956944 - val_loss: 35.474349 - val_accuracy: 0.925000\n",
            "Epoch 450/800 - loss: 304.242870 - accuracy: 0.956944 - val_loss: 35.265706 - val_accuracy: 0.925000\n",
            "Epoch 460/800 - loss: 302.322212 - accuracy: 0.956944 - val_loss: 35.059876 - val_accuracy: 0.925000\n",
            "Epoch 470/800 - loss: 300.428943 - accuracy: 0.956944 - val_loss: 34.856823 - val_accuracy: 0.925000\n",
            "Epoch 480/800 - loss: 298.562481 - accuracy: 0.956944 - val_loss: 34.656506 - val_accuracy: 0.925000\n",
            "Epoch 490/800 - loss: 296.722259 - accuracy: 0.958333 - val_loss: 34.458887 - val_accuracy: 0.925000\n",
            "Epoch 500/800 - loss: 294.907731 - accuracy: 0.958333 - val_loss: 34.263925 - val_accuracy: 0.937500\n",
            "Epoch 510/800 - loss: 293.118365 - accuracy: 0.958333 - val_loss: 34.071580 - val_accuracy: 0.950000\n",
            "Epoch 520/800 - loss: 291.353644 - accuracy: 0.958333 - val_loss: 33.881809 - val_accuracy: 0.950000\n",
            "Epoch 530/800 - loss: 289.613067 - accuracy: 0.958333 - val_loss: 33.694573 - val_accuracy: 0.950000\n",
            "Epoch 540/800 - loss: 287.896145 - accuracy: 0.959722 - val_loss: 33.509829 - val_accuracy: 0.950000\n",
            "Epoch 550/800 - loss: 286.202404 - accuracy: 0.959722 - val_loss: 33.327536 - val_accuracy: 0.950000\n",
            "Epoch 560/800 - loss: 284.531381 - accuracy: 0.959722 - val_loss: 33.147653 - val_accuracy: 0.950000\n",
            "Epoch 570/800 - loss: 282.882625 - accuracy: 0.959722 - val_loss: 32.970140 - val_accuracy: 0.950000\n",
            "Epoch 580/800 - loss: 281.255698 - accuracy: 0.959722 - val_loss: 32.794955 - val_accuracy: 0.950000\n",
            "Epoch 590/800 - loss: 279.650172 - accuracy: 0.961111 - val_loss: 32.622059 - val_accuracy: 0.950000\n",
            "Epoch 600/800 - loss: 278.065629 - accuracy: 0.961111 - val_loss: 32.451411 - val_accuracy: 0.950000\n",
            "Epoch 610/800 - loss: 276.501663 - accuracy: 0.961111 - val_loss: 32.282973 - val_accuracy: 0.950000\n",
            "Epoch 620/800 - loss: 274.957878 - accuracy: 0.962500 - val_loss: 32.116705 - val_accuracy: 0.950000\n",
            "Epoch 630/800 - loss: 273.433887 - accuracy: 0.962500 - val_loss: 31.952570 - val_accuracy: 0.950000\n",
            "Epoch 640/800 - loss: 271.929313 - accuracy: 0.962500 - val_loss: 31.790530 - val_accuracy: 0.950000\n",
            "Epoch 650/800 - loss: 270.443787 - accuracy: 0.962500 - val_loss: 31.630547 - val_accuracy: 0.950000\n",
            "Epoch 660/800 - loss: 268.976951 - accuracy: 0.962500 - val_loss: 31.472585 - val_accuracy: 0.950000\n",
            "Epoch 670/800 - loss: 267.528453 - accuracy: 0.962500 - val_loss: 31.316609 - val_accuracy: 0.950000\n",
            "Epoch 680/800 - loss: 266.097953 - accuracy: 0.962500 - val_loss: 31.162583 - val_accuracy: 0.950000\n",
            "Epoch 690/800 - loss: 264.685115 - accuracy: 0.962500 - val_loss: 31.010473 - val_accuracy: 0.962500\n",
            "Epoch 700/800 - loss: 263.289615 - accuracy: 0.961111 - val_loss: 30.860245 - val_accuracy: 0.962500\n",
            "Epoch 710/800 - loss: 261.911133 - accuracy: 0.961111 - val_loss: 30.711865 - val_accuracy: 0.962500\n",
            "Epoch 720/800 - loss: 260.549359 - accuracy: 0.961111 - val_loss: 30.565301 - val_accuracy: 0.962500\n",
            "Epoch 730/800 - loss: 259.203989 - accuracy: 0.961111 - val_loss: 30.420521 - val_accuracy: 0.962500\n",
            "Epoch 740/800 - loss: 257.874728 - accuracy: 0.961111 - val_loss: 30.277494 - val_accuracy: 0.962500\n",
            "Epoch 750/800 - loss: 256.561284 - accuracy: 0.961111 - val_loss: 30.136188 - val_accuracy: 0.962500\n",
            "Epoch 760/800 - loss: 255.263376 - accuracy: 0.961111 - val_loss: 29.996574 - val_accuracy: 0.962500\n",
            "Epoch 770/800 - loss: 253.980726 - accuracy: 0.961111 - val_loss: 29.858622 - val_accuracy: 0.962500\n",
            "Epoch 780/800 - loss: 252.713066 - accuracy: 0.961111 - val_loss: 29.722304 - val_accuracy: 0.962500\n",
            "Epoch 790/800 - loss: 251.460131 - accuracy: 0.961111 - val_loss: 29.587590 - val_accuracy: 0.950000\n",
            "Accuracy on the test set is  0.94\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnqrQvtia0B4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cabf5db-64bb-47bb-c50f-4305d44511a7"
      },
      "source": [
        "# COMPARISONS WITH THE STANDARD LIBRARY \n",
        "\n",
        "#MODEL 1 STANDARD LIBRARY\n",
        "my_model_1_stdlib = keras.Sequential()\n",
        "# Your code here!\n",
        "my_model_1_stdlib.add(keras.layers.Dense(2, activation=\"tanh\", input_dim=2))\n",
        "my_model_1_stdlib.add(keras.layers.Dense(100, activation=\"tanh\"))\n",
        "my_model_1_stdlib.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
        "\n",
        "my_model_1_stdlib.compile(loss=\"sparse_categorical_crossentropy\" ,\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "my_model_1_stdlib.fit(X_train, y_train, batch_size=64, epochs=570,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/570\n",
            "12/12 [==============================] - 1s 15ms/step - loss: 0.6881 - accuracy: 0.6319 - val_loss: 0.6924 - val_accuracy: 0.5750\n",
            "Epoch 2/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.6542 - val_loss: 0.6933 - val_accuracy: 0.5875\n",
            "Epoch 3/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.6653 - val_loss: 0.6947 - val_accuracy: 0.5750\n",
            "Epoch 4/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.6750 - val_loss: 0.6944 - val_accuracy: 0.5750\n",
            "Epoch 5/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.6583 - val_loss: 0.6950 - val_accuracy: 0.5750\n",
            "Epoch 6/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.6639 - val_loss: 0.6952 - val_accuracy: 0.5750\n",
            "Epoch 7/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6722 - val_loss: 0.6957 - val_accuracy: 0.5750\n",
            "Epoch 8/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.6736 - val_loss: 0.6955 - val_accuracy: 0.5750\n",
            "Epoch 9/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.6611 - val_loss: 0.6958 - val_accuracy: 0.5750\n",
            "Epoch 10/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.6569 - val_loss: 0.6972 - val_accuracy: 0.5750\n",
            "Epoch 11/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.6722 - val_loss: 0.6971 - val_accuracy: 0.5750\n",
            "Epoch 12/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.6653 - val_loss: 0.6969 - val_accuracy: 0.5750\n",
            "Epoch 13/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6556 - val_loss: 0.6978 - val_accuracy: 0.5750\n",
            "Epoch 14/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.6583 - val_loss: 0.6980 - val_accuracy: 0.5750\n",
            "Epoch 15/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.6667 - val_loss: 0.6990 - val_accuracy: 0.5750\n",
            "Epoch 16/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6736 - val_loss: 0.6985 - val_accuracy: 0.5750\n",
            "Epoch 17/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.6625 - val_loss: 0.6977 - val_accuracy: 0.5750\n",
            "Epoch 18/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6611 - val_loss: 0.6986 - val_accuracy: 0.5750\n",
            "Epoch 19/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.6583 - val_loss: 0.6983 - val_accuracy: 0.5750\n",
            "Epoch 20/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.6611 - val_loss: 0.6981 - val_accuracy: 0.5750\n",
            "Epoch 21/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6542 - val_loss: 0.6984 - val_accuracy: 0.5750\n",
            "Epoch 22/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6597 - val_loss: 0.7005 - val_accuracy: 0.5750\n",
            "Epoch 23/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.6681 - val_loss: 0.7004 - val_accuracy: 0.5750\n",
            "Epoch 24/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.6639 - val_loss: 0.6998 - val_accuracy: 0.5750\n",
            "Epoch 25/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.6625 - val_loss: 0.6998 - val_accuracy: 0.5750\n",
            "Epoch 26/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.6611 - val_loss: 0.6996 - val_accuracy: 0.5750\n",
            "Epoch 27/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6611 - val_loss: 0.6992 - val_accuracy: 0.5750\n",
            "Epoch 28/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6611 - val_loss: 0.6988 - val_accuracy: 0.5750\n",
            "Epoch 29/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.6569 - val_loss: 0.6985 - val_accuracy: 0.5750\n",
            "Epoch 30/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.6625 - val_loss: 0.6979 - val_accuracy: 0.5750\n",
            "Epoch 31/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.6583 - val_loss: 0.6970 - val_accuracy: 0.5750\n",
            "Epoch 32/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.6556 - val_loss: 0.6970 - val_accuracy: 0.5750\n",
            "Epoch 33/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.6556 - val_loss: 0.6974 - val_accuracy: 0.5750\n",
            "Epoch 34/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.6611 - val_loss: 0.6974 - val_accuracy: 0.5750\n",
            "Epoch 35/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.6583 - val_loss: 0.6975 - val_accuracy: 0.5750\n",
            "Epoch 36/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6611 - val_loss: 0.6983 - val_accuracy: 0.5750\n",
            "Epoch 37/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6611 - val_loss: 0.6983 - val_accuracy: 0.5750\n",
            "Epoch 38/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.6625 - val_loss: 0.6982 - val_accuracy: 0.5750\n",
            "Epoch 39/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6681 - val_loss: 0.6997 - val_accuracy: 0.5875\n",
            "Epoch 40/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6694 - val_loss: 0.6986 - val_accuracy: 0.5750\n",
            "Epoch 41/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6750 - val_loss: 0.6985 - val_accuracy: 0.5750\n",
            "Epoch 42/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6736 - val_loss: 0.6978 - val_accuracy: 0.5875\n",
            "Epoch 43/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6764 - val_loss: 0.6962 - val_accuracy: 0.5750\n",
            "Epoch 44/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.6694 - val_loss: 0.6947 - val_accuracy: 0.5750\n",
            "Epoch 45/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6653 - val_loss: 0.6949 - val_accuracy: 0.5750\n",
            "Epoch 46/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6667 - val_loss: 0.6936 - val_accuracy: 0.5750\n",
            "Epoch 47/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6653 - val_loss: 0.6929 - val_accuracy: 0.5750\n",
            "Epoch 48/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6653 - val_loss: 0.6907 - val_accuracy: 0.5750\n",
            "Epoch 49/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.6653 - val_loss: 0.6893 - val_accuracy: 0.5875\n",
            "Epoch 50/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6611 - val_loss: 0.6911 - val_accuracy: 0.5750\n",
            "Epoch 51/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6681 - val_loss: 0.6911 - val_accuracy: 0.5750\n",
            "Epoch 52/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6764 - val_loss: 0.6903 - val_accuracy: 0.5750\n",
            "Epoch 53/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.6694 - val_loss: 0.6899 - val_accuracy: 0.5750\n",
            "Epoch 54/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6722 - val_loss: 0.6881 - val_accuracy: 0.5750\n",
            "Epoch 55/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.6681 - val_loss: 0.6870 - val_accuracy: 0.5875\n",
            "Epoch 56/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6708 - val_loss: 0.6866 - val_accuracy: 0.5875\n",
            "Epoch 57/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6708 - val_loss: 0.6856 - val_accuracy: 0.5875\n",
            "Epoch 58/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.6736 - val_loss: 0.6845 - val_accuracy: 0.5875\n",
            "Epoch 59/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6708 - val_loss: 0.6843 - val_accuracy: 0.5875\n",
            "Epoch 60/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6764 - val_loss: 0.6823 - val_accuracy: 0.5875\n",
            "Epoch 61/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.6639 - val_loss: 0.6825 - val_accuracy: 0.5875\n",
            "Epoch 62/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.6792 - val_loss: 0.6828 - val_accuracy: 0.5750\n",
            "Epoch 63/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6819 - val_loss: 0.6810 - val_accuracy: 0.5875\n",
            "Epoch 64/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6806 - val_loss: 0.6813 - val_accuracy: 0.5875\n",
            "Epoch 65/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6847 - val_loss: 0.6798 - val_accuracy: 0.6000\n",
            "Epoch 66/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.6847 - val_loss: 0.6784 - val_accuracy: 0.6000\n",
            "Epoch 67/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6833 - val_loss: 0.6789 - val_accuracy: 0.6000\n",
            "Epoch 68/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.6903 - val_loss: 0.6775 - val_accuracy: 0.6125\n",
            "Epoch 69/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.6917 - val_loss: 0.6796 - val_accuracy: 0.6125\n",
            "Epoch 70/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6958 - val_loss: 0.6758 - val_accuracy: 0.6250\n",
            "Epoch 71/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6931 - val_loss: 0.6755 - val_accuracy: 0.6125\n",
            "Epoch 72/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6931 - val_loss: 0.6755 - val_accuracy: 0.6125\n",
            "Epoch 73/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6958 - val_loss: 0.6746 - val_accuracy: 0.6125\n",
            "Epoch 74/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6958 - val_loss: 0.6744 - val_accuracy: 0.6125\n",
            "Epoch 75/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6958 - val_loss: 0.6727 - val_accuracy: 0.6250\n",
            "Epoch 76/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6986 - val_loss: 0.6726 - val_accuracy: 0.6250\n",
            "Epoch 77/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6425 - accuracy: 0.7042 - val_loss: 0.6718 - val_accuracy: 0.6250\n",
            "Epoch 78/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7069 - val_loss: 0.6704 - val_accuracy: 0.6250\n",
            "Epoch 79/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7139 - val_loss: 0.6688 - val_accuracy: 0.6250\n",
            "Epoch 80/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7069 - val_loss: 0.6682 - val_accuracy: 0.6250\n",
            "Epoch 81/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7194 - val_loss: 0.6647 - val_accuracy: 0.6375\n",
            "Epoch 82/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7111 - val_loss: 0.6642 - val_accuracy: 0.6375\n",
            "Epoch 83/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7167 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
            "Epoch 84/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7167 - val_loss: 0.6611 - val_accuracy: 0.6375\n",
            "Epoch 85/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.7125 - val_loss: 0.6611 - val_accuracy: 0.6375\n",
            "Epoch 86/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7181 - val_loss: 0.6605 - val_accuracy: 0.6375\n",
            "Epoch 87/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7194 - val_loss: 0.6604 - val_accuracy: 0.6250\n",
            "Epoch 88/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7236 - val_loss: 0.6593 - val_accuracy: 0.6250\n",
            "Epoch 89/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.7194 - val_loss: 0.6586 - val_accuracy: 0.6375\n",
            "Epoch 90/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7264 - val_loss: 0.6560 - val_accuracy: 0.6375\n",
            "Epoch 91/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.7250 - val_loss: 0.6557 - val_accuracy: 0.6375\n",
            "Epoch 92/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.7278 - val_loss: 0.6545 - val_accuracy: 0.6375\n",
            "Epoch 93/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.7319 - val_loss: 0.6542 - val_accuracy: 0.6375\n",
            "Epoch 94/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.7333 - val_loss: 0.6550 - val_accuracy: 0.6375\n",
            "Epoch 95/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.7375 - val_loss: 0.6519 - val_accuracy: 0.6375\n",
            "Epoch 96/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.7347 - val_loss: 0.6497 - val_accuracy: 0.6375\n",
            "Epoch 97/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.7333 - val_loss: 0.6483 - val_accuracy: 0.6375\n",
            "Epoch 98/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.7361 - val_loss: 0.6471 - val_accuracy: 0.6500\n",
            "Epoch 99/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.7361 - val_loss: 0.6451 - val_accuracy: 0.6500\n",
            "Epoch 100/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.7375 - val_loss: 0.6442 - val_accuracy: 0.6500\n",
            "Epoch 101/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7375 - val_loss: 0.6438 - val_accuracy: 0.6500\n",
            "Epoch 102/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.7375 - val_loss: 0.6418 - val_accuracy: 0.6500\n",
            "Epoch 103/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.7361 - val_loss: 0.6407 - val_accuracy: 0.6500\n",
            "Epoch 104/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.7403 - val_loss: 0.6404 - val_accuracy: 0.6500\n",
            "Epoch 105/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.7389 - val_loss: 0.6377 - val_accuracy: 0.6500\n",
            "Epoch 106/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.7417 - val_loss: 0.6350 - val_accuracy: 0.6500\n",
            "Epoch 107/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7417 - val_loss: 0.6318 - val_accuracy: 0.6500\n",
            "Epoch 108/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7389 - val_loss: 0.6320 - val_accuracy: 0.6500\n",
            "Epoch 109/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7417 - val_loss: 0.6295 - val_accuracy: 0.6500\n",
            "Epoch 110/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7403 - val_loss: 0.6269 - val_accuracy: 0.6500\n",
            "Epoch 111/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7389 - val_loss: 0.6271 - val_accuracy: 0.6500\n",
            "Epoch 112/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7417 - val_loss: 0.6232 - val_accuracy: 0.6500\n",
            "Epoch 113/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7389 - val_loss: 0.6217 - val_accuracy: 0.6500\n",
            "Epoch 114/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7403 - val_loss: 0.6185 - val_accuracy: 0.6625\n",
            "Epoch 115/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7375 - val_loss: 0.6186 - val_accuracy: 0.6500\n",
            "Epoch 116/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7389 - val_loss: 0.6154 - val_accuracy: 0.6625\n",
            "Epoch 117/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7361 - val_loss: 0.6159 - val_accuracy: 0.6500\n",
            "Epoch 118/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7361 - val_loss: 0.6142 - val_accuracy: 0.6500\n",
            "Epoch 119/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7389 - val_loss: 0.6113 - val_accuracy: 0.6500\n",
            "Epoch 120/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7389 - val_loss: 0.6101 - val_accuracy: 0.6500\n",
            "Epoch 121/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7417 - val_loss: 0.6053 - val_accuracy: 0.6625\n",
            "Epoch 122/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7403 - val_loss: 0.6042 - val_accuracy: 0.6500\n",
            "Epoch 123/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7389 - val_loss: 0.6038 - val_accuracy: 0.6500\n",
            "Epoch 124/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7389 - val_loss: 0.6031 - val_accuracy: 0.6500\n",
            "Epoch 125/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7375 - val_loss: 0.6011 - val_accuracy: 0.6500\n",
            "Epoch 126/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7389 - val_loss: 0.5991 - val_accuracy: 0.6500\n",
            "Epoch 127/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7417 - val_loss: 0.5946 - val_accuracy: 0.6500\n",
            "Epoch 128/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7403 - val_loss: 0.5923 - val_accuracy: 0.6500\n",
            "Epoch 129/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7403 - val_loss: 0.5922 - val_accuracy: 0.6500\n",
            "Epoch 130/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7444 - val_loss: 0.5898 - val_accuracy: 0.6500\n",
            "Epoch 131/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7431 - val_loss: 0.5872 - val_accuracy: 0.6500\n",
            "Epoch 132/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7431 - val_loss: 0.5831 - val_accuracy: 0.6500\n",
            "Epoch 133/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5543 - accuracy: 0.7403 - val_loss: 0.5813 - val_accuracy: 0.6500\n",
            "Epoch 134/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7417 - val_loss: 0.5803 - val_accuracy: 0.6500\n",
            "Epoch 135/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7431 - val_loss: 0.5798 - val_accuracy: 0.6500\n",
            "Epoch 136/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7472 - val_loss: 0.5766 - val_accuracy: 0.6500\n",
            "Epoch 137/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7458 - val_loss: 0.5747 - val_accuracy: 0.6500\n",
            "Epoch 138/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7486 - val_loss: 0.5714 - val_accuracy: 0.6500\n",
            "Epoch 139/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7472 - val_loss: 0.5671 - val_accuracy: 0.6500\n",
            "Epoch 140/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7486 - val_loss: 0.5657 - val_accuracy: 0.6500\n",
            "Epoch 141/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7486 - val_loss: 0.5620 - val_accuracy: 0.6625\n",
            "Epoch 142/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7500 - val_loss: 0.5602 - val_accuracy: 0.6625\n",
            "Epoch 143/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7528 - val_loss: 0.5586 - val_accuracy: 0.6625\n",
            "Epoch 144/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7500 - val_loss: 0.5553 - val_accuracy: 0.6625\n",
            "Epoch 145/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7500 - val_loss: 0.5498 - val_accuracy: 0.6625\n",
            "Epoch 146/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7556 - val_loss: 0.5509 - val_accuracy: 0.6625\n",
            "Epoch 147/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7514 - val_loss: 0.5455 - val_accuracy: 0.6750\n",
            "Epoch 148/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7583 - val_loss: 0.5434 - val_accuracy: 0.6750\n",
            "Epoch 149/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.7583 - val_loss: 0.5402 - val_accuracy: 0.6875\n",
            "Epoch 150/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7625 - val_loss: 0.5351 - val_accuracy: 0.7000\n",
            "Epoch 151/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7667 - val_loss: 0.5329 - val_accuracy: 0.7000\n",
            "Epoch 152/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7639 - val_loss: 0.5313 - val_accuracy: 0.6875\n",
            "Epoch 153/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7653 - val_loss: 0.5274 - val_accuracy: 0.7000\n",
            "Epoch 154/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7694 - val_loss: 0.5239 - val_accuracy: 0.7000\n",
            "Epoch 155/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7833 - val_loss: 0.5219 - val_accuracy: 0.7000\n",
            "Epoch 156/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7000\n",
            "Epoch 157/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7778 - val_loss: 0.5160 - val_accuracy: 0.7000\n",
            "Epoch 158/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7833 - val_loss: 0.5118 - val_accuracy: 0.7125\n",
            "Epoch 159/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7931 - val_loss: 0.5042 - val_accuracy: 0.7250\n",
            "Epoch 160/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.8153 - val_loss: 0.5002 - val_accuracy: 0.7375\n",
            "Epoch 161/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.8125 - val_loss: 0.4963 - val_accuracy: 0.7375\n",
            "Epoch 162/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.8236 - val_loss: 0.4944 - val_accuracy: 0.7375\n",
            "Epoch 163/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.8167 - val_loss: 0.4876 - val_accuracy: 0.7375\n",
            "Epoch 164/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8264 - val_loss: 0.4823 - val_accuracy: 0.7500\n",
            "Epoch 165/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.8333 - val_loss: 0.4771 - val_accuracy: 0.7500\n",
            "Epoch 166/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.8417 - val_loss: 0.4744 - val_accuracy: 0.7500\n",
            "Epoch 167/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8333 - val_loss: 0.4672 - val_accuracy: 0.7625\n",
            "Epoch 168/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8542 - val_loss: 0.4615 - val_accuracy: 0.7625\n",
            "Epoch 169/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8667 - val_loss: 0.4567 - val_accuracy: 0.7750\n",
            "Epoch 170/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8681 - val_loss: 0.4548 - val_accuracy: 0.7625\n",
            "Epoch 171/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8639 - val_loss: 0.4511 - val_accuracy: 0.7625\n",
            "Epoch 172/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8653 - val_loss: 0.4458 - val_accuracy: 0.7750\n",
            "Epoch 173/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8653 - val_loss: 0.4420 - val_accuracy: 0.7875\n",
            "Epoch 174/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8736 - val_loss: 0.4370 - val_accuracy: 0.7875\n",
            "Epoch 175/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8778 - val_loss: 0.4302 - val_accuracy: 0.8125\n",
            "Epoch 176/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8875 - val_loss: 0.4257 - val_accuracy: 0.8250\n",
            "Epoch 177/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.9000 - val_loss: 0.4185 - val_accuracy: 0.8625\n",
            "Epoch 178/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.9042 - val_loss: 0.4127 - val_accuracy: 0.8625\n",
            "Epoch 179/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.9056 - val_loss: 0.4062 - val_accuracy: 0.8625\n",
            "Epoch 180/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.9083 - val_loss: 0.4035 - val_accuracy: 0.8625\n",
            "Epoch 181/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.9097 - val_loss: 0.4010 - val_accuracy: 0.8625\n",
            "Epoch 182/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.9056 - val_loss: 0.3943 - val_accuracy: 0.8750\n",
            "Epoch 183/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.9097 - val_loss: 0.3889 - val_accuracy: 0.8750\n",
            "Epoch 184/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.9139 - val_loss: 0.3847 - val_accuracy: 0.8750\n",
            "Epoch 185/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.9111 - val_loss: 0.3798 - val_accuracy: 0.8750\n",
            "Epoch 186/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.9125 - val_loss: 0.3751 - val_accuracy: 0.8750\n",
            "Epoch 187/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.9125 - val_loss: 0.3685 - val_accuracy: 0.9000\n",
            "Epoch 188/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.9250 - val_loss: 0.3633 - val_accuracy: 0.9000\n",
            "Epoch 189/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.9264 - val_loss: 0.3604 - val_accuracy: 0.8875\n",
            "Epoch 190/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.9236 - val_loss: 0.3557 - val_accuracy: 0.8875\n",
            "Epoch 191/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.9250 - val_loss: 0.3510 - val_accuracy: 0.8875\n",
            "Epoch 192/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.9264 - val_loss: 0.3451 - val_accuracy: 0.9000\n",
            "Epoch 193/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.9278 - val_loss: 0.3393 - val_accuracy: 0.9000\n",
            "Epoch 194/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.9319 - val_loss: 0.3340 - val_accuracy: 0.9000\n",
            "Epoch 195/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.9306 - val_loss: 0.3283 - val_accuracy: 0.9000\n",
            "Epoch 196/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.9292 - val_loss: 0.3242 - val_accuracy: 0.9000\n",
            "Epoch 197/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.9306 - val_loss: 0.3194 - val_accuracy: 0.9000\n",
            "Epoch 198/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.9278 - val_loss: 0.3141 - val_accuracy: 0.9000\n",
            "Epoch 199/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.9292 - val_loss: 0.3063 - val_accuracy: 0.9125\n",
            "Epoch 200/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.9278 - val_loss: 0.3033 - val_accuracy: 0.9125\n",
            "Epoch 201/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9319 - val_loss: 0.3010 - val_accuracy: 0.9000\n",
            "Epoch 202/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9306 - val_loss: 0.2991 - val_accuracy: 0.9000\n",
            "Epoch 203/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.9292 - val_loss: 0.2963 - val_accuracy: 0.9000\n",
            "Epoch 204/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.9306 - val_loss: 0.2914 - val_accuracy: 0.9000\n",
            "Epoch 205/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.9292 - val_loss: 0.2859 - val_accuracy: 0.9125\n",
            "Epoch 206/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.9292 - val_loss: 0.2818 - val_accuracy: 0.9125\n",
            "Epoch 207/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.9306 - val_loss: 0.2769 - val_accuracy: 0.9125\n",
            "Epoch 208/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.9292 - val_loss: 0.2735 - val_accuracy: 0.9125\n",
            "Epoch 209/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.9333 - val_loss: 0.2712 - val_accuracy: 0.9125\n",
            "Epoch 210/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.9319 - val_loss: 0.2681 - val_accuracy: 0.9125\n",
            "Epoch 211/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9333 - val_loss: 0.2652 - val_accuracy: 0.9125\n",
            "Epoch 212/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9306 - val_loss: 0.2610 - val_accuracy: 0.9125\n",
            "Epoch 213/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9361 - val_loss: 0.2557 - val_accuracy: 0.9125\n",
            "Epoch 214/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.9389 - val_loss: 0.2541 - val_accuracy: 0.9125\n",
            "Epoch 215/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9375 - val_loss: 0.2500 - val_accuracy: 0.9250\n",
            "Epoch 216/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9417 - val_loss: 0.2467 - val_accuracy: 0.9250\n",
            "Epoch 217/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2405 - accuracy: 0.9417 - val_loss: 0.2456 - val_accuracy: 0.9125\n",
            "Epoch 218/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.9389 - val_loss: 0.2425 - val_accuracy: 0.9250\n",
            "Epoch 219/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9431 - val_loss: 0.2402 - val_accuracy: 0.9250\n",
            "Epoch 220/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.9389 - val_loss: 0.2382 - val_accuracy: 0.9250\n",
            "Epoch 221/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2297 - accuracy: 0.9403 - val_loss: 0.2368 - val_accuracy: 0.9125\n",
            "Epoch 222/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9389 - val_loss: 0.2367 - val_accuracy: 0.9125\n",
            "Epoch 223/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9417 - val_loss: 0.2327 - val_accuracy: 0.9125\n",
            "Epoch 224/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9431 - val_loss: 0.2291 - val_accuracy: 0.9250\n",
            "Epoch 225/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9417 - val_loss: 0.2283 - val_accuracy: 0.9125\n",
            "Epoch 226/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9431 - val_loss: 0.2231 - val_accuracy: 0.9250\n",
            "Epoch 227/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9444 - val_loss: 0.2207 - val_accuracy: 0.9250\n",
            "Epoch 228/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2134 - accuracy: 0.9444 - val_loss: 0.2182 - val_accuracy: 0.9250\n",
            "Epoch 229/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2111 - accuracy: 0.9431 - val_loss: 0.2163 - val_accuracy: 0.9250\n",
            "Epoch 230/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9444 - val_loss: 0.2099 - val_accuracy: 0.9250\n",
            "Epoch 231/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9431 - val_loss: 0.2090 - val_accuracy: 0.9250\n",
            "Epoch 232/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9417 - val_loss: 0.2082 - val_accuracy: 0.9250\n",
            "Epoch 233/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9444 - val_loss: 0.2058 - val_accuracy: 0.9250\n",
            "Epoch 234/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9431 - val_loss: 0.2063 - val_accuracy: 0.9250\n",
            "Epoch 235/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9431 - val_loss: 0.2032 - val_accuracy: 0.9250\n",
            "Epoch 236/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9444 - val_loss: 0.1997 - val_accuracy: 0.9250\n",
            "Epoch 237/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.9417 - val_loss: 0.1985 - val_accuracy: 0.9250\n",
            "Epoch 238/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1943 - accuracy: 0.9444 - val_loss: 0.1964 - val_accuracy: 0.9250\n",
            "Epoch 239/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9458 - val_loss: 0.1951 - val_accuracy: 0.9250\n",
            "Epoch 240/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9444 - val_loss: 0.1933 - val_accuracy: 0.9250\n",
            "Epoch 241/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9444 - val_loss: 0.1919 - val_accuracy: 0.9250\n",
            "Epoch 242/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9431 - val_loss: 0.1886 - val_accuracy: 0.9375\n",
            "Epoch 243/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9431 - val_loss: 0.1874 - val_accuracy: 0.9375\n",
            "Epoch 244/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9431 - val_loss: 0.1861 - val_accuracy: 0.9375\n",
            "Epoch 245/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9431 - val_loss: 0.1877 - val_accuracy: 0.9250\n",
            "Epoch 246/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9431 - val_loss: 0.1857 - val_accuracy: 0.9250\n",
            "Epoch 247/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9431 - val_loss: 0.1844 - val_accuracy: 0.9250\n",
            "Epoch 248/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9458 - val_loss: 0.1838 - val_accuracy: 0.9250\n",
            "Epoch 249/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9431 - val_loss: 0.1817 - val_accuracy: 0.9250\n",
            "Epoch 250/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9431 - val_loss: 0.1771 - val_accuracy: 0.9375\n",
            "Epoch 251/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.9472 - val_loss: 0.1789 - val_accuracy: 0.9250\n",
            "Epoch 252/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9431 - val_loss: 0.1751 - val_accuracy: 0.9375\n",
            "Epoch 253/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9458 - val_loss: 0.1744 - val_accuracy: 0.9375\n",
            "Epoch 254/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9444 - val_loss: 0.1735 - val_accuracy: 0.9375\n",
            "Epoch 255/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9431 - val_loss: 0.1718 - val_accuracy: 0.9375\n",
            "Epoch 256/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9431 - val_loss: 0.1697 - val_accuracy: 0.9375\n",
            "Epoch 257/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1704 - accuracy: 0.9444 - val_loss: 0.1689 - val_accuracy: 0.9375\n",
            "Epoch 258/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9458 - val_loss: 0.1698 - val_accuracy: 0.9375\n",
            "Epoch 259/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9444 - val_loss: 0.1701 - val_accuracy: 0.9375\n",
            "Epoch 260/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9431 - val_loss: 0.1678 - val_accuracy: 0.9375\n",
            "Epoch 261/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9458 - val_loss: 0.1669 - val_accuracy: 0.9375\n",
            "Epoch 262/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9458 - val_loss: 0.1669 - val_accuracy: 0.9375\n",
            "Epoch 263/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9431 - val_loss: 0.1626 - val_accuracy: 0.9375\n",
            "Epoch 264/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9458 - val_loss: 0.1638 - val_accuracy: 0.9375\n",
            "Epoch 265/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9444 - val_loss: 0.1632 - val_accuracy: 0.9375\n",
            "Epoch 266/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9444 - val_loss: 0.1609 - val_accuracy: 0.9375\n",
            "Epoch 267/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1619 - accuracy: 0.9444 - val_loss: 0.1601 - val_accuracy: 0.9375\n",
            "Epoch 268/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1610 - accuracy: 0.9444 - val_loss: 0.1603 - val_accuracy: 0.9375\n",
            "Epoch 269/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9444 - val_loss: 0.1601 - val_accuracy: 0.9375\n",
            "Epoch 270/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9444 - val_loss: 0.1585 - val_accuracy: 0.9375\n",
            "Epoch 271/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9458 - val_loss: 0.1589 - val_accuracy: 0.9375\n",
            "Epoch 272/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9444 - val_loss: 0.1582 - val_accuracy: 0.9375\n",
            "Epoch 273/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9458 - val_loss: 0.1544 - val_accuracy: 0.9375\n",
            "Epoch 274/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9472 - val_loss: 0.1544 - val_accuracy: 0.9375\n",
            "Epoch 275/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9472 - val_loss: 0.1538 - val_accuracy: 0.9375\n",
            "Epoch 276/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9472 - val_loss: 0.1553 - val_accuracy: 0.9375\n",
            "Epoch 277/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9458 - val_loss: 0.1559 - val_accuracy: 0.9375\n",
            "Epoch 278/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9458 - val_loss: 0.1528 - val_accuracy: 0.9375\n",
            "Epoch 279/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9472 - val_loss: 0.1528 - val_accuracy: 0.9375\n",
            "Epoch 280/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9472 - val_loss: 0.1525 - val_accuracy: 0.9375\n",
            "Epoch 281/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9472 - val_loss: 0.1531 - val_accuracy: 0.9375\n",
            "Epoch 282/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9444 - val_loss: 0.1525 - val_accuracy: 0.9375\n",
            "Epoch 283/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9472 - val_loss: 0.1518 - val_accuracy: 0.9375\n",
            "Epoch 284/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9472 - val_loss: 0.1518 - val_accuracy: 0.9375\n",
            "Epoch 285/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9472 - val_loss: 0.1495 - val_accuracy: 0.9375\n",
            "Epoch 286/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.9458 - val_loss: 0.1488 - val_accuracy: 0.9375\n",
            "Epoch 287/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9472 - val_loss: 0.1495 - val_accuracy: 0.9375\n",
            "Epoch 288/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9472 - val_loss: 0.1488 - val_accuracy: 0.9375\n",
            "Epoch 289/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9472 - val_loss: 0.1491 - val_accuracy: 0.9375\n",
            "Epoch 290/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9458 - val_loss: 0.1467 - val_accuracy: 0.9375\n",
            "Epoch 291/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9472 - val_loss: 0.1482 - val_accuracy: 0.9375\n",
            "Epoch 292/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9458 - val_loss: 0.1462 - val_accuracy: 0.9375\n",
            "Epoch 293/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9458 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
            "Epoch 294/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9444 - val_loss: 0.1428 - val_accuracy: 0.9500\n",
            "Epoch 295/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9458 - val_loss: 0.1432 - val_accuracy: 0.9375\n",
            "Epoch 296/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9472 - val_loss: 0.1448 - val_accuracy: 0.9375\n",
            "Epoch 297/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9444 - val_loss: 0.1430 - val_accuracy: 0.9375\n",
            "Epoch 298/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9458 - val_loss: 0.1425 - val_accuracy: 0.9375\n",
            "Epoch 299/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9444 - val_loss: 0.1457 - val_accuracy: 0.9375\n",
            "Epoch 300/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1455 - accuracy: 0.9444 - val_loss: 0.1448 - val_accuracy: 0.9375\n",
            "Epoch 301/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9458 - val_loss: 0.1439 - val_accuracy: 0.9375\n",
            "Epoch 302/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9444 - val_loss: 0.1438 - val_accuracy: 0.9375\n",
            "Epoch 303/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9472 - val_loss: 0.1421 - val_accuracy: 0.9375\n",
            "Epoch 304/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9472 - val_loss: 0.1384 - val_accuracy: 0.9500\n",
            "Epoch 305/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9458 - val_loss: 0.1393 - val_accuracy: 0.9375\n",
            "Epoch 306/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9444 - val_loss: 0.1397 - val_accuracy: 0.9375\n",
            "Epoch 307/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9458 - val_loss: 0.1405 - val_accuracy: 0.9375\n",
            "Epoch 308/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9458 - val_loss: 0.1406 - val_accuracy: 0.9375\n",
            "Epoch 309/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9458 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
            "Epoch 310/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9458 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 311/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9458 - val_loss: 0.1399 - val_accuracy: 0.9500\n",
            "Epoch 312/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9458 - val_loss: 0.1387 - val_accuracy: 0.9500\n",
            "Epoch 313/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9458 - val_loss: 0.1387 - val_accuracy: 0.9500\n",
            "Epoch 314/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9472 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
            "Epoch 315/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9472 - val_loss: 0.1368 - val_accuracy: 0.9500\n",
            "Epoch 316/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9458 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
            "Epoch 317/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9458 - val_loss: 0.1378 - val_accuracy: 0.9500\n",
            "Epoch 318/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9472 - val_loss: 0.1365 - val_accuracy: 0.9500\n",
            "Epoch 319/570\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1402 - accuracy: 0.9458 - val_loss: 0.1386 - val_accuracy: 0.9500\n",
            "Epoch 320/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1401 - accuracy: 0.9458 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
            "Epoch 321/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.9472 - val_loss: 0.1334 - val_accuracy: 0.9500\n",
            "Epoch 322/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1401 - accuracy: 0.9458 - val_loss: 0.1362 - val_accuracy: 0.9500\n",
            "Epoch 323/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9472 - val_loss: 0.1372 - val_accuracy: 0.9500\n",
            "Epoch 324/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.9472 - val_loss: 0.1354 - val_accuracy: 0.9500\n",
            "Epoch 325/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9458 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
            "Epoch 326/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9444 - val_loss: 0.1357 - val_accuracy: 0.9500\n",
            "Epoch 327/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9458 - val_loss: 0.1369 - val_accuracy: 0.9500\n",
            "Epoch 328/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9458 - val_loss: 0.1344 - val_accuracy: 0.9500\n",
            "Epoch 329/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9458 - val_loss: 0.1326 - val_accuracy: 0.9500\n",
            "Epoch 330/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1381 - accuracy: 0.9444 - val_loss: 0.1328 - val_accuracy: 0.9500\n",
            "Epoch 331/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9444 - val_loss: 0.1345 - val_accuracy: 0.9500\n",
            "Epoch 332/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9458 - val_loss: 0.1346 - val_accuracy: 0.9500\n",
            "Epoch 333/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9458 - val_loss: 0.1357 - val_accuracy: 0.9375\n",
            "Epoch 334/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9472 - val_loss: 0.1334 - val_accuracy: 0.9500\n",
            "Epoch 335/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9444 - val_loss: 0.1325 - val_accuracy: 0.9500\n",
            "Epoch 336/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9472 - val_loss: 0.1314 - val_accuracy: 0.9500\n",
            "Epoch 337/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9444 - val_loss: 0.1336 - val_accuracy: 0.9500\n",
            "Epoch 338/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9472 - val_loss: 0.1329 - val_accuracy: 0.9500\n",
            "Epoch 339/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9458 - val_loss: 0.1326 - val_accuracy: 0.9500\n",
            "Epoch 340/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9472 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
            "Epoch 341/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9486 - val_loss: 0.1312 - val_accuracy: 0.9500\n",
            "Epoch 342/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9444 - val_loss: 0.1327 - val_accuracy: 0.9500\n",
            "Epoch 343/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9458 - val_loss: 0.1317 - val_accuracy: 0.9500\n",
            "Epoch 344/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9472 - val_loss: 0.1300 - val_accuracy: 0.9500\n",
            "Epoch 345/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9458 - val_loss: 0.1308 - val_accuracy: 0.9500\n",
            "Epoch 346/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9472 - val_loss: 0.1306 - val_accuracy: 0.9500\n",
            "Epoch 347/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9444 - val_loss: 0.1311 - val_accuracy: 0.9500\n",
            "Epoch 348/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9458 - val_loss: 0.1318 - val_accuracy: 0.9500\n",
            "Epoch 349/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9458 - val_loss: 0.1300 - val_accuracy: 0.9500\n",
            "Epoch 350/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9458 - val_loss: 0.1308 - val_accuracy: 0.9500\n",
            "Epoch 351/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9472 - val_loss: 0.1299 - val_accuracy: 0.9500\n",
            "Epoch 352/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9458 - val_loss: 0.1306 - val_accuracy: 0.9500\n",
            "Epoch 353/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9458 - val_loss: 0.1310 - val_accuracy: 0.9500\n",
            "Epoch 354/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9458 - val_loss: 0.1315 - val_accuracy: 0.9500\n",
            "Epoch 355/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9458 - val_loss: 0.1311 - val_accuracy: 0.9500\n",
            "Epoch 356/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9472 - val_loss: 0.1299 - val_accuracy: 0.9500\n",
            "Epoch 357/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.9458 - val_loss: 0.1287 - val_accuracy: 0.9500\n",
            "Epoch 358/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9444 - val_loss: 0.1303 - val_accuracy: 0.9500\n",
            "Epoch 359/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9444 - val_loss: 0.1288 - val_accuracy: 0.9500\n",
            "Epoch 360/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9444 - val_loss: 0.1269 - val_accuracy: 0.9500\n",
            "Epoch 361/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.9444 - val_loss: 0.1282 - val_accuracy: 0.9500\n",
            "Epoch 362/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9458 - val_loss: 0.1290 - val_accuracy: 0.9500\n",
            "Epoch 363/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9458 - val_loss: 0.1264 - val_accuracy: 0.9500\n",
            "Epoch 364/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9444 - val_loss: 0.1299 - val_accuracy: 0.9500\n",
            "Epoch 365/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9472 - val_loss: 0.1280 - val_accuracy: 0.9500\n",
            "Epoch 366/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9444 - val_loss: 0.1302 - val_accuracy: 0.9500\n",
            "Epoch 367/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9458 - val_loss: 0.1313 - val_accuracy: 0.9375\n",
            "Epoch 368/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9444 - val_loss: 0.1293 - val_accuracy: 0.9500\n",
            "Epoch 369/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9444 - val_loss: 0.1302 - val_accuracy: 0.9500\n",
            "Epoch 370/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9458 - val_loss: 0.1286 - val_accuracy: 0.9500\n",
            "Epoch 371/570\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9444 - val_loss: 0.1278 - val_accuracy: 0.9500\n",
            "Epoch 372/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9444 - val_loss: 0.1293 - val_accuracy: 0.9500\n",
            "Epoch 373/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9458 - val_loss: 0.1269 - val_accuracy: 0.9500\n",
            "Epoch 374/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9444 - val_loss: 0.1288 - val_accuracy: 0.9500\n",
            "Epoch 375/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9444 - val_loss: 0.1304 - val_accuracy: 0.9500\n",
            "Epoch 376/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1333 - accuracy: 0.9458 - val_loss: 0.1296 - val_accuracy: 0.9500\n",
            "Epoch 377/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9458 - val_loss: 0.1306 - val_accuracy: 0.9500\n",
            "Epoch 378/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9472 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
            "Epoch 379/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9444 - val_loss: 0.1261 - val_accuracy: 0.9500\n",
            "Epoch 380/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9458 - val_loss: 0.1255 - val_accuracy: 0.9500\n",
            "Epoch 381/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9444 - val_loss: 0.1267 - val_accuracy: 0.9500\n",
            "Epoch 382/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9472 - val_loss: 0.1278 - val_accuracy: 0.9500\n",
            "Epoch 383/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9458 - val_loss: 0.1304 - val_accuracy: 0.9500\n",
            "Epoch 384/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9472 - val_loss: 0.1270 - val_accuracy: 0.9500\n",
            "Epoch 385/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9458 - val_loss: 0.1278 - val_accuracy: 0.9500\n",
            "Epoch 386/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9458 - val_loss: 0.1271 - val_accuracy: 0.9500\n",
            "Epoch 387/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9444 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
            "Epoch 388/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9444 - val_loss: 0.1273 - val_accuracy: 0.9500\n",
            "Epoch 389/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9472 - val_loss: 0.1279 - val_accuracy: 0.9500\n",
            "Epoch 390/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9472 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
            "Epoch 391/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9458 - val_loss: 0.1261 - val_accuracy: 0.9500\n",
            "Epoch 392/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9444 - val_loss: 0.1253 - val_accuracy: 0.9500\n",
            "Epoch 393/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 394/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9444 - val_loss: 0.1262 - val_accuracy: 0.9500\n",
            "Epoch 395/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9458 - val_loss: 0.1241 - val_accuracy: 0.9500\n",
            "Epoch 396/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 397/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 398/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9444 - val_loss: 0.1236 - val_accuracy: 0.9500\n",
            "Epoch 399/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9458 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
            "Epoch 400/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9444 - val_loss: 0.1251 - val_accuracy: 0.9500\n",
            "Epoch 401/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 402/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9431 - val_loss: 0.1252 - val_accuracy: 0.9500\n",
            "Epoch 403/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9458 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 404/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9458 - val_loss: 0.1245 - val_accuracy: 0.9500\n",
            "Epoch 405/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9444 - val_loss: 0.1252 - val_accuracy: 0.9500\n",
            "Epoch 406/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9444 - val_loss: 0.1254 - val_accuracy: 0.9500\n",
            "Epoch 407/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9458 - val_loss: 0.1276 - val_accuracy: 0.9500\n",
            "Epoch 408/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9472 - val_loss: 0.1258 - val_accuracy: 0.9500\n",
            "Epoch 409/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9472 - val_loss: 0.1260 - val_accuracy: 0.9500\n",
            "Epoch 410/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9444 - val_loss: 0.1258 - val_accuracy: 0.9500\n",
            "Epoch 411/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9472 - val_loss: 0.1265 - val_accuracy: 0.9500\n",
            "Epoch 412/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9472 - val_loss: 0.1262 - val_accuracy: 0.9500\n",
            "Epoch 413/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9458 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 414/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9444 - val_loss: 0.1259 - val_accuracy: 0.9500\n",
            "Epoch 415/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9458 - val_loss: 0.1243 - val_accuracy: 0.9500\n",
            "Epoch 416/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9458 - val_loss: 0.1245 - val_accuracy: 0.9500\n",
            "Epoch 417/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9458 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
            "Epoch 418/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 419/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9444 - val_loss: 0.1241 - val_accuracy: 0.9500\n",
            "Epoch 420/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1311 - accuracy: 0.9458 - val_loss: 0.1235 - val_accuracy: 0.9500\n",
            "Epoch 421/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9444 - val_loss: 0.1269 - val_accuracy: 0.9500\n",
            "Epoch 422/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9444 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
            "Epoch 423/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9458 - val_loss: 0.1261 - val_accuracy: 0.9500\n",
            "Epoch 424/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9444 - val_loss: 0.1275 - val_accuracy: 0.9500\n",
            "Epoch 425/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9486 - val_loss: 0.1254 - val_accuracy: 0.9500\n",
            "Epoch 426/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9458 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
            "Epoch 427/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9444 - val_loss: 0.1226 - val_accuracy: 0.9500\n",
            "Epoch 428/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9444 - val_loss: 0.1206 - val_accuracy: 0.9625\n",
            "Epoch 429/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9444 - val_loss: 0.1219 - val_accuracy: 0.9500\n",
            "Epoch 430/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9444 - val_loss: 0.1227 - val_accuracy: 0.9500\n",
            "Epoch 431/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9444 - val_loss: 0.1235 - val_accuracy: 0.9500\n",
            "Epoch 432/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9444 - val_loss: 0.1247 - val_accuracy: 0.9500\n",
            "Epoch 433/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9444 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 434/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9444 - val_loss: 0.1254 - val_accuracy: 0.9500\n",
            "Epoch 435/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9458 - val_loss: 0.1250 - val_accuracy: 0.9500\n",
            "Epoch 436/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9458 - val_loss: 0.1239 - val_accuracy: 0.9500\n",
            "Epoch 437/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9444 - val_loss: 0.1228 - val_accuracy: 0.9500\n",
            "Epoch 438/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9458 - val_loss: 0.1233 - val_accuracy: 0.9500\n",
            "Epoch 439/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9458 - val_loss: 0.1236 - val_accuracy: 0.9500\n",
            "Epoch 440/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9444 - val_loss: 0.1236 - val_accuracy: 0.9500\n",
            "Epoch 441/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9458 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 442/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9458 - val_loss: 0.1255 - val_accuracy: 0.9500\n",
            "Epoch 443/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9458 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 444/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9444 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 445/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9444 - val_loss: 0.1267 - val_accuracy: 0.9375\n",
            "Epoch 446/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9444 - val_loss: 0.1263 - val_accuracy: 0.9500\n",
            "Epoch 447/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9458 - val_loss: 0.1256 - val_accuracy: 0.9500\n",
            "Epoch 448/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9458 - val_loss: 0.1257 - val_accuracy: 0.9500\n",
            "Epoch 449/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9458 - val_loss: 0.1268 - val_accuracy: 0.9500\n",
            "Epoch 450/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9458 - val_loss: 0.1270 - val_accuracy: 0.9500\n",
            "Epoch 451/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9486 - val_loss: 0.1251 - val_accuracy: 0.9500\n",
            "Epoch 452/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9458 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 453/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9444 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
            "Epoch 454/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9458 - val_loss: 0.1220 - val_accuracy: 0.9500\n",
            "Epoch 455/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9458 - val_loss: 0.1229 - val_accuracy: 0.9500\n",
            "Epoch 456/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9458 - val_loss: 0.1211 - val_accuracy: 0.9625\n",
            "Epoch 457/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9431 - val_loss: 0.1218 - val_accuracy: 0.9500\n",
            "Epoch 458/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9431 - val_loss: 0.1221 - val_accuracy: 0.9500\n",
            "Epoch 459/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9458 - val_loss: 0.1213 - val_accuracy: 0.9625\n",
            "Epoch 460/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9444 - val_loss: 0.1218 - val_accuracy: 0.9500\n",
            "Epoch 461/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9458 - val_loss: 0.1209 - val_accuracy: 0.9625\n",
            "Epoch 462/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9431 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
            "Epoch 463/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1257 - val_accuracy: 0.9500\n",
            "Epoch 464/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9444 - val_loss: 0.1251 - val_accuracy: 0.9500\n",
            "Epoch 465/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9444 - val_loss: 0.1245 - val_accuracy: 0.9500\n",
            "Epoch 466/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9444 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 467/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9444 - val_loss: 0.1237 - val_accuracy: 0.9500\n",
            "Epoch 468/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9444 - val_loss: 0.1250 - val_accuracy: 0.9500\n",
            "Epoch 469/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1271 - val_accuracy: 0.9500\n",
            "Epoch 470/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9458 - val_loss: 0.1244 - val_accuracy: 0.9500\n",
            "Epoch 471/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1252 - val_accuracy: 0.9500\n",
            "Epoch 472/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1243 - val_accuracy: 0.9500\n",
            "Epoch 473/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9458 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 474/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9458 - val_loss: 0.1233 - val_accuracy: 0.9500\n",
            "Epoch 475/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9444 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 476/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1232 - val_accuracy: 0.9500\n",
            "Epoch 477/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9444 - val_loss: 0.1247 - val_accuracy: 0.9500\n",
            "Epoch 478/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1301 - accuracy: 0.9472 - val_loss: 0.1235 - val_accuracy: 0.9500\n",
            "Epoch 479/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 480/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9458 - val_loss: 0.1193 - val_accuracy: 0.9625\n",
            "Epoch 481/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9444 - val_loss: 0.1233 - val_accuracy: 0.9500\n",
            "Epoch 482/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9444 - val_loss: 0.1215 - val_accuracy: 0.9625\n",
            "Epoch 483/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9431 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 484/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1236 - val_accuracy: 0.9500\n",
            "Epoch 485/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9458 - val_loss: 0.1258 - val_accuracy: 0.9500\n",
            "Epoch 486/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9472 - val_loss: 0.1236 - val_accuracy: 0.9500\n",
            "Epoch 487/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9444 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
            "Epoch 488/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9458 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
            "Epoch 489/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9458 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
            "Epoch 490/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9444 - val_loss: 0.1260 - val_accuracy: 0.9500\n",
            "Epoch 491/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9458 - val_loss: 0.1230 - val_accuracy: 0.9500\n",
            "Epoch 492/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9458 - val_loss: 0.1220 - val_accuracy: 0.9500\n",
            "Epoch 493/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9444 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 494/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1221 - val_accuracy: 0.9500\n",
            "Epoch 495/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9444 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
            "Epoch 496/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9444 - val_loss: 0.1201 - val_accuracy: 0.9625\n",
            "Epoch 497/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9431 - val_loss: 0.1212 - val_accuracy: 0.9500\n",
            "Epoch 498/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9444 - val_loss: 0.1206 - val_accuracy: 0.9625\n",
            "Epoch 499/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9444 - val_loss: 0.1197 - val_accuracy: 0.9625\n",
            "Epoch 500/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9431 - val_loss: 0.1200 - val_accuracy: 0.9625\n",
            "Epoch 501/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9431 - val_loss: 0.1222 - val_accuracy: 0.9500\n",
            "Epoch 502/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9458 - val_loss: 0.1226 - val_accuracy: 0.9500\n",
            "Epoch 503/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1228 - val_accuracy: 0.9500\n",
            "Epoch 504/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.9458 - val_loss: 0.1214 - val_accuracy: 0.9500\n",
            "Epoch 505/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9444 - val_loss: 0.1203 - val_accuracy: 0.9625\n",
            "Epoch 506/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1233 - val_accuracy: 0.9500\n",
            "Epoch 507/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1252 - val_accuracy: 0.9500\n",
            "Epoch 508/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1260 - val_accuracy: 0.9500\n",
            "Epoch 509/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9472 - val_loss: 0.1255 - val_accuracy: 0.9500\n",
            "Epoch 510/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9458 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
            "Epoch 511/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 512/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1247 - val_accuracy: 0.9500\n",
            "Epoch 513/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9458 - val_loss: 0.1231 - val_accuracy: 0.9500\n",
            "Epoch 514/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1299 - accuracy: 0.9458 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
            "Epoch 515/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1252 - val_accuracy: 0.9500\n",
            "Epoch 516/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1249 - val_accuracy: 0.9500\n",
            "Epoch 517/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9458 - val_loss: 0.1215 - val_accuracy: 0.9500\n",
            "Epoch 518/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9458 - val_loss: 0.1201 - val_accuracy: 0.9625\n",
            "Epoch 519/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9431 - val_loss: 0.1220 - val_accuracy: 0.9500\n",
            "Epoch 520/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1229 - val_accuracy: 0.9500\n",
            "Epoch 521/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1202 - val_accuracy: 0.9625\n",
            "Epoch 522/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9431 - val_loss: 0.1212 - val_accuracy: 0.9500\n",
            "Epoch 523/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9444 - val_loss: 0.1211 - val_accuracy: 0.9500\n",
            "Epoch 524/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1215 - val_accuracy: 0.9500\n",
            "Epoch 525/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1220 - val_accuracy: 0.9500\n",
            "Epoch 526/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9458 - val_loss: 0.1214 - val_accuracy: 0.9500\n",
            "Epoch 527/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1233 - val_accuracy: 0.9500\n",
            "Epoch 528/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9458 - val_loss: 0.1222 - val_accuracy: 0.9500\n",
            "Epoch 529/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9431 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
            "Epoch 530/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9444 - val_loss: 0.1212 - val_accuracy: 0.9500\n",
            "Epoch 531/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9444 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
            "Epoch 532/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9431 - val_loss: 0.1239 - val_accuracy: 0.9500\n",
            "Epoch 533/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.9444 - val_loss: 0.1237 - val_accuracy: 0.9500\n",
            "Epoch 534/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9444 - val_loss: 0.1258 - val_accuracy: 0.9500\n",
            "Epoch 535/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9472 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
            "Epoch 536/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9444 - val_loss: 0.1214 - val_accuracy: 0.9500\n",
            "Epoch 537/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1220 - val_accuracy: 0.9500\n",
            "Epoch 538/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9458 - val_loss: 0.1214 - val_accuracy: 0.9500\n",
            "Epoch 539/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9431 - val_loss: 0.1224 - val_accuracy: 0.9500\n",
            "Epoch 540/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9431 - val_loss: 0.1235 - val_accuracy: 0.9500\n",
            "Epoch 541/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9472 - val_loss: 0.1233 - val_accuracy: 0.9500\n",
            "Epoch 542/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9458 - val_loss: 0.1227 - val_accuracy: 0.9500\n",
            "Epoch 543/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9458 - val_loss: 0.1223 - val_accuracy: 0.9500\n",
            "Epoch 544/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9444 - val_loss: 0.1221 - val_accuracy: 0.9500\n",
            "Epoch 545/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9431 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 546/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
            "Epoch 547/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9444 - val_loss: 0.1247 - val_accuracy: 0.9500\n",
            "Epoch 548/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9444 - val_loss: 0.1246 - val_accuracy: 0.9500\n",
            "Epoch 549/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9431 - val_loss: 0.1270 - val_accuracy: 0.9500\n",
            "Epoch 550/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9458 - val_loss: 0.1237 - val_accuracy: 0.9500\n",
            "Epoch 551/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9458 - val_loss: 0.1231 - val_accuracy: 0.9500\n",
            "Epoch 552/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9444 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 553/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9431 - val_loss: 0.1241 - val_accuracy: 0.9500\n",
            "Epoch 554/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9458 - val_loss: 0.1237 - val_accuracy: 0.9500\n",
            "Epoch 555/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9458 - val_loss: 0.1253 - val_accuracy: 0.9500\n",
            "Epoch 556/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9472 - val_loss: 0.1249 - val_accuracy: 0.9500\n",
            "Epoch 557/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9472 - val_loss: 0.1241 - val_accuracy: 0.9500\n",
            "Epoch 558/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9444 - val_loss: 0.1243 - val_accuracy: 0.9500\n",
            "Epoch 559/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9458 - val_loss: 0.1254 - val_accuracy: 0.9500\n",
            "Epoch 560/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9458 - val_loss: 0.1245 - val_accuracy: 0.9500\n",
            "Epoch 561/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9472 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
            "Epoch 562/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9458 - val_loss: 0.1235 - val_accuracy: 0.9500\n",
            "Epoch 563/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9458 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 564/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9458 - val_loss: 0.1209 - val_accuracy: 0.9625\n",
            "Epoch 565/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9444 - val_loss: 0.1230 - val_accuracy: 0.9500\n",
            "Epoch 566/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9444 - val_loss: 0.1212 - val_accuracy: 0.9625\n",
            "Epoch 567/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9458 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
            "Epoch 568/570\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1292 - accuracy: 0.9458 - val_loss: 0.1227 - val_accuracy: 0.9500\n",
            "Epoch 569/570\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9444 - val_loss: 0.1224 - val_accuracy: 0.9500\n",
            "Epoch 570/570\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9444 - val_loss: 0.1243 - val_accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36b0c41790>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D5ICaRXWOQV",
        "outputId": "cfe6970a-c8e5-43c0-b1df-8c66ba8fd3c1"
      },
      "source": [
        "#MODEL 2 STANDARD LIBRARY\n",
        "my_model_2_stdlib = keras.Sequential()\n",
        "# Your code here!\n",
        "my_model_2_stdlib.add(keras.layers.Dense(2, activation=\"tanh\", input_dim=2))\n",
        "my_model_2_stdlib.add(keras.layers.Dense(280, activation=\"tanh\"))\n",
        "my_model_2_stdlib.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
        "\n",
        "my_model_2_stdlib.compile(loss=\"sparse_categorical_crossentropy\" ,\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "my_model_2_stdlib.fit(X_train, y_train, batch_size=64, epochs=800,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6941 - accuracy: 0.4181 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 2/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5542 - val_loss: 0.6906 - val_accuracy: 0.5500\n",
            "Epoch 3/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5333 - val_loss: 0.6882 - val_accuracy: 0.6625\n",
            "Epoch 4/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.5736 - val_loss: 0.6868 - val_accuracy: 0.6500\n",
            "Epoch 5/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.6417 - val_loss: 0.6855 - val_accuracy: 0.6000\n",
            "Epoch 6/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6431 - val_loss: 0.6830 - val_accuracy: 0.6625\n",
            "Epoch 7/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6417 - val_loss: 0.6815 - val_accuracy: 0.6625\n",
            "Epoch 8/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5944 - val_loss: 0.6790 - val_accuracy: 0.7000\n",
            "Epoch 9/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6444 - val_loss: 0.6773 - val_accuracy: 0.7125\n",
            "Epoch 10/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6639 - val_loss: 0.6761 - val_accuracy: 0.7000\n",
            "Epoch 11/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.6431 - val_loss: 0.6747 - val_accuracy: 0.7125\n",
            "Epoch 12/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.6611 - val_loss: 0.6740 - val_accuracy: 0.7000\n",
            "Epoch 13/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6569 - val_loss: 0.6732 - val_accuracy: 0.6625\n",
            "Epoch 14/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.6278 - val_loss: 0.6719 - val_accuracy: 0.6625\n",
            "Epoch 15/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.6250 - val_loss: 0.6718 - val_accuracy: 0.6500\n",
            "Epoch 16/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.6014 - val_loss: 0.6705 - val_accuracy: 0.6500\n",
            "Epoch 17/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.6097 - val_loss: 0.6692 - val_accuracy: 0.6500\n",
            "Epoch 18/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.6222 - val_loss: 0.6681 - val_accuracy: 0.6500\n",
            "Epoch 19/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.5986 - val_loss: 0.6665 - val_accuracy: 0.6625\n",
            "Epoch 20/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6083 - val_loss: 0.6637 - val_accuracy: 0.7000\n",
            "Epoch 21/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6375 - val_loss: 0.6627 - val_accuracy: 0.6750\n",
            "Epoch 22/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.6319 - val_loss: 0.6621 - val_accuracy: 0.6625\n",
            "Epoch 23/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6167 - val_loss: 0.6602 - val_accuracy: 0.6625\n",
            "Epoch 24/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.6319 - val_loss: 0.6604 - val_accuracy: 0.6625\n",
            "Epoch 25/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6069 - val_loss: 0.6590 - val_accuracy: 0.6625\n",
            "Epoch 26/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6264 - val_loss: 0.6575 - val_accuracy: 0.6625\n",
            "Epoch 27/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6361 - val_loss: 0.6580 - val_accuracy: 0.6500\n",
            "Epoch 28/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.5931 - val_loss: 0.6562 - val_accuracy: 0.6625\n",
            "Epoch 29/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.6083 - val_loss: 0.6552 - val_accuracy: 0.6625\n",
            "Epoch 30/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6111 - val_loss: 0.6538 - val_accuracy: 0.6625\n",
            "Epoch 31/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.6111 - val_loss: 0.6518 - val_accuracy: 0.6625\n",
            "Epoch 32/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6153 - val_loss: 0.6508 - val_accuracy: 0.6625\n",
            "Epoch 33/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6236 - val_loss: 0.6504 - val_accuracy: 0.6625\n",
            "Epoch 34/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.6000 - val_loss: 0.6499 - val_accuracy: 0.6500\n",
            "Epoch 35/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.5944 - val_loss: 0.6479 - val_accuracy: 0.6625\n",
            "Epoch 36/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.5972 - val_loss: 0.6466 - val_accuracy: 0.6625\n",
            "Epoch 37/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6056 - val_loss: 0.6456 - val_accuracy: 0.6625\n",
            "Epoch 38/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6056 - val_loss: 0.6433 - val_accuracy: 0.6625\n",
            "Epoch 39/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6181 - val_loss: 0.6433 - val_accuracy: 0.6625\n",
            "Epoch 40/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6028 - val_loss: 0.6429 - val_accuracy: 0.6500\n",
            "Epoch 41/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.5875 - val_loss: 0.6414 - val_accuracy: 0.6500\n",
            "Epoch 42/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6014 - val_loss: 0.6393 - val_accuracy: 0.6625\n",
            "Epoch 43/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.5889 - val_loss: 0.6374 - val_accuracy: 0.6625\n",
            "Epoch 44/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6236 - val_loss: 0.6369 - val_accuracy: 0.6625\n",
            "Epoch 45/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6153 - val_loss: 0.6359 - val_accuracy: 0.6625\n",
            "Epoch 46/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6208 - val_loss: 0.6345 - val_accuracy: 0.6625\n",
            "Epoch 47/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6042 - val_loss: 0.6327 - val_accuracy: 0.6625\n",
            "Epoch 48/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6292 - val_loss: 0.6330 - val_accuracy: 0.6500\n",
            "Epoch 49/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6097 - val_loss: 0.6323 - val_accuracy: 0.6375\n",
            "Epoch 50/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6069 - val_loss: 0.6320 - val_accuracy: 0.6125\n",
            "Epoch 51/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.5931 - val_loss: 0.6312 - val_accuracy: 0.6000\n",
            "Epoch 52/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.5806 - val_loss: 0.6291 - val_accuracy: 0.6375\n",
            "Epoch 53/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.5792 - val_loss: 0.6267 - val_accuracy: 0.6625\n",
            "Epoch 54/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.5986 - val_loss: 0.6247 - val_accuracy: 0.6625\n",
            "Epoch 55/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6194 - val_loss: 0.6242 - val_accuracy: 0.6625\n",
            "Epoch 56/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6111 - val_loss: 0.6225 - val_accuracy: 0.6625\n",
            "Epoch 57/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.5972 - val_loss: 0.6208 - val_accuracy: 0.6625\n",
            "Epoch 58/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6097 - val_loss: 0.6198 - val_accuracy: 0.6625\n",
            "Epoch 59/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6278 - val_loss: 0.6186 - val_accuracy: 0.6625\n",
            "Epoch 60/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6222 - val_loss: 0.6191 - val_accuracy: 0.6500\n",
            "Epoch 61/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.5889 - val_loss: 0.6172 - val_accuracy: 0.6625\n",
            "Epoch 62/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6056 - val_loss: 0.6163 - val_accuracy: 0.6500\n",
            "Epoch 63/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.5917 - val_loss: 0.6148 - val_accuracy: 0.6500\n",
            "Epoch 64/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6111 - val_loss: 0.6137 - val_accuracy: 0.6625\n",
            "Epoch 65/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.6125 - val_loss: 0.6123 - val_accuracy: 0.6625\n",
            "Epoch 66/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6194 - val_loss: 0.6107 - val_accuracy: 0.6625\n",
            "Epoch 67/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.5931 - val_loss: 0.6092 - val_accuracy: 0.6625\n",
            "Epoch 68/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6014 - val_loss: 0.6063 - val_accuracy: 0.6625\n",
            "Epoch 69/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6319 - val_loss: 0.6050 - val_accuracy: 0.6625\n",
            "Epoch 70/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.6319 - val_loss: 0.6040 - val_accuracy: 0.6625\n",
            "Epoch 71/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6292 - val_loss: 0.6026 - val_accuracy: 0.6625\n",
            "Epoch 72/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6278 - val_loss: 0.6006 - val_accuracy: 0.7000\n",
            "Epoch 73/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6333 - val_loss: 0.6000 - val_accuracy: 0.6625\n",
            "Epoch 74/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.6292 - val_loss: 0.5992 - val_accuracy: 0.6625\n",
            "Epoch 75/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6319 - val_loss: 0.5973 - val_accuracy: 0.6750\n",
            "Epoch 76/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6319 - val_loss: 0.5958 - val_accuracy: 0.6875\n",
            "Epoch 77/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.6389 - val_loss: 0.5951 - val_accuracy: 0.6625\n",
            "Epoch 78/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6292 - val_loss: 0.5934 - val_accuracy: 0.6875\n",
            "Epoch 79/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6278 - val_loss: 0.5913 - val_accuracy: 0.7000\n",
            "Epoch 80/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6319 - val_loss: 0.5897 - val_accuracy: 0.7000\n",
            "Epoch 81/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.6431 - val_loss: 0.5891 - val_accuracy: 0.7000\n",
            "Epoch 82/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6361 - val_loss: 0.5887 - val_accuracy: 0.6625\n",
            "Epoch 83/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6333 - val_loss: 0.5903 - val_accuracy: 0.6500\n",
            "Epoch 84/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.5986 - val_loss: 0.5886 - val_accuracy: 0.6625\n",
            "Epoch 85/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6125 - val_loss: 0.5869 - val_accuracy: 0.6625\n",
            "Epoch 86/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.6069 - val_loss: 0.5846 - val_accuracy: 0.6625\n",
            "Epoch 87/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.6278 - val_loss: 0.5829 - val_accuracy: 0.6625\n",
            "Epoch 88/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6250 - val_loss: 0.5805 - val_accuracy: 0.6875\n",
            "Epoch 89/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6319 - val_loss: 0.5792 - val_accuracy: 0.7000\n",
            "Epoch 90/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6375 - val_loss: 0.5790 - val_accuracy: 0.6625\n",
            "Epoch 91/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.6194 - val_loss: 0.5776 - val_accuracy: 0.6750\n",
            "Epoch 92/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6278 - val_loss: 0.5767 - val_accuracy: 0.6625\n",
            "Epoch 93/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.6306 - val_loss: 0.5766 - val_accuracy: 0.6625\n",
            "Epoch 94/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6194 - val_loss: 0.5756 - val_accuracy: 0.6625\n",
            "Epoch 95/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.5861 - val_loss: 0.5716 - val_accuracy: 0.7000\n",
            "Epoch 96/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6417 - val_loss: 0.5701 - val_accuracy: 0.7000\n",
            "Epoch 97/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6458 - val_loss: 0.5699 - val_accuracy: 0.6750\n",
            "Epoch 98/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.6292 - val_loss: 0.5685 - val_accuracy: 0.6750\n",
            "Epoch 99/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.6361 - val_loss: 0.5687 - val_accuracy: 0.6625\n",
            "Epoch 100/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.6208 - val_loss: 0.5666 - val_accuracy: 0.6750\n",
            "Epoch 101/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6292 - val_loss: 0.5656 - val_accuracy: 0.6750\n",
            "Epoch 102/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.6333 - val_loss: 0.5636 - val_accuracy: 0.6875\n",
            "Epoch 103/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.6458 - val_loss: 0.5632 - val_accuracy: 0.6750\n",
            "Epoch 104/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.6222 - val_loss: 0.5614 - val_accuracy: 0.6875\n",
            "Epoch 105/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.6403 - val_loss: 0.5608 - val_accuracy: 0.6750\n",
            "Epoch 106/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.6306 - val_loss: 0.5587 - val_accuracy: 0.7000\n",
            "Epoch 107/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6431 - val_loss: 0.5583 - val_accuracy: 0.6750\n",
            "Epoch 108/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6389 - val_loss: 0.5581 - val_accuracy: 0.6625\n",
            "Epoch 109/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.6222 - val_loss: 0.5574 - val_accuracy: 0.6625\n",
            "Epoch 110/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.6222 - val_loss: 0.5560 - val_accuracy: 0.6625\n",
            "Epoch 111/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.6250 - val_loss: 0.5555 - val_accuracy: 0.6500\n",
            "Epoch 112/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6153 - val_loss: 0.5544 - val_accuracy: 0.6625\n",
            "Epoch 113/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.6083 - val_loss: 0.5531 - val_accuracy: 0.6625\n",
            "Epoch 114/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.6153 - val_loss: 0.5526 - val_accuracy: 0.6250\n",
            "Epoch 115/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.6042 - val_loss: 0.5502 - val_accuracy: 0.6625\n",
            "Epoch 116/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.6236 - val_loss: 0.5487 - val_accuracy: 0.6750\n",
            "Epoch 117/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.6236 - val_loss: 0.5463 - val_accuracy: 0.6750\n",
            "Epoch 118/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.6389 - val_loss: 0.5454 - val_accuracy: 0.6750\n",
            "Epoch 119/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.6306 - val_loss: 0.5451 - val_accuracy: 0.6750\n",
            "Epoch 120/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.6389 - val_loss: 0.5451 - val_accuracy: 0.6250\n",
            "Epoch 121/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.6181 - val_loss: 0.5446 - val_accuracy: 0.6250\n",
            "Epoch 122/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.6014 - val_loss: 0.5437 - val_accuracy: 0.6250\n",
            "Epoch 123/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.5931 - val_loss: 0.5414 - val_accuracy: 0.6500\n",
            "Epoch 124/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.6069 - val_loss: 0.5403 - val_accuracy: 0.6500\n",
            "Epoch 125/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5492 - accuracy: 0.6236 - val_loss: 0.5401 - val_accuracy: 0.6250\n",
            "Epoch 126/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.5847 - val_loss: 0.5368 - val_accuracy: 0.6750\n",
            "Epoch 127/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.6278 - val_loss: 0.5358 - val_accuracy: 0.6750\n",
            "Epoch 128/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.6292 - val_loss: 0.5343 - val_accuracy: 0.6750\n",
            "Epoch 129/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.6403 - val_loss: 0.5338 - val_accuracy: 0.6750\n",
            "Epoch 130/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.6319 - val_loss: 0.5331 - val_accuracy: 0.6750\n",
            "Epoch 131/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.6264 - val_loss: 0.5317 - val_accuracy: 0.6750\n",
            "Epoch 132/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.6375 - val_loss: 0.5300 - val_accuracy: 0.6750\n",
            "Epoch 133/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.6389 - val_loss: 0.5301 - val_accuracy: 0.6625\n",
            "Epoch 134/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.6278 - val_loss: 0.5284 - val_accuracy: 0.6750\n",
            "Epoch 135/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.6458 - val_loss: 0.5279 - val_accuracy: 0.6625\n",
            "Epoch 136/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.6361 - val_loss: 0.5269 - val_accuracy: 0.6625\n",
            "Epoch 137/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.6292 - val_loss: 0.5259 - val_accuracy: 0.6625\n",
            "Epoch 138/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.6306 - val_loss: 0.5249 - val_accuracy: 0.6625\n",
            "Epoch 139/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.6292 - val_loss: 0.5231 - val_accuracy: 0.6875\n",
            "Epoch 140/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.6389 - val_loss: 0.5215 - val_accuracy: 0.7000\n",
            "Epoch 141/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.6667 - val_loss: 0.5219 - val_accuracy: 0.6625\n",
            "Epoch 142/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.6431 - val_loss: 0.5211 - val_accuracy: 0.6625\n",
            "Epoch 143/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.6333 - val_loss: 0.5201 - val_accuracy: 0.6625\n",
            "Epoch 144/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.6458 - val_loss: 0.5197 - val_accuracy: 0.6500\n",
            "Epoch 145/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.6264 - val_loss: 0.5178 - val_accuracy: 0.6750\n",
            "Epoch 146/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.6542 - val_loss: 0.5178 - val_accuracy: 0.6500\n",
            "Epoch 147/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.6333 - val_loss: 0.5165 - val_accuracy: 0.6500\n",
            "Epoch 148/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.6278 - val_loss: 0.5163 - val_accuracy: 0.6375\n",
            "Epoch 149/800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.6375 - val_loss: 0.5169 - val_accuracy: 0.6125\n",
            "Epoch 150/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.5806 - val_loss: 0.5162 - val_accuracy: 0.6000\n",
            "Epoch 151/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.5653 - val_loss: 0.5137 - val_accuracy: 0.6375\n",
            "Epoch 152/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.6208 - val_loss: 0.5123 - val_accuracy: 0.6500\n",
            "Epoch 153/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.6375 - val_loss: 0.5108 - val_accuracy: 0.6500\n",
            "Epoch 154/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.6347 - val_loss: 0.5097 - val_accuracy: 0.6625\n",
            "Epoch 155/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.6389 - val_loss: 0.5086 - val_accuracy: 0.6875\n",
            "Epoch 156/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.6625 - val_loss: 0.5099 - val_accuracy: 0.6250\n",
            "Epoch 157/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.6458 - val_loss: 0.5113 - val_accuracy: 0.5375\n",
            "Epoch 158/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.5653 - val_loss: 0.5090 - val_accuracy: 0.5875\n",
            "Epoch 159/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.6125 - val_loss: 0.5080 - val_accuracy: 0.6000\n",
            "Epoch 160/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.6097 - val_loss: 0.5101 - val_accuracy: 0.5375\n",
            "Epoch 161/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.5375 - val_loss: 0.5055 - val_accuracy: 0.6250\n",
            "Epoch 162/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.6167 - val_loss: 0.5036 - val_accuracy: 0.6500\n",
            "Epoch 163/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.6319 - val_loss: 0.5017 - val_accuracy: 0.6875\n",
            "Epoch 164/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.6639 - val_loss: 0.5035 - val_accuracy: 0.6125\n",
            "Epoch 165/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.5958 - val_loss: 0.5032 - val_accuracy: 0.5875\n",
            "Epoch 166/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.5653 - val_loss: 0.5006 - val_accuracy: 0.6500\n",
            "Epoch 167/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.6250 - val_loss: 0.4993 - val_accuracy: 0.6375\n",
            "Epoch 168/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.6472 - val_loss: 0.4989 - val_accuracy: 0.6500\n",
            "Epoch 169/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.6278 - val_loss: 0.4969 - val_accuracy: 0.7000\n",
            "Epoch 170/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.6528 - val_loss: 0.4975 - val_accuracy: 0.6500\n",
            "Epoch 171/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.6431 - val_loss: 0.4981 - val_accuracy: 0.5875\n",
            "Epoch 172/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.6194 - val_loss: 0.4974 - val_accuracy: 0.5875\n",
            "Epoch 173/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.5917 - val_loss: 0.4970 - val_accuracy: 0.5750\n",
            "Epoch 174/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.5931 - val_loss: 0.4959 - val_accuracy: 0.5875\n",
            "Epoch 175/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.6028 - val_loss: 0.4953 - val_accuracy: 0.5750\n",
            "Epoch 176/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.5917 - val_loss: 0.4937 - val_accuracy: 0.6000\n",
            "Epoch 177/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.6111 - val_loss: 0.4923 - val_accuracy: 0.6375\n",
            "Epoch 178/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.6278 - val_loss: 0.4914 - val_accuracy: 0.6500\n",
            "Epoch 179/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.6375 - val_loss: 0.4908 - val_accuracy: 0.6375\n",
            "Epoch 180/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.6264 - val_loss: 0.4907 - val_accuracy: 0.5875\n",
            "Epoch 181/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.6139 - val_loss: 0.4903 - val_accuracy: 0.5875\n",
            "Epoch 182/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.6375 - val_loss: 0.4896 - val_accuracy: 0.5875\n",
            "Epoch 183/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.6208 - val_loss: 0.4886 - val_accuracy: 0.6125\n",
            "Epoch 184/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.6361 - val_loss: 0.4867 - val_accuracy: 0.7000\n",
            "Epoch 185/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.6736 - val_loss: 0.4869 - val_accuracy: 0.6625\n",
            "Epoch 186/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.6569 - val_loss: 0.4874 - val_accuracy: 0.5625\n",
            "Epoch 187/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.6194 - val_loss: 0.4860 - val_accuracy: 0.6250\n",
            "Epoch 188/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.6264 - val_loss: 0.4868 - val_accuracy: 0.5750\n",
            "Epoch 189/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.6042 - val_loss: 0.4851 - val_accuracy: 0.5875\n",
            "Epoch 190/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.6222 - val_loss: 0.4850 - val_accuracy: 0.5625\n",
            "Epoch 191/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.6153 - val_loss: 0.4839 - val_accuracy: 0.5750\n",
            "Epoch 192/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.6306 - val_loss: 0.4836 - val_accuracy: 0.5625\n",
            "Epoch 193/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.6236 - val_loss: 0.4821 - val_accuracy: 0.6125\n",
            "Epoch 194/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.6375 - val_loss: 0.4820 - val_accuracy: 0.5875\n",
            "Epoch 195/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.6611 - val_loss: 0.4833 - val_accuracy: 0.5875\n",
            "Epoch 196/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.6139 - val_loss: 0.4834 - val_accuracy: 0.6000\n",
            "Epoch 197/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.6139 - val_loss: 0.4810 - val_accuracy: 0.6000\n",
            "Epoch 198/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.6361 - val_loss: 0.4819 - val_accuracy: 0.6000\n",
            "Epoch 199/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.6125 - val_loss: 0.4796 - val_accuracy: 0.6000\n",
            "Epoch 200/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.6319 - val_loss: 0.4801 - val_accuracy: 0.6000\n",
            "Epoch 201/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.6194 - val_loss: 0.4776 - val_accuracy: 0.6500\n",
            "Epoch 202/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.6625 - val_loss: 0.4771 - val_accuracy: 0.6125\n",
            "Epoch 203/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.6500 - val_loss: 0.4766 - val_accuracy: 0.6125\n",
            "Epoch 204/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.6528 - val_loss: 0.4750 - val_accuracy: 0.7000\n",
            "Epoch 205/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.6792 - val_loss: 0.4752 - val_accuracy: 0.6500\n",
            "Epoch 206/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.6639 - val_loss: 0.4768 - val_accuracy: 0.6250\n",
            "Epoch 207/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.6403 - val_loss: 0.4779 - val_accuracy: 0.6125\n",
            "Epoch 208/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.6236 - val_loss: 0.4767 - val_accuracy: 0.6125\n",
            "Epoch 209/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.6306 - val_loss: 0.4756 - val_accuracy: 0.6250\n",
            "Epoch 210/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.6347 - val_loss: 0.4733 - val_accuracy: 0.6125\n",
            "Epoch 211/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.6542 - val_loss: 0.4731 - val_accuracy: 0.6250\n",
            "Epoch 212/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.6667 - val_loss: 0.4723 - val_accuracy: 0.6250\n",
            "Epoch 213/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.6556 - val_loss: 0.4719 - val_accuracy: 0.6375\n",
            "Epoch 214/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.6764 - val_loss: 0.4709 - val_accuracy: 0.6375\n",
            "Epoch 215/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.6667 - val_loss: 0.4706 - val_accuracy: 0.6375\n",
            "Epoch 216/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.6778 - val_loss: 0.4696 - val_accuracy: 0.6625\n",
            "Epoch 217/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.6778 - val_loss: 0.4704 - val_accuracy: 0.6375\n",
            "Epoch 218/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.6597 - val_loss: 0.4689 - val_accuracy: 0.6375\n",
            "Epoch 219/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.6750 - val_loss: 0.4681 - val_accuracy: 0.6625\n",
            "Epoch 220/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.6875 - val_loss: 0.4702 - val_accuracy: 0.6500\n",
            "Epoch 221/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.6528 - val_loss: 0.4677 - val_accuracy: 0.6375\n",
            "Epoch 222/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.6833 - val_loss: 0.4688 - val_accuracy: 0.6500\n",
            "Epoch 223/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.6708 - val_loss: 0.4678 - val_accuracy: 0.6500\n",
            "Epoch 224/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.6681 - val_loss: 0.4652 - val_accuracy: 0.6750\n",
            "Epoch 225/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.6986 - val_loss: 0.4649 - val_accuracy: 0.6750\n",
            "Epoch 226/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.6958 - val_loss: 0.4642 - val_accuracy: 0.6750\n",
            "Epoch 227/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.6972 - val_loss: 0.4648 - val_accuracy: 0.6500\n",
            "Epoch 228/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.6903 - val_loss: 0.4642 - val_accuracy: 0.6500\n",
            "Epoch 229/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7014 - val_loss: 0.4628 - val_accuracy: 0.6625\n",
            "Epoch 230/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7069 - val_loss: 0.4638 - val_accuracy: 0.6625\n",
            "Epoch 231/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7000 - val_loss: 0.4618 - val_accuracy: 0.6875\n",
            "Epoch 232/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7028 - val_loss: 0.4618 - val_accuracy: 0.6625\n",
            "Epoch 233/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7069 - val_loss: 0.4608 - val_accuracy: 0.6875\n",
            "Epoch 234/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7139 - val_loss: 0.4609 - val_accuracy: 0.6625\n",
            "Epoch 235/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7167 - val_loss: 0.4611 - val_accuracy: 0.6625\n",
            "Epoch 236/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7208 - val_loss: 0.4583 - val_accuracy: 0.7125\n",
            "Epoch 237/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7222 - val_loss: 0.4571 - val_accuracy: 0.7250\n",
            "Epoch 238/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7278 - val_loss: 0.4570 - val_accuracy: 0.7250\n",
            "Epoch 239/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7278 - val_loss: 0.4588 - val_accuracy: 0.7000\n",
            "Epoch 240/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7361 - val_loss: 0.4579 - val_accuracy: 0.6875\n",
            "Epoch 241/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7375 - val_loss: 0.4576 - val_accuracy: 0.7000\n",
            "Epoch 242/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7528 - val_loss: 0.4559 - val_accuracy: 0.7125\n",
            "Epoch 243/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7500 - val_loss: 0.4558 - val_accuracy: 0.7125\n",
            "Epoch 244/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7569 - val_loss: 0.4536 - val_accuracy: 0.7125\n",
            "Epoch 245/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7542 - val_loss: 0.4551 - val_accuracy: 0.6875\n",
            "Epoch 246/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7750 - val_loss: 0.4531 - val_accuracy: 0.7125\n",
            "Epoch 247/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7694 - val_loss: 0.4512 - val_accuracy: 0.7250\n",
            "Epoch 248/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7653 - val_loss: 0.4506 - val_accuracy: 0.7375\n",
            "Epoch 249/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7764 - val_loss: 0.4492 - val_accuracy: 0.7375\n",
            "Epoch 250/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7764 - val_loss: 0.4488 - val_accuracy: 0.7375\n",
            "Epoch 251/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4460 - val_accuracy: 0.7375\n",
            "Epoch 252/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7903 - val_loss: 0.4456 - val_accuracy: 0.7500\n",
            "Epoch 253/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7958 - val_loss: 0.4445 - val_accuracy: 0.7500\n",
            "Epoch 254/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8042 - val_loss: 0.4437 - val_accuracy: 0.7625\n",
            "Epoch 255/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8014 - val_loss: 0.4429 - val_accuracy: 0.7625\n",
            "Epoch 256/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8125 - val_loss: 0.4415 - val_accuracy: 0.7625\n",
            "Epoch 257/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8222 - val_loss: 0.4403 - val_accuracy: 0.7625\n",
            "Epoch 258/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8292 - val_loss: 0.4384 - val_accuracy: 0.7625\n",
            "Epoch 259/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8250 - val_loss: 0.4380 - val_accuracy: 0.7875\n",
            "Epoch 260/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8431 - val_loss: 0.4389 - val_accuracy: 0.8000\n",
            "Epoch 261/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8556 - val_loss: 0.4357 - val_accuracy: 0.7875\n",
            "Epoch 262/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8597 - val_loss: 0.4320 - val_accuracy: 0.8000\n",
            "Epoch 263/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8597 - val_loss: 0.4312 - val_accuracy: 0.8125\n",
            "Epoch 264/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8639 - val_loss: 0.4309 - val_accuracy: 0.8375\n",
            "Epoch 265/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8694 - val_loss: 0.4268 - val_accuracy: 0.8125\n",
            "Epoch 266/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8750 - val_loss: 0.4244 - val_accuracy: 0.8125\n",
            "Epoch 267/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8792 - val_loss: 0.4237 - val_accuracy: 0.8375\n",
            "Epoch 268/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8736 - val_loss: 0.4229 - val_accuracy: 0.8375\n",
            "Epoch 269/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8861 - val_loss: 0.4178 - val_accuracy: 0.8125\n",
            "Epoch 270/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8889 - val_loss: 0.4137 - val_accuracy: 0.8250\n",
            "Epoch 271/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8875 - val_loss: 0.4114 - val_accuracy: 0.8250\n",
            "Epoch 272/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8903 - val_loss: 0.4115 - val_accuracy: 0.8250\n",
            "Epoch 273/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.9000 - val_loss: 0.4080 - val_accuracy: 0.8250\n",
            "Epoch 274/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8986 - val_loss: 0.4032 - val_accuracy: 0.8375\n",
            "Epoch 275/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.9000 - val_loss: 0.4010 - val_accuracy: 0.8375\n",
            "Epoch 276/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.9042 - val_loss: 0.3972 - val_accuracy: 0.8375\n",
            "Epoch 277/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.9056 - val_loss: 0.3948 - val_accuracy: 0.8375\n",
            "Epoch 278/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.9167 - val_loss: 0.3884 - val_accuracy: 0.8375\n",
            "Epoch 279/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.9111 - val_loss: 0.3865 - val_accuracy: 0.8500\n",
            "Epoch 280/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.9153 - val_loss: 0.3847 - val_accuracy: 0.8625\n",
            "Epoch 281/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.9250 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
            "Epoch 282/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.9236 - val_loss: 0.3751 - val_accuracy: 0.8500\n",
            "Epoch 283/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.9236 - val_loss: 0.3709 - val_accuracy: 0.8375\n",
            "Epoch 284/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.9236 - val_loss: 0.3688 - val_accuracy: 0.8750\n",
            "Epoch 285/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.9333 - val_loss: 0.3651 - val_accuracy: 0.8750\n",
            "Epoch 286/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.9306 - val_loss: 0.3620 - val_accuracy: 0.8875\n",
            "Epoch 287/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.9306 - val_loss: 0.3578 - val_accuracy: 0.8625\n",
            "Epoch 288/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.9292 - val_loss: 0.3549 - val_accuracy: 0.8875\n",
            "Epoch 289/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.9306 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
            "Epoch 290/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3016 - accuracy: 0.9347 - val_loss: 0.3486 - val_accuracy: 0.8875\n",
            "Epoch 291/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.9347 - val_loss: 0.3460 - val_accuracy: 0.8875\n",
            "Epoch 292/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.9361 - val_loss: 0.3439 - val_accuracy: 0.9000\n",
            "Epoch 293/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.9361 - val_loss: 0.3402 - val_accuracy: 0.9000\n",
            "Epoch 294/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.9361 - val_loss: 0.3376 - val_accuracy: 0.9125\n",
            "Epoch 295/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.9361 - val_loss: 0.3352 - val_accuracy: 0.9000\n",
            "Epoch 296/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.9361 - val_loss: 0.3327 - val_accuracy: 0.9125\n",
            "Epoch 297/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.9375 - val_loss: 0.3279 - val_accuracy: 0.9125\n",
            "Epoch 298/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.9361 - val_loss: 0.3261 - val_accuracy: 0.9250\n",
            "Epoch 299/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.9375 - val_loss: 0.3224 - val_accuracy: 0.9125\n",
            "Epoch 300/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.9375 - val_loss: 0.3206 - val_accuracy: 0.9250\n",
            "Epoch 301/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.9361 - val_loss: 0.3172 - val_accuracy: 0.9250\n",
            "Epoch 302/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9361 - val_loss: 0.3144 - val_accuracy: 0.9125\n",
            "Epoch 303/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9389 - val_loss: 0.3118 - val_accuracy: 0.9125\n",
            "Epoch 304/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9389 - val_loss: 0.3108 - val_accuracy: 0.9125\n",
            "Epoch 305/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9375 - val_loss: 0.3090 - val_accuracy: 0.9125\n",
            "Epoch 306/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2520 - accuracy: 0.9389 - val_loss: 0.3057 - val_accuracy: 0.9125\n",
            "Epoch 307/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.9403 - val_loss: 0.3027 - val_accuracy: 0.9125\n",
            "Epoch 308/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9389 - val_loss: 0.2996 - val_accuracy: 0.9125\n",
            "Epoch 309/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2441 - accuracy: 0.9389 - val_loss: 0.2957 - val_accuracy: 0.9250\n",
            "Epoch 310/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9403 - val_loss: 0.2927 - val_accuracy: 0.9375\n",
            "Epoch 311/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9403 - val_loss: 0.2906 - val_accuracy: 0.9250\n",
            "Epoch 312/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2370 - accuracy: 0.9403 - val_loss: 0.2913 - val_accuracy: 0.9125\n",
            "Epoch 313/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2349 - accuracy: 0.9403 - val_loss: 0.2869 - val_accuracy: 0.9250\n",
            "Epoch 314/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9417 - val_loss: 0.2869 - val_accuracy: 0.9125\n",
            "Epoch 315/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9403 - val_loss: 0.2856 - val_accuracy: 0.9125\n",
            "Epoch 316/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2280 - accuracy: 0.9375 - val_loss: 0.2821 - val_accuracy: 0.9125\n",
            "Epoch 317/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9403 - val_loss: 0.2792 - val_accuracy: 0.9125\n",
            "Epoch 318/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9403 - val_loss: 0.2790 - val_accuracy: 0.9125\n",
            "Epoch 319/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9403 - val_loss: 0.2764 - val_accuracy: 0.9125\n",
            "Epoch 320/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2199 - accuracy: 0.9417 - val_loss: 0.2756 - val_accuracy: 0.9125\n",
            "Epoch 321/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2178 - accuracy: 0.9389 - val_loss: 0.2719 - val_accuracy: 0.9125\n",
            "Epoch 322/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9417 - val_loss: 0.2722 - val_accuracy: 0.9250\n",
            "Epoch 323/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2141 - accuracy: 0.9403 - val_loss: 0.2684 - val_accuracy: 0.9250\n",
            "Epoch 324/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9403 - val_loss: 0.2655 - val_accuracy: 0.9250\n",
            "Epoch 325/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9417 - val_loss: 0.2648 - val_accuracy: 0.9250\n",
            "Epoch 326/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9389 - val_loss: 0.2628 - val_accuracy: 0.9250\n",
            "Epoch 327/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9417 - val_loss: 0.2619 - val_accuracy: 0.9250\n",
            "Epoch 328/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9431 - val_loss: 0.2592 - val_accuracy: 0.9375\n",
            "Epoch 329/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2039 - accuracy: 0.9403 - val_loss: 0.2592 - val_accuracy: 0.9250\n",
            "Epoch 330/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.9431 - val_loss: 0.2577 - val_accuracy: 0.9250\n",
            "Epoch 331/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9417 - val_loss: 0.2548 - val_accuracy: 0.9375\n",
            "Epoch 332/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9431 - val_loss: 0.2545 - val_accuracy: 0.9250\n",
            "Epoch 333/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9431 - val_loss: 0.2523 - val_accuracy: 0.9250\n",
            "Epoch 334/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9403 - val_loss: 0.2501 - val_accuracy: 0.9375\n",
            "Epoch 335/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9431 - val_loss: 0.2495 - val_accuracy: 0.9375\n",
            "Epoch 336/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.9417 - val_loss: 0.2492 - val_accuracy: 0.9250\n",
            "Epoch 337/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9417 - val_loss: 0.2471 - val_accuracy: 0.9375\n",
            "Epoch 338/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1902 - accuracy: 0.9417 - val_loss: 0.2453 - val_accuracy: 0.9250\n",
            "Epoch 339/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9431 - val_loss: 0.2470 - val_accuracy: 0.9250\n",
            "Epoch 340/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9458 - val_loss: 0.2425 - val_accuracy: 0.9375\n",
            "Epoch 341/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1862 - accuracy: 0.9417 - val_loss: 0.2450 - val_accuracy: 0.9250\n",
            "Epoch 342/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1852 - accuracy: 0.9431 - val_loss: 0.2414 - val_accuracy: 0.9250\n",
            "Epoch 343/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9431 - val_loss: 0.2416 - val_accuracy: 0.9250\n",
            "Epoch 344/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9486 - val_loss: 0.2373 - val_accuracy: 0.9375\n",
            "Epoch 345/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1812 - accuracy: 0.9431 - val_loss: 0.2360 - val_accuracy: 0.9375\n",
            "Epoch 346/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9444 - val_loss: 0.2358 - val_accuracy: 0.9250\n",
            "Epoch 347/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9431 - val_loss: 0.2340 - val_accuracy: 0.9375\n",
            "Epoch 348/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9417 - val_loss: 0.2328 - val_accuracy: 0.9375\n",
            "Epoch 349/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9444 - val_loss: 0.2328 - val_accuracy: 0.9250\n",
            "Epoch 350/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9444 - val_loss: 0.2340 - val_accuracy: 0.9250\n",
            "Epoch 351/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9444 - val_loss: 0.2313 - val_accuracy: 0.9250\n",
            "Epoch 352/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9431 - val_loss: 0.2291 - val_accuracy: 0.9375\n",
            "Epoch 353/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9458 - val_loss: 0.2306 - val_accuracy: 0.9250\n",
            "Epoch 354/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1718 - accuracy: 0.9444 - val_loss: 0.2288 - val_accuracy: 0.9250\n",
            "Epoch 355/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9472 - val_loss: 0.2271 - val_accuracy: 0.9375\n",
            "Epoch 356/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9458 - val_loss: 0.2279 - val_accuracy: 0.9250\n",
            "Epoch 357/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9486 - val_loss: 0.2242 - val_accuracy: 0.9375\n",
            "Epoch 358/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9458 - val_loss: 0.2240 - val_accuracy: 0.9375\n",
            "Epoch 359/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9472 - val_loss: 0.2229 - val_accuracy: 0.9375\n",
            "Epoch 360/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9472 - val_loss: 0.2226 - val_accuracy: 0.9250\n",
            "Epoch 361/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.9472 - val_loss: 0.2220 - val_accuracy: 0.9250\n",
            "Epoch 362/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9472 - val_loss: 0.2226 - val_accuracy: 0.9250\n",
            "Epoch 363/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9472 - val_loss: 0.2227 - val_accuracy: 0.9250\n",
            "Epoch 364/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9472 - val_loss: 0.2220 - val_accuracy: 0.9250\n",
            "Epoch 365/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1619 - accuracy: 0.9486 - val_loss: 0.2184 - val_accuracy: 0.9375\n",
            "Epoch 366/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9486 - val_loss: 0.2188 - val_accuracy: 0.9375\n",
            "Epoch 367/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1605 - accuracy: 0.9458 - val_loss: 0.2176 - val_accuracy: 0.9375\n",
            "Epoch 368/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9486 - val_loss: 0.2201 - val_accuracy: 0.9125\n",
            "Epoch 369/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9458 - val_loss: 0.2164 - val_accuracy: 0.9375\n",
            "Epoch 370/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9486 - val_loss: 0.2186 - val_accuracy: 0.9250\n",
            "Epoch 371/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9500 - val_loss: 0.2205 - val_accuracy: 0.9125\n",
            "Epoch 372/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9458 - val_loss: 0.2162 - val_accuracy: 0.9250\n",
            "Epoch 373/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9500 - val_loss: 0.2144 - val_accuracy: 0.9375\n",
            "Epoch 374/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.9472 - val_loss: 0.2169 - val_accuracy: 0.9125\n",
            "Epoch 375/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9458 - val_loss: 0.2139 - val_accuracy: 0.9250\n",
            "Epoch 376/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1539 - accuracy: 0.9500 - val_loss: 0.2136 - val_accuracy: 0.9250\n",
            "Epoch 377/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9472 - val_loss: 0.2124 - val_accuracy: 0.9250\n",
            "Epoch 378/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9486 - val_loss: 0.2119 - val_accuracy: 0.9375\n",
            "Epoch 379/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9500 - val_loss: 0.2126 - val_accuracy: 0.9250\n",
            "Epoch 380/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9500 - val_loss: 0.2105 - val_accuracy: 0.9375\n",
            "Epoch 381/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.9486 - val_loss: 0.2100 - val_accuracy: 0.9375\n",
            "Epoch 382/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9500 - val_loss: 0.2105 - val_accuracy: 0.9250\n",
            "Epoch 383/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9486 - val_loss: 0.2081 - val_accuracy: 0.9375\n",
            "Epoch 384/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9514 - val_loss: 0.2078 - val_accuracy: 0.9250\n",
            "Epoch 385/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9472 - val_loss: 0.2084 - val_accuracy: 0.9125\n",
            "Epoch 386/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9472 - val_loss: 0.2079 - val_accuracy: 0.9125\n",
            "Epoch 387/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1482 - accuracy: 0.9472 - val_loss: 0.2089 - val_accuracy: 0.9125\n",
            "Epoch 388/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9500 - val_loss: 0.2052 - val_accuracy: 0.9375\n",
            "Epoch 389/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9472 - val_loss: 0.2055 - val_accuracy: 0.9375\n",
            "Epoch 390/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.9472 - val_loss: 0.2044 - val_accuracy: 0.9375\n",
            "Epoch 391/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9486 - val_loss: 0.2046 - val_accuracy: 0.9375\n",
            "Epoch 392/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9486 - val_loss: 0.2068 - val_accuracy: 0.9125\n",
            "Epoch 393/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9486 - val_loss: 0.2054 - val_accuracy: 0.9250\n",
            "Epoch 394/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9486 - val_loss: 0.2045 - val_accuracy: 0.9375\n",
            "Epoch 395/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9528 - val_loss: 0.2039 - val_accuracy: 0.9375\n",
            "Epoch 396/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9500 - val_loss: 0.2058 - val_accuracy: 0.9125\n",
            "Epoch 397/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9472 - val_loss: 0.2032 - val_accuracy: 0.9375\n",
            "Epoch 398/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9528 - val_loss: 0.2022 - val_accuracy: 0.9375\n",
            "Epoch 399/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9486 - val_loss: 0.2018 - val_accuracy: 0.9375\n",
            "Epoch 400/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9514 - val_loss: 0.2051 - val_accuracy: 0.9125\n",
            "Epoch 401/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.9458 - val_loss: 0.2014 - val_accuracy: 0.9375\n",
            "Epoch 402/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9486 - val_loss: 0.2004 - val_accuracy: 0.9375\n",
            "Epoch 403/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9500 - val_loss: 0.2020 - val_accuracy: 0.9125\n",
            "Epoch 404/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1405 - accuracy: 0.9472 - val_loss: 0.2019 - val_accuracy: 0.9125\n",
            "Epoch 405/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9486 - val_loss: 0.1998 - val_accuracy: 0.9375\n",
            "Epoch 406/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1395 - accuracy: 0.9500 - val_loss: 0.2039 - val_accuracy: 0.9125\n",
            "Epoch 407/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9486 - val_loss: 0.2005 - val_accuracy: 0.9250\n",
            "Epoch 408/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9486 - val_loss: 0.1990 - val_accuracy: 0.9375\n",
            "Epoch 409/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9514 - val_loss: 0.1976 - val_accuracy: 0.9375\n",
            "Epoch 410/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9486 - val_loss: 0.1970 - val_accuracy: 0.9375\n",
            "Epoch 411/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9514 - val_loss: 0.2000 - val_accuracy: 0.9125\n",
            "Epoch 412/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9486 - val_loss: 0.1990 - val_accuracy: 0.9375\n",
            "Epoch 413/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9514 - val_loss: 0.1971 - val_accuracy: 0.9375\n",
            "Epoch 414/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9514 - val_loss: 0.1972 - val_accuracy: 0.9375\n",
            "Epoch 415/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9514 - val_loss: 0.1983 - val_accuracy: 0.9250\n",
            "Epoch 416/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9500 - val_loss: 0.1984 - val_accuracy: 0.9125\n",
            "Epoch 417/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9472 - val_loss: 0.1973 - val_accuracy: 0.9375\n",
            "Epoch 418/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9514 - val_loss: 0.1949 - val_accuracy: 0.9375\n",
            "Epoch 419/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9486 - val_loss: 0.1951 - val_accuracy: 0.9375\n",
            "Epoch 420/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9514 - val_loss: 0.1938 - val_accuracy: 0.9375\n",
            "Epoch 421/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9472 - val_loss: 0.1934 - val_accuracy: 0.9375\n",
            "Epoch 422/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1346 - accuracy: 0.9542 - val_loss: 0.1955 - val_accuracy: 0.9125\n",
            "Epoch 423/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9486 - val_loss: 0.1950 - val_accuracy: 0.9125\n",
            "Epoch 424/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.9486 - val_loss: 0.1942 - val_accuracy: 0.9375\n",
            "Epoch 425/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9500 - val_loss: 0.1920 - val_accuracy: 0.9375\n",
            "Epoch 426/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9486 - val_loss: 0.1946 - val_accuracy: 0.9125\n",
            "Epoch 427/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.9500 - val_loss: 0.1949 - val_accuracy: 0.9125\n",
            "Epoch 428/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9486 - val_loss: 0.1975 - val_accuracy: 0.9125\n",
            "Epoch 429/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9458 - val_loss: 0.1970 - val_accuracy: 0.9125\n",
            "Epoch 430/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9472 - val_loss: 0.1931 - val_accuracy: 0.9375\n",
            "Epoch 431/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1318 - accuracy: 0.9500 - val_loss: 0.1928 - val_accuracy: 0.9250\n",
            "Epoch 432/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9500 - val_loss: 0.1919 - val_accuracy: 0.9250\n",
            "Epoch 433/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9472 - val_loss: 0.1908 - val_accuracy: 0.9375\n",
            "Epoch 434/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9486 - val_loss: 0.1903 - val_accuracy: 0.9375\n",
            "Epoch 435/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9486 - val_loss: 0.1916 - val_accuracy: 0.9375\n",
            "Epoch 436/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9486 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 437/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9458 - val_loss: 0.1920 - val_accuracy: 0.9375\n",
            "Epoch 438/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9486 - val_loss: 0.1948 - val_accuracy: 0.9125\n",
            "Epoch 439/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9472 - val_loss: 0.1931 - val_accuracy: 0.9125\n",
            "Epoch 440/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9486 - val_loss: 0.1944 - val_accuracy: 0.9375\n",
            "Epoch 441/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9500 - val_loss: 0.1954 - val_accuracy: 0.9125\n",
            "Epoch 442/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9500 - val_loss: 0.1938 - val_accuracy: 0.9250\n",
            "Epoch 443/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9486 - val_loss: 0.1962 - val_accuracy: 0.9125\n",
            "Epoch 444/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9444 - val_loss: 0.1941 - val_accuracy: 0.9125\n",
            "Epoch 445/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9486 - val_loss: 0.1953 - val_accuracy: 0.9125\n",
            "Epoch 446/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9458 - val_loss: 0.1940 - val_accuracy: 0.9125\n",
            "Epoch 447/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9472 - val_loss: 0.1936 - val_accuracy: 0.9125\n",
            "Epoch 448/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9514 - val_loss: 0.1929 - val_accuracy: 0.9125\n",
            "Epoch 449/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.9472 - val_loss: 0.1937 - val_accuracy: 0.9125\n",
            "Epoch 450/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1282 - accuracy: 0.9472 - val_loss: 0.1947 - val_accuracy: 0.9125\n",
            "Epoch 451/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9486 - val_loss: 0.1922 - val_accuracy: 0.9375\n",
            "Epoch 452/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.1920 - val_accuracy: 0.9375\n",
            "Epoch 453/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9514 - val_loss: 0.1932 - val_accuracy: 0.9125\n",
            "Epoch 454/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9500 - val_loss: 0.1954 - val_accuracy: 0.9125\n",
            "Epoch 455/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9486 - val_loss: 0.1921 - val_accuracy: 0.9125\n",
            "Epoch 456/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9472 - val_loss: 0.1931 - val_accuracy: 0.9125\n",
            "Epoch 457/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9472 - val_loss: 0.1909 - val_accuracy: 0.9125\n",
            "Epoch 458/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9486 - val_loss: 0.1887 - val_accuracy: 0.9375\n",
            "Epoch 459/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9486 - val_loss: 0.1895 - val_accuracy: 0.9375\n",
            "Epoch 460/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9486 - val_loss: 0.1922 - val_accuracy: 0.9125\n",
            "Epoch 461/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9472 - val_loss: 0.1912 - val_accuracy: 0.9125\n",
            "Epoch 462/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9472 - val_loss: 0.1915 - val_accuracy: 0.9125\n",
            "Epoch 463/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9500 - val_loss: 0.1887 - val_accuracy: 0.9250\n",
            "Epoch 464/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9486 - val_loss: 0.1895 - val_accuracy: 0.9125\n",
            "Epoch 465/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9486 - val_loss: 0.1882 - val_accuracy: 0.9375\n",
            "Epoch 466/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9486 - val_loss: 0.1910 - val_accuracy: 0.9125\n",
            "Epoch 467/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9486 - val_loss: 0.1915 - val_accuracy: 0.9125\n",
            "Epoch 468/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9486 - val_loss: 0.1914 - val_accuracy: 0.9125\n",
            "Epoch 469/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9472 - val_loss: 0.1923 - val_accuracy: 0.9125\n",
            "Epoch 470/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9486 - val_loss: 0.1921 - val_accuracy: 0.9125\n",
            "Epoch 471/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9486 - val_loss: 0.1925 - val_accuracy: 0.9125\n",
            "Epoch 472/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9472 - val_loss: 0.1901 - val_accuracy: 0.9125\n",
            "Epoch 473/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1242 - accuracy: 0.9472 - val_loss: 0.1923 - val_accuracy: 0.9125\n",
            "Epoch 474/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9472 - val_loss: 0.1899 - val_accuracy: 0.9125\n",
            "Epoch 475/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9472 - val_loss: 0.1903 - val_accuracy: 0.9125\n",
            "Epoch 476/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9486 - val_loss: 0.1900 - val_accuracy: 0.9125\n",
            "Epoch 477/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9486 - val_loss: 0.1916 - val_accuracy: 0.9125\n",
            "Epoch 478/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9486 - val_loss: 0.1879 - val_accuracy: 0.9375\n",
            "Epoch 479/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9500 - val_loss: 0.1903 - val_accuracy: 0.9125\n",
            "Epoch 480/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1236 - accuracy: 0.9458 - val_loss: 0.1878 - val_accuracy: 0.9375\n",
            "Epoch 481/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9500 - val_loss: 0.1934 - val_accuracy: 0.9125\n",
            "Epoch 482/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1233 - accuracy: 0.9486 - val_loss: 0.1922 - val_accuracy: 0.9125\n",
            "Epoch 483/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9458 - val_loss: 0.1889 - val_accuracy: 0.9250\n",
            "Epoch 484/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9486 - val_loss: 0.1912 - val_accuracy: 0.9125\n",
            "Epoch 485/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9486 - val_loss: 0.1905 - val_accuracy: 0.9125\n",
            "Epoch 486/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9472 - val_loss: 0.1898 - val_accuracy: 0.9125\n",
            "Epoch 487/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9458 - val_loss: 0.1872 - val_accuracy: 0.9125\n",
            "Epoch 488/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9486 - val_loss: 0.1857 - val_accuracy: 0.9375\n",
            "Epoch 489/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9472 - val_loss: 0.1875 - val_accuracy: 0.9125\n",
            "Epoch 490/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1225 - accuracy: 0.9444 - val_loss: 0.1880 - val_accuracy: 0.9125\n",
            "Epoch 491/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1223 - accuracy: 0.9458 - val_loss: 0.1868 - val_accuracy: 0.9250\n",
            "Epoch 492/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1223 - accuracy: 0.9458 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
            "Epoch 493/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1222 - accuracy: 0.9486 - val_loss: 0.1859 - val_accuracy: 0.9250\n",
            "Epoch 494/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9486 - val_loss: 0.1913 - val_accuracy: 0.9250\n",
            "Epoch 495/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9472 - val_loss: 0.1881 - val_accuracy: 0.9125\n",
            "Epoch 496/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9500 - val_loss: 0.1872 - val_accuracy: 0.9125\n",
            "Epoch 497/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9486 - val_loss: 0.1881 - val_accuracy: 0.9125\n",
            "Epoch 498/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9486 - val_loss: 0.1878 - val_accuracy: 0.9125\n",
            "Epoch 499/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9486 - val_loss: 0.1907 - val_accuracy: 0.9125\n",
            "Epoch 500/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9472 - val_loss: 0.1882 - val_accuracy: 0.9125\n",
            "Epoch 501/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9486 - val_loss: 0.1889 - val_accuracy: 0.9125\n",
            "Epoch 502/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1211 - accuracy: 0.9472 - val_loss: 0.1899 - val_accuracy: 0.9125\n",
            "Epoch 503/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9472 - val_loss: 0.1924 - val_accuracy: 0.9250\n",
            "Epoch 504/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9458 - val_loss: 0.1901 - val_accuracy: 0.9125\n",
            "Epoch 505/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9486 - val_loss: 0.1922 - val_accuracy: 0.9250\n",
            "Epoch 506/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9458 - val_loss: 0.1879 - val_accuracy: 0.9125\n",
            "Epoch 507/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9486 - val_loss: 0.1875 - val_accuracy: 0.9125\n",
            "Epoch 508/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9486 - val_loss: 0.1907 - val_accuracy: 0.9125\n",
            "Epoch 509/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9431 - val_loss: 0.1912 - val_accuracy: 0.9125\n",
            "Epoch 510/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9458 - val_loss: 0.1877 - val_accuracy: 0.9125\n",
            "Epoch 511/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1203 - accuracy: 0.9500 - val_loss: 0.1890 - val_accuracy: 0.9125\n",
            "Epoch 512/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9458 - val_loss: 0.1892 - val_accuracy: 0.9125\n",
            "Epoch 513/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9472 - val_loss: 0.1899 - val_accuracy: 0.9125\n",
            "Epoch 514/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9486 - val_loss: 0.1873 - val_accuracy: 0.9375\n",
            "Epoch 515/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9472 - val_loss: 0.1902 - val_accuracy: 0.9125\n",
            "Epoch 516/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9500 - val_loss: 0.1914 - val_accuracy: 0.9125\n",
            "Epoch 517/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9458 - val_loss: 0.1911 - val_accuracy: 0.9125\n",
            "Epoch 518/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9458 - val_loss: 0.1884 - val_accuracy: 0.9125\n",
            "Epoch 519/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9472 - val_loss: 0.1884 - val_accuracy: 0.9125\n",
            "Epoch 520/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9472 - val_loss: 0.1944 - val_accuracy: 0.9250\n",
            "Epoch 521/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.9472 - val_loss: 0.1896 - val_accuracy: 0.9125\n",
            "Epoch 522/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9444 - val_loss: 0.1883 - val_accuracy: 0.9125\n",
            "Epoch 523/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9500 - val_loss: 0.1868 - val_accuracy: 0.9250\n",
            "Epoch 524/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9472 - val_loss: 0.1889 - val_accuracy: 0.9125\n",
            "Epoch 525/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9486 - val_loss: 0.1925 - val_accuracy: 0.9125\n",
            "Epoch 526/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9444 - val_loss: 0.1895 - val_accuracy: 0.9125\n",
            "Epoch 527/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9486 - val_loss: 0.1872 - val_accuracy: 0.9125\n",
            "Epoch 528/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9458 - val_loss: 0.1869 - val_accuracy: 0.9125\n",
            "Epoch 529/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9472 - val_loss: 0.1892 - val_accuracy: 0.9125\n",
            "Epoch 530/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9444 - val_loss: 0.1905 - val_accuracy: 0.9125\n",
            "Epoch 531/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.9444 - val_loss: 0.1918 - val_accuracy: 0.9250\n",
            "Epoch 532/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9458 - val_loss: 0.1927 - val_accuracy: 0.9250\n",
            "Epoch 533/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9431 - val_loss: 0.1935 - val_accuracy: 0.9250\n",
            "Epoch 534/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9458 - val_loss: 0.1899 - val_accuracy: 0.9125\n",
            "Epoch 535/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9500 - val_loss: 0.1917 - val_accuracy: 0.9125\n",
            "Epoch 536/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9458 - val_loss: 0.1915 - val_accuracy: 0.9125\n",
            "Epoch 537/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9458 - val_loss: 0.1912 - val_accuracy: 0.9125\n",
            "Epoch 538/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9472 - val_loss: 0.1919 - val_accuracy: 0.9125\n",
            "Epoch 539/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9431 - val_loss: 0.1908 - val_accuracy: 0.9125\n",
            "Epoch 540/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9458 - val_loss: 0.1886 - val_accuracy: 0.9125\n",
            "Epoch 541/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9472 - val_loss: 0.1886 - val_accuracy: 0.9125\n",
            "Epoch 542/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9472 - val_loss: 0.1912 - val_accuracy: 0.9250\n",
            "Epoch 543/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9458 - val_loss: 0.1908 - val_accuracy: 0.9250\n",
            "Epoch 544/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9500 - val_loss: 0.1912 - val_accuracy: 0.9125\n",
            "Epoch 545/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9472 - val_loss: 0.1893 - val_accuracy: 0.9125\n",
            "Epoch 546/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9500 - val_loss: 0.1917 - val_accuracy: 0.9125\n",
            "Epoch 547/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9444 - val_loss: 0.1892 - val_accuracy: 0.9250\n",
            "Epoch 548/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9472 - val_loss: 0.1901 - val_accuracy: 0.9125\n",
            "Epoch 549/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.9472 - val_loss: 0.1942 - val_accuracy: 0.9125\n",
            "Epoch 550/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9458 - val_loss: 0.1928 - val_accuracy: 0.9125\n",
            "Epoch 551/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9458 - val_loss: 0.1941 - val_accuracy: 0.9250\n",
            "Epoch 552/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9458 - val_loss: 0.1919 - val_accuracy: 0.9250\n",
            "Epoch 553/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9458 - val_loss: 0.1885 - val_accuracy: 0.9125\n",
            "Epoch 554/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9472 - val_loss: 0.1920 - val_accuracy: 0.9250\n",
            "Epoch 555/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9458 - val_loss: 0.1901 - val_accuracy: 0.9250\n",
            "Epoch 556/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9500 - val_loss: 0.1929 - val_accuracy: 0.9250\n",
            "Epoch 557/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9472 - val_loss: 0.1916 - val_accuracy: 0.9250\n",
            "Epoch 558/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9486 - val_loss: 0.1908 - val_accuracy: 0.9250\n",
            "Epoch 559/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9472 - val_loss: 0.1886 - val_accuracy: 0.9125\n",
            "Epoch 560/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9486 - val_loss: 0.1900 - val_accuracy: 0.9125\n",
            "Epoch 561/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9458 - val_loss: 0.1892 - val_accuracy: 0.9125\n",
            "Epoch 562/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9472 - val_loss: 0.1876 - val_accuracy: 0.9125\n",
            "Epoch 563/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9458 - val_loss: 0.1896 - val_accuracy: 0.9125\n",
            "Epoch 564/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9458 - val_loss: 0.1892 - val_accuracy: 0.9125\n",
            "Epoch 565/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9486 - val_loss: 0.1868 - val_accuracy: 0.9250\n",
            "Epoch 566/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9486 - val_loss: 0.1914 - val_accuracy: 0.9125\n",
            "Epoch 567/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9486 - val_loss: 0.1954 - val_accuracy: 0.9125\n",
            "Epoch 568/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9444 - val_loss: 0.1884 - val_accuracy: 0.9125\n",
            "Epoch 569/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9472 - val_loss: 0.1896 - val_accuracy: 0.9125\n",
            "Epoch 570/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9486 - val_loss: 0.1995 - val_accuracy: 0.9250\n",
            "Epoch 571/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9431 - val_loss: 0.1941 - val_accuracy: 0.9125\n",
            "Epoch 572/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9444 - val_loss: 0.1910 - val_accuracy: 0.9125\n",
            "Epoch 573/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.9472 - val_loss: 0.1893 - val_accuracy: 0.9125\n",
            "Epoch 574/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9458 - val_loss: 0.1914 - val_accuracy: 0.9125\n",
            "Epoch 575/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9458 - val_loss: 0.1910 - val_accuracy: 0.9125\n",
            "Epoch 576/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9458 - val_loss: 0.1899 - val_accuracy: 0.9125\n",
            "Epoch 577/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9472 - val_loss: 0.1930 - val_accuracy: 0.9125\n",
            "Epoch 578/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9444 - val_loss: 0.1888 - val_accuracy: 0.9125\n",
            "Epoch 579/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9472 - val_loss: 0.1872 - val_accuracy: 0.9125\n",
            "Epoch 580/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9472 - val_loss: 0.1888 - val_accuracy: 0.9125\n",
            "Epoch 581/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9486 - val_loss: 0.1924 - val_accuracy: 0.9250\n",
            "Epoch 582/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9444 - val_loss: 0.1922 - val_accuracy: 0.9250\n",
            "Epoch 583/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9472 - val_loss: 0.1928 - val_accuracy: 0.9125\n",
            "Epoch 584/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9458 - val_loss: 0.1931 - val_accuracy: 0.9125\n",
            "Epoch 585/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9458 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 586/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9458 - val_loss: 0.1915 - val_accuracy: 0.9125\n",
            "Epoch 587/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9472 - val_loss: 0.1913 - val_accuracy: 0.9125\n",
            "Epoch 588/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9472 - val_loss: 0.1927 - val_accuracy: 0.9125\n",
            "Epoch 589/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9444 - val_loss: 0.1955 - val_accuracy: 0.9250\n",
            "Epoch 590/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9444 - val_loss: 0.1898 - val_accuracy: 0.9125\n",
            "Epoch 591/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9458 - val_loss: 0.1876 - val_accuracy: 0.9125\n",
            "Epoch 592/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9500 - val_loss: 0.1963 - val_accuracy: 0.9250\n",
            "Epoch 593/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9431 - val_loss: 0.1884 - val_accuracy: 0.9125\n",
            "Epoch 594/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9458 - val_loss: 0.1903 - val_accuracy: 0.9125\n",
            "Epoch 595/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9472 - val_loss: 0.1907 - val_accuracy: 0.9125\n",
            "Epoch 596/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9472 - val_loss: 0.1918 - val_accuracy: 0.9125\n",
            "Epoch 597/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9486 - val_loss: 0.1944 - val_accuracy: 0.9125\n",
            "Epoch 598/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.9431 - val_loss: 0.1931 - val_accuracy: 0.9125\n",
            "Epoch 599/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9458 - val_loss: 0.1919 - val_accuracy: 0.9125\n",
            "Epoch 600/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9458 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 601/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9472 - val_loss: 0.1901 - val_accuracy: 0.9125\n",
            "Epoch 602/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9458 - val_loss: 0.1964 - val_accuracy: 0.9125\n",
            "Epoch 603/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9444 - val_loss: 0.1907 - val_accuracy: 0.9125\n",
            "Epoch 604/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9458 - val_loss: 0.1946 - val_accuracy: 0.9125\n",
            "Epoch 605/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9458 - val_loss: 0.1941 - val_accuracy: 0.9125\n",
            "Epoch 606/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.9486 - val_loss: 0.1988 - val_accuracy: 0.9125\n",
            "Epoch 607/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9444 - val_loss: 0.1961 - val_accuracy: 0.9125\n",
            "Epoch 608/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9444 - val_loss: 0.1947 - val_accuracy: 0.9125\n",
            "Epoch 609/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9458 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 610/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9458 - val_loss: 0.1911 - val_accuracy: 0.9125\n",
            "Epoch 611/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9458 - val_loss: 0.1939 - val_accuracy: 0.9125\n",
            "Epoch 612/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9431 - val_loss: 0.1937 - val_accuracy: 0.9125\n",
            "Epoch 613/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9444 - val_loss: 0.1923 - val_accuracy: 0.9125\n",
            "Epoch 614/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9431 - val_loss: 0.1931 - val_accuracy: 0.9125\n",
            "Epoch 615/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9472 - val_loss: 0.1934 - val_accuracy: 0.9125\n",
            "Epoch 616/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9444 - val_loss: 0.1960 - val_accuracy: 0.9250\n",
            "Epoch 617/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9458 - val_loss: 0.1922 - val_accuracy: 0.9125\n",
            "Epoch 618/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9458 - val_loss: 0.1915 - val_accuracy: 0.9125\n",
            "Epoch 619/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9444 - val_loss: 0.1901 - val_accuracy: 0.9125\n",
            "Epoch 620/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9472 - val_loss: 0.1916 - val_accuracy: 0.9125\n",
            "Epoch 621/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9444 - val_loss: 0.1932 - val_accuracy: 0.9125\n",
            "Epoch 622/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9472 - val_loss: 0.1937 - val_accuracy: 0.9125\n",
            "Epoch 623/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9458 - val_loss: 0.1936 - val_accuracy: 0.9125\n",
            "Epoch 624/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9431 - val_loss: 0.1921 - val_accuracy: 0.9125\n",
            "Epoch 625/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9431 - val_loss: 0.1916 - val_accuracy: 0.9125\n",
            "Epoch 626/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9458 - val_loss: 0.1959 - val_accuracy: 0.9250\n",
            "Epoch 627/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9444 - val_loss: 0.1909 - val_accuracy: 0.9250\n",
            "Epoch 628/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9472 - val_loss: 0.1915 - val_accuracy: 0.9250\n",
            "Epoch 629/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9458 - val_loss: 0.1939 - val_accuracy: 0.9250\n",
            "Epoch 630/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9444 - val_loss: 0.1900 - val_accuracy: 0.9250\n",
            "Epoch 631/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9458 - val_loss: 0.1888 - val_accuracy: 0.9125\n",
            "Epoch 632/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9458 - val_loss: 0.1914 - val_accuracy: 0.9250\n",
            "Epoch 633/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9458 - val_loss: 0.1937 - val_accuracy: 0.9250\n",
            "Epoch 634/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9472 - val_loss: 0.1920 - val_accuracy: 0.9125\n",
            "Epoch 635/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9458 - val_loss: 0.1945 - val_accuracy: 0.9125\n",
            "Epoch 636/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9431 - val_loss: 0.1988 - val_accuracy: 0.9250\n",
            "Epoch 637/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9431 - val_loss: 0.1952 - val_accuracy: 0.9125\n",
            "Epoch 638/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9444 - val_loss: 0.1938 - val_accuracy: 0.9125\n",
            "Epoch 639/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9458 - val_loss: 0.1948 - val_accuracy: 0.9125\n",
            "Epoch 640/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9458 - val_loss: 0.1953 - val_accuracy: 0.9125\n",
            "Epoch 641/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9472 - val_loss: 0.1962 - val_accuracy: 0.9125\n",
            "Epoch 642/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9431 - val_loss: 0.1963 - val_accuracy: 0.9125\n",
            "Epoch 643/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9472 - val_loss: 0.1945 - val_accuracy: 0.9125\n",
            "Epoch 644/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9458 - val_loss: 0.1980 - val_accuracy: 0.9125\n",
            "Epoch 645/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9431 - val_loss: 0.1979 - val_accuracy: 0.9125\n",
            "Epoch 646/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9444 - val_loss: 0.1954 - val_accuracy: 0.9250\n",
            "Epoch 647/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9472 - val_loss: 0.1893 - val_accuracy: 0.9125\n",
            "Epoch 648/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9472 - val_loss: 0.2003 - val_accuracy: 0.9250\n",
            "Epoch 649/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9417 - val_loss: 0.1954 - val_accuracy: 0.9250\n",
            "Epoch 650/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9444 - val_loss: 0.1926 - val_accuracy: 0.9250\n",
            "Epoch 651/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9472 - val_loss: 0.1960 - val_accuracy: 0.9250\n",
            "Epoch 652/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9458 - val_loss: 0.1921 - val_accuracy: 0.9250\n",
            "Epoch 653/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9472 - val_loss: 0.1963 - val_accuracy: 0.9250\n",
            "Epoch 654/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9444 - val_loss: 0.1909 - val_accuracy: 0.9250\n",
            "Epoch 655/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9486 - val_loss: 0.1938 - val_accuracy: 0.9125\n",
            "Epoch 656/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9472 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 657/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9458 - val_loss: 0.1934 - val_accuracy: 0.9125\n",
            "Epoch 658/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9458 - val_loss: 0.1922 - val_accuracy: 0.9125\n",
            "Epoch 659/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9486 - val_loss: 0.1929 - val_accuracy: 0.9125\n",
            "Epoch 660/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9472 - val_loss: 0.2028 - val_accuracy: 0.9250\n",
            "Epoch 661/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9444 - val_loss: 0.1982 - val_accuracy: 0.9250\n",
            "Epoch 662/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9500 - val_loss: 0.1923 - val_accuracy: 0.9125\n",
            "Epoch 663/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9458 - val_loss: 0.1922 - val_accuracy: 0.9250\n",
            "Epoch 664/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9458 - val_loss: 0.1932 - val_accuracy: 0.9250\n",
            "Epoch 665/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9472 - val_loss: 0.1919 - val_accuracy: 0.9250\n",
            "Epoch 666/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9444 - val_loss: 0.1912 - val_accuracy: 0.9250\n",
            "Epoch 667/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9472 - val_loss: 0.1882 - val_accuracy: 0.9250\n",
            "Epoch 668/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9500 - val_loss: 0.1982 - val_accuracy: 0.9250\n",
            "Epoch 669/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9458 - val_loss: 0.1900 - val_accuracy: 0.9250\n",
            "Epoch 670/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9472 - val_loss: 0.1888 - val_accuracy: 0.9250\n",
            "Epoch 671/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9486 - val_loss: 0.1897 - val_accuracy: 0.9125\n",
            "Epoch 672/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9500 - val_loss: 0.1935 - val_accuracy: 0.9250\n",
            "Epoch 673/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9472 - val_loss: 0.1879 - val_accuracy: 0.9250\n",
            "Epoch 674/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9514 - val_loss: 0.1908 - val_accuracy: 0.9250\n",
            "Epoch 675/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9486 - val_loss: 0.1932 - val_accuracy: 0.9250\n",
            "Epoch 676/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9472 - val_loss: 0.1912 - val_accuracy: 0.9250\n",
            "Epoch 677/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9472 - val_loss: 0.1930 - val_accuracy: 0.9125\n",
            "Epoch 678/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9444 - val_loss: 0.1922 - val_accuracy: 0.9125\n",
            "Epoch 679/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9486 - val_loss: 0.1960 - val_accuracy: 0.9250\n",
            "Epoch 680/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1937 - val_accuracy: 0.9250\n",
            "Epoch 681/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9444 - val_loss: 0.1964 - val_accuracy: 0.9250\n",
            "Epoch 682/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9444 - val_loss: 0.1950 - val_accuracy: 0.9250\n",
            "Epoch 683/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9444 - val_loss: 0.1986 - val_accuracy: 0.9125\n",
            "Epoch 684/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9444 - val_loss: 0.1981 - val_accuracy: 0.9125\n",
            "Epoch 685/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9431 - val_loss: 0.1946 - val_accuracy: 0.9250\n",
            "Epoch 686/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1967 - val_accuracy: 0.9250\n",
            "Epoch 687/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9458 - val_loss: 0.1917 - val_accuracy: 0.9250\n",
            "Epoch 688/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9472 - val_loss: 0.1926 - val_accuracy: 0.9250\n",
            "Epoch 689/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9472 - val_loss: 0.1976 - val_accuracy: 0.9250\n",
            "Epoch 690/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9486 - val_loss: 0.1935 - val_accuracy: 0.9250\n",
            "Epoch 691/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9458 - val_loss: 0.1972 - val_accuracy: 0.9250\n",
            "Epoch 692/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9458 - val_loss: 0.1977 - val_accuracy: 0.9250\n",
            "Epoch 693/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9444 - val_loss: 0.1992 - val_accuracy: 0.9125\n",
            "Epoch 694/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9458 - val_loss: 0.2006 - val_accuracy: 0.9250\n",
            "Epoch 695/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9458 - val_loss: 0.1951 - val_accuracy: 0.9125\n",
            "Epoch 696/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9444 - val_loss: 0.1916 - val_accuracy: 0.9125\n",
            "Epoch 697/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9444 - val_loss: 0.1924 - val_accuracy: 0.9125\n",
            "Epoch 698/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9431 - val_loss: 0.1937 - val_accuracy: 0.9250\n",
            "Epoch 699/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9486 - val_loss: 0.1947 - val_accuracy: 0.9250\n",
            "Epoch 700/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1935 - val_accuracy: 0.9125\n",
            "Epoch 701/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9444 - val_loss: 0.1959 - val_accuracy: 0.9250\n",
            "Epoch 702/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1967 - val_accuracy: 0.9250\n",
            "Epoch 703/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9458 - val_loss: 0.1892 - val_accuracy: 0.9250\n",
            "Epoch 704/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9472 - val_loss: 0.1901 - val_accuracy: 0.9125\n",
            "Epoch 705/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9458 - val_loss: 0.1916 - val_accuracy: 0.9125\n",
            "Epoch 706/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9444 - val_loss: 0.1907 - val_accuracy: 0.9250\n",
            "Epoch 707/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1903 - val_accuracy: 0.9125\n",
            "Epoch 708/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9472 - val_loss: 0.1911 - val_accuracy: 0.9125\n",
            "Epoch 709/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9472 - val_loss: 0.1932 - val_accuracy: 0.9125\n",
            "Epoch 710/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9431 - val_loss: 0.1892 - val_accuracy: 0.9250\n",
            "Epoch 711/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9458 - val_loss: 0.1893 - val_accuracy: 0.9250\n",
            "Epoch 712/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9500 - val_loss: 0.1936 - val_accuracy: 0.9250\n",
            "Epoch 713/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1142 - accuracy: 0.9486 - val_loss: 0.1949 - val_accuracy: 0.9250\n",
            "Epoch 714/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9458 - val_loss: 0.1913 - val_accuracy: 0.9125\n",
            "Epoch 715/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9458 - val_loss: 0.1895 - val_accuracy: 0.9125\n",
            "Epoch 716/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9486 - val_loss: 0.1969 - val_accuracy: 0.9125\n",
            "Epoch 717/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9431 - val_loss: 0.1915 - val_accuracy: 0.9125\n",
            "Epoch 718/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9472 - val_loss: 0.1932 - val_accuracy: 0.9250\n",
            "Epoch 719/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9472 - val_loss: 0.1947 - val_accuracy: 0.9250\n",
            "Epoch 720/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9444 - val_loss: 0.1918 - val_accuracy: 0.9250\n",
            "Epoch 721/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9458 - val_loss: 0.1903 - val_accuracy: 0.9125\n",
            "Epoch 722/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9486 - val_loss: 0.1928 - val_accuracy: 0.9250\n",
            "Epoch 723/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9458 - val_loss: 0.1873 - val_accuracy: 0.9375\n",
            "Epoch 724/800\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1150 - accuracy: 0.9472 - val_loss: 0.1907 - val_accuracy: 0.9250\n",
            "Epoch 725/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9472 - val_loss: 0.1938 - val_accuracy: 0.9250\n",
            "Epoch 726/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9444 - val_loss: 0.1977 - val_accuracy: 0.9250\n",
            "Epoch 727/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9472 - val_loss: 0.1916 - val_accuracy: 0.9250\n",
            "Epoch 728/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9486 - val_loss: 0.1947 - val_accuracy: 0.9250\n",
            "Epoch 729/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9458 - val_loss: 0.1884 - val_accuracy: 0.9250\n",
            "Epoch 730/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9472 - val_loss: 0.1899 - val_accuracy: 0.9125\n",
            "Epoch 731/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9458 - val_loss: 0.1914 - val_accuracy: 0.9250\n",
            "Epoch 732/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1942 - val_accuracy: 0.9250\n",
            "Epoch 733/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9444 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 734/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9458 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 735/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9472 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
            "Epoch 736/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9444 - val_loss: 0.1923 - val_accuracy: 0.9125\n",
            "Epoch 737/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9472 - val_loss: 0.1921 - val_accuracy: 0.9250\n",
            "Epoch 738/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9472 - val_loss: 0.1910 - val_accuracy: 0.9250\n",
            "Epoch 739/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9472 - val_loss: 0.1939 - val_accuracy: 0.9250\n",
            "Epoch 740/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9458 - val_loss: 0.1911 - val_accuracy: 0.9250\n",
            "Epoch 741/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9486 - val_loss: 0.1928 - val_accuracy: 0.9250\n",
            "Epoch 742/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9458 - val_loss: 0.1986 - val_accuracy: 0.9250\n",
            "Epoch 743/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9458 - val_loss: 0.1992 - val_accuracy: 0.9250\n",
            "Epoch 744/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9472 - val_loss: 0.1946 - val_accuracy: 0.9250\n",
            "Epoch 745/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9486 - val_loss: 0.1960 - val_accuracy: 0.9250\n",
            "Epoch 746/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.9444 - val_loss: 0.1954 - val_accuracy: 0.9250\n",
            "Epoch 747/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9458 - val_loss: 0.1968 - val_accuracy: 0.9250\n",
            "Epoch 748/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1979 - val_accuracy: 0.9250\n",
            "Epoch 749/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9458 - val_loss: 0.1980 - val_accuracy: 0.9250\n",
            "Epoch 750/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9472 - val_loss: 0.2006 - val_accuracy: 0.9250\n",
            "Epoch 751/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9472 - val_loss: 0.1954 - val_accuracy: 0.9250\n",
            "Epoch 752/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9458 - val_loss: 0.1928 - val_accuracy: 0.9250\n",
            "Epoch 753/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9458 - val_loss: 0.1936 - val_accuracy: 0.9250\n",
            "Epoch 754/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9472 - val_loss: 0.1952 - val_accuracy: 0.9250\n",
            "Epoch 755/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9458 - val_loss: 0.1957 - val_accuracy: 0.9250\n",
            "Epoch 756/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9486 - val_loss: 0.2018 - val_accuracy: 0.9250\n",
            "Epoch 757/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9500 - val_loss: 0.1924 - val_accuracy: 0.9250\n",
            "Epoch 758/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9472 - val_loss: 0.1978 - val_accuracy: 0.9125\n",
            "Epoch 759/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9486 - val_loss: 0.1975 - val_accuracy: 0.9250\n",
            "Epoch 760/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9458 - val_loss: 0.1907 - val_accuracy: 0.9125\n",
            "Epoch 761/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9500 - val_loss: 0.1912 - val_accuracy: 0.9125\n",
            "Epoch 762/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9486 - val_loss: 0.1972 - val_accuracy: 0.9250\n",
            "Epoch 763/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9458 - val_loss: 0.2002 - val_accuracy: 0.9250\n",
            "Epoch 764/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9486 - val_loss: 0.1966 - val_accuracy: 0.9250\n",
            "Epoch 765/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9486 - val_loss: 0.1951 - val_accuracy: 0.9250\n",
            "Epoch 766/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9458 - val_loss: 0.1970 - val_accuracy: 0.9250\n",
            "Epoch 767/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9458 - val_loss: 0.1936 - val_accuracy: 0.9250\n",
            "Epoch 768/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9486 - val_loss: 0.1939 - val_accuracy: 0.9250\n",
            "Epoch 769/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9472 - val_loss: 0.1965 - val_accuracy: 0.9250\n",
            "Epoch 770/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9458 - val_loss: 0.1959 - val_accuracy: 0.9250\n",
            "Epoch 771/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9486 - val_loss: 0.2050 - val_accuracy: 0.9250\n",
            "Epoch 772/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9431 - val_loss: 0.1995 - val_accuracy: 0.9250\n",
            "Epoch 773/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9444 - val_loss: 0.2006 - val_accuracy: 0.9250\n",
            "Epoch 774/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9472 - val_loss: 0.1925 - val_accuracy: 0.9250\n",
            "Epoch 775/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9500 - val_loss: 0.1934 - val_accuracy: 0.9250\n",
            "Epoch 776/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9486 - val_loss: 0.1944 - val_accuracy: 0.9250\n",
            "Epoch 777/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9486 - val_loss: 0.1952 - val_accuracy: 0.9250\n",
            "Epoch 778/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9472 - val_loss: 0.1926 - val_accuracy: 0.9250\n",
            "Epoch 779/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9472 - val_loss: 0.1908 - val_accuracy: 0.9250\n",
            "Epoch 780/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9472 - val_loss: 0.1962 - val_accuracy: 0.9250\n",
            "Epoch 781/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9486 - val_loss: 0.1941 - val_accuracy: 0.9250\n",
            "Epoch 782/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9444 - val_loss: 0.1922 - val_accuracy: 0.9250\n",
            "Epoch 783/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9486 - val_loss: 0.1943 - val_accuracy: 0.9250\n",
            "Epoch 784/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9444 - val_loss: 0.2022 - val_accuracy: 0.9250\n",
            "Epoch 785/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9486 - val_loss: 0.1976 - val_accuracy: 0.9125\n",
            "Epoch 786/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9444 - val_loss: 0.1994 - val_accuracy: 0.9250\n",
            "Epoch 787/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9444 - val_loss: 0.2005 - val_accuracy: 0.9125\n",
            "Epoch 788/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9444 - val_loss: 0.2023 - val_accuracy: 0.9125\n",
            "Epoch 789/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9431 - val_loss: 0.2018 - val_accuracy: 0.9125\n",
            "Epoch 790/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9444 - val_loss: 0.2017 - val_accuracy: 0.9250\n",
            "Epoch 791/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9458 - val_loss: 0.2007 - val_accuracy: 0.9250\n",
            "Epoch 792/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9458 - val_loss: 0.2104 - val_accuracy: 0.9250\n",
            "Epoch 793/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9431 - val_loss: 0.2020 - val_accuracy: 0.9250\n",
            "Epoch 794/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9431 - val_loss: 0.2058 - val_accuracy: 0.9250\n",
            "Epoch 795/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9431 - val_loss: 0.1982 - val_accuracy: 0.9125\n",
            "Epoch 796/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9458 - val_loss: 0.1980 - val_accuracy: 0.9250\n",
            "Epoch 797/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9500 - val_loss: 0.2015 - val_accuracy: 0.9250\n",
            "Epoch 798/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9444 - val_loss: 0.2003 - val_accuracy: 0.9250\n",
            "Epoch 799/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9431 - val_loss: 0.1986 - val_accuracy: 0.9250\n",
            "Epoch 800/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9458 - val_loss: 0.1964 - val_accuracy: 0.9250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36b0abacd0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20C_MR9mWOne",
        "outputId": "84f5f16f-8ede-4e47-bdab-ddb2d4fa676d"
      },
      "source": [
        "#MODEL 3 STANDARD LIBRARY\n",
        "my_model_3_stdlib = keras.Sequential()\n",
        "# Your code here!\n",
        "my_model_3_stdlib.add(keras.layers.Dense(2, activation=\"tanh\", input_dim=2))\n",
        "my_model_3_stdlib.add(keras.layers.Dense(500, activation=\"tanh\"))\n",
        "my_model_3_stdlib.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
        "\n",
        "my_model_3_stdlib.compile(loss=\"sparse_categorical_crossentropy\" ,\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "my_model_3_stdlib.fit(X_train, y_train, batch_size=64, epochs=800,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6912 - accuracy: 0.4583 - val_loss: 0.6941 - val_accuracy: 0.4000\n",
            "Epoch 2/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.4444 - val_loss: 0.6944 - val_accuracy: 0.4125\n",
            "Epoch 3/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.4972 - val_loss: 0.6959 - val_accuracy: 0.4375\n",
            "Epoch 4/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.5819 - val_loss: 0.6962 - val_accuracy: 0.4375\n",
            "Epoch 5/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5389 - val_loss: 0.6978 - val_accuracy: 0.5250\n",
            "Epoch 6/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.6403 - val_loss: 0.6985 - val_accuracy: 0.5500\n",
            "Epoch 7/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.6264 - val_loss: 0.6999 - val_accuracy: 0.5500\n",
            "Epoch 8/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.6694 - val_loss: 0.6992 - val_accuracy: 0.5500\n",
            "Epoch 9/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.6444 - val_loss: 0.6995 - val_accuracy: 0.5500\n",
            "Epoch 10/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6444 - val_loss: 0.6978 - val_accuracy: 0.5250\n",
            "Epoch 11/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6236 - val_loss: 0.6973 - val_accuracy: 0.4875\n",
            "Epoch 12/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5875 - val_loss: 0.6983 - val_accuracy: 0.5250\n",
            "Epoch 13/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.6403 - val_loss: 0.6972 - val_accuracy: 0.4875\n",
            "Epoch 14/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.6167 - val_loss: 0.6964 - val_accuracy: 0.4875\n",
            "Epoch 15/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5833 - val_loss: 0.6978 - val_accuracy: 0.5250\n",
            "Epoch 16/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.6208 - val_loss: 0.6973 - val_accuracy: 0.4875\n",
            "Epoch 17/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.6194 - val_loss: 0.6978 - val_accuracy: 0.5375\n",
            "Epoch 18/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.6292 - val_loss: 0.6987 - val_accuracy: 0.5500\n",
            "Epoch 19/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.6375 - val_loss: 0.6989 - val_accuracy: 0.5625\n",
            "Epoch 20/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.6458 - val_loss: 0.6993 - val_accuracy: 0.5625\n",
            "Epoch 21/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.6486 - val_loss: 0.6991 - val_accuracy: 0.5625\n",
            "Epoch 22/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.6569 - val_loss: 0.6978 - val_accuracy: 0.5500\n",
            "Epoch 23/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.6319 - val_loss: 0.6995 - val_accuracy: 0.5625\n",
            "Epoch 24/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.6597 - val_loss: 0.6992 - val_accuracy: 0.5625\n",
            "Epoch 25/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6805 - accuracy: 0.6681 - val_loss: 0.6992 - val_accuracy: 0.5625\n",
            "Epoch 26/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.6528 - val_loss: 0.6973 - val_accuracy: 0.5500\n",
            "Epoch 27/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.6389 - val_loss: 0.6974 - val_accuracy: 0.5625\n",
            "Epoch 28/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.6486 - val_loss: 0.6962 - val_accuracy: 0.5500\n",
            "Epoch 29/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.6375 - val_loss: 0.6955 - val_accuracy: 0.5500\n",
            "Epoch 30/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.6458 - val_loss: 0.6946 - val_accuracy: 0.5500\n",
            "Epoch 31/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.6347 - val_loss: 0.6941 - val_accuracy: 0.5500\n",
            "Epoch 32/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.6444 - val_loss: 0.6926 - val_accuracy: 0.5250\n",
            "Epoch 33/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6333 - val_loss: 0.6911 - val_accuracy: 0.5250\n",
            "Epoch 34/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6713 - accuracy: 0.6125 - val_loss: 0.6912 - val_accuracy: 0.5250\n",
            "Epoch 35/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6208 - val_loss: 0.6896 - val_accuracy: 0.5250\n",
            "Epoch 36/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.6306 - val_loss: 0.6887 - val_accuracy: 0.5250\n",
            "Epoch 37/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.6236 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
            "Epoch 38/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6264 - val_loss: 0.6882 - val_accuracy: 0.5500\n",
            "Epoch 39/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6431 - val_loss: 0.6872 - val_accuracy: 0.5500\n",
            "Epoch 40/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6635 - accuracy: 0.6403 - val_loss: 0.6853 - val_accuracy: 0.5500\n",
            "Epoch 41/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.6444 - val_loss: 0.6848 - val_accuracy: 0.5500\n",
            "Epoch 42/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6458 - val_loss: 0.6828 - val_accuracy: 0.5500\n",
            "Epoch 43/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.6389 - val_loss: 0.6834 - val_accuracy: 0.5625\n",
            "Epoch 44/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6472 - val_loss: 0.6805 - val_accuracy: 0.5500\n",
            "Epoch 45/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6403 - val_loss: 0.6780 - val_accuracy: 0.5250\n",
            "Epoch 46/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6347 - val_loss: 0.6754 - val_accuracy: 0.5000\n",
            "Epoch 47/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6236 - val_loss: 0.6755 - val_accuracy: 0.5250\n",
            "Epoch 48/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6444 - val_loss: 0.6746 - val_accuracy: 0.5375\n",
            "Epoch 49/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6472 - val_loss: 0.6738 - val_accuracy: 0.5500\n",
            "Epoch 50/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6528 - val_loss: 0.6720 - val_accuracy: 0.5500\n",
            "Epoch 51/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6444 - val_loss: 0.6696 - val_accuracy: 0.5375\n",
            "Epoch 52/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6347 - val_loss: 0.6698 - val_accuracy: 0.5500\n",
            "Epoch 53/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.6569 - val_loss: 0.6681 - val_accuracy: 0.5500\n",
            "Epoch 54/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6542 - val_loss: 0.6673 - val_accuracy: 0.5500\n",
            "Epoch 55/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6653 - val_loss: 0.6665 - val_accuracy: 0.5500\n",
            "Epoch 56/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6722 - val_loss: 0.6649 - val_accuracy: 0.5500\n",
            "Epoch 57/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.6681 - val_loss: 0.6635 - val_accuracy: 0.5875\n",
            "Epoch 58/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6764 - val_loss: 0.6617 - val_accuracy: 0.5875\n",
            "Epoch 59/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6764 - val_loss: 0.6588 - val_accuracy: 0.5500\n",
            "Epoch 60/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6722 - val_loss: 0.6563 - val_accuracy: 0.5500\n",
            "Epoch 61/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6639 - val_loss: 0.6547 - val_accuracy: 0.5500\n",
            "Epoch 62/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.6694 - val_loss: 0.6538 - val_accuracy: 0.5750\n",
            "Epoch 63/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6764 - val_loss: 0.6495 - val_accuracy: 0.5500\n",
            "Epoch 64/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6667 - val_loss: 0.6475 - val_accuracy: 0.5500\n",
            "Epoch 65/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6556 - val_loss: 0.6465 - val_accuracy: 0.5625\n",
            "Epoch 66/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.6569 - val_loss: 0.6456 - val_accuracy: 0.5625\n",
            "Epoch 67/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.6750 - val_loss: 0.6432 - val_accuracy: 0.5625\n",
            "Epoch 68/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6722 - val_loss: 0.6396 - val_accuracy: 0.5625\n",
            "Epoch 69/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.6583 - val_loss: 0.6381 - val_accuracy: 0.5625\n",
            "Epoch 70/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6722 - val_loss: 0.6352 - val_accuracy: 0.5625\n",
            "Epoch 71/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.6556 - val_loss: 0.6322 - val_accuracy: 0.5625\n",
            "Epoch 72/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6528 - val_loss: 0.6302 - val_accuracy: 0.5500\n",
            "Epoch 73/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.6514 - val_loss: 0.6290 - val_accuracy: 0.5625\n",
            "Epoch 74/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6597 - val_loss: 0.6260 - val_accuracy: 0.5500\n",
            "Epoch 75/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.6611 - val_loss: 0.6243 - val_accuracy: 0.5500\n",
            "Epoch 76/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5914 - accuracy: 0.6472 - val_loss: 0.6225 - val_accuracy: 0.5500\n",
            "Epoch 77/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6444 - val_loss: 0.6202 - val_accuracy: 0.5500\n",
            "Epoch 78/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.6542 - val_loss: 0.6179 - val_accuracy: 0.5500\n",
            "Epoch 79/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.6417 - val_loss: 0.6171 - val_accuracy: 0.5625\n",
            "Epoch 80/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5833 - accuracy: 0.6569 - val_loss: 0.6148 - val_accuracy: 0.5500\n",
            "Epoch 81/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5810 - accuracy: 0.6500 - val_loss: 0.6129 - val_accuracy: 0.5500\n",
            "Epoch 82/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.6556 - val_loss: 0.6082 - val_accuracy: 0.5000\n",
            "Epoch 83/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.6236 - val_loss: 0.6063 - val_accuracy: 0.5000\n",
            "Epoch 84/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.6431 - val_loss: 0.6047 - val_accuracy: 0.5000\n",
            "Epoch 85/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.6181 - val_loss: 0.6048 - val_accuracy: 0.5500\n",
            "Epoch 86/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.6417 - val_loss: 0.6025 - val_accuracy: 0.5375\n",
            "Epoch 87/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.6472 - val_loss: 0.5980 - val_accuracy: 0.5000\n",
            "Epoch 88/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.6097 - val_loss: 0.5968 - val_accuracy: 0.5000\n",
            "Epoch 89/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.6181 - val_loss: 0.5975 - val_accuracy: 0.5375\n",
            "Epoch 90/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6486 - val_loss: 0.5989 - val_accuracy: 0.5625\n",
            "Epoch 91/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.6653 - val_loss: 0.5976 - val_accuracy: 0.5625\n",
            "Epoch 92/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.6681 - val_loss: 0.5971 - val_accuracy: 0.5625\n",
            "Epoch 93/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.6764 - val_loss: 0.5954 - val_accuracy: 0.5625\n",
            "Epoch 94/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.6514 - val_loss: 0.5898 - val_accuracy: 0.5500\n",
            "Epoch 95/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.6472 - val_loss: 0.5872 - val_accuracy: 0.5375\n",
            "Epoch 96/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.6333 - val_loss: 0.5828 - val_accuracy: 0.5000\n",
            "Epoch 97/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.5972 - val_loss: 0.5834 - val_accuracy: 0.5000\n",
            "Epoch 98/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5482 - accuracy: 0.6153 - val_loss: 0.5829 - val_accuracy: 0.5375\n",
            "Epoch 99/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.6431 - val_loss: 0.5823 - val_accuracy: 0.5500\n",
            "Epoch 100/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.6417 - val_loss: 0.5822 - val_accuracy: 0.5625\n",
            "Epoch 101/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.6556 - val_loss: 0.5800 - val_accuracy: 0.5625\n",
            "Epoch 102/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.6597 - val_loss: 0.5751 - val_accuracy: 0.5000\n",
            "Epoch 103/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5396 - accuracy: 0.6222 - val_loss: 0.5758 - val_accuracy: 0.5500\n",
            "Epoch 104/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.6458 - val_loss: 0.5742 - val_accuracy: 0.5375\n",
            "Epoch 105/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.6431 - val_loss: 0.5733 - val_accuracy: 0.5500\n",
            "Epoch 106/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.6569 - val_loss: 0.5714 - val_accuracy: 0.5500\n",
            "Epoch 107/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.6514 - val_loss: 0.5695 - val_accuracy: 0.5375\n",
            "Epoch 108/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.6486 - val_loss: 0.5683 - val_accuracy: 0.5375\n",
            "Epoch 109/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.6389 - val_loss: 0.5664 - val_accuracy: 0.5375\n",
            "Epoch 110/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.6319 - val_loss: 0.5656 - val_accuracy: 0.5375\n",
            "Epoch 111/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.6486 - val_loss: 0.5643 - val_accuracy: 0.5500\n",
            "Epoch 112/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.6556 - val_loss: 0.5605 - val_accuracy: 0.5000\n",
            "Epoch 113/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.6153 - val_loss: 0.5572 - val_accuracy: 0.5000\n",
            "Epoch 114/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.5792 - val_loss: 0.5564 - val_accuracy: 0.5000\n",
            "Epoch 115/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.5972 - val_loss: 0.5546 - val_accuracy: 0.5000\n",
            "Epoch 116/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.5708 - val_loss: 0.5564 - val_accuracy: 0.5250\n",
            "Epoch 117/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.6083 - val_loss: 0.5551 - val_accuracy: 0.5250\n",
            "Epoch 118/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.6306 - val_loss: 0.5528 - val_accuracy: 0.5000\n",
            "Epoch 119/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.6292 - val_loss: 0.5519 - val_accuracy: 0.5000\n",
            "Epoch 120/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.6264 - val_loss: 0.5502 - val_accuracy: 0.5000\n",
            "Epoch 121/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.6167 - val_loss: 0.5478 - val_accuracy: 0.5000\n",
            "Epoch 122/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.6208 - val_loss: 0.5456 - val_accuracy: 0.5000\n",
            "Epoch 123/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.5833 - val_loss: 0.5441 - val_accuracy: 0.4875\n",
            "Epoch 124/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.5986 - val_loss: 0.5451 - val_accuracy: 0.5000\n",
            "Epoch 125/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.6014 - val_loss: 0.5457 - val_accuracy: 0.5375\n",
            "Epoch 126/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.6222 - val_loss: 0.5434 - val_accuracy: 0.5000\n",
            "Epoch 127/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.6264 - val_loss: 0.5431 - val_accuracy: 0.5250\n",
            "Epoch 128/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.6222 - val_loss: 0.5417 - val_accuracy: 0.5000\n",
            "Epoch 129/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.6444 - val_loss: 0.5386 - val_accuracy: 0.5000\n",
            "Epoch 130/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.5986 - val_loss: 0.5399 - val_accuracy: 0.5250\n",
            "Epoch 131/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.6014 - val_loss: 0.5418 - val_accuracy: 0.5625\n",
            "Epoch 132/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.6583 - val_loss: 0.5387 - val_accuracy: 0.5375\n",
            "Epoch 133/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.6347 - val_loss: 0.5396 - val_accuracy: 0.5625\n",
            "Epoch 134/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.6569 - val_loss: 0.5374 - val_accuracy: 0.5500\n",
            "Epoch 135/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.6514 - val_loss: 0.5365 - val_accuracy: 0.5500\n",
            "Epoch 136/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.6583 - val_loss: 0.5356 - val_accuracy: 0.5500\n",
            "Epoch 137/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.6389 - val_loss: 0.5346 - val_accuracy: 0.5500\n",
            "Epoch 138/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.6597 - val_loss: 0.5303 - val_accuracy: 0.5000\n",
            "Epoch 139/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.6042 - val_loss: 0.5299 - val_accuracy: 0.5000\n",
            "Epoch 140/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.6431 - val_loss: 0.5278 - val_accuracy: 0.5000\n",
            "Epoch 141/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.6167 - val_loss: 0.5272 - val_accuracy: 0.5000\n",
            "Epoch 142/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.5986 - val_loss: 0.5265 - val_accuracy: 0.5000\n",
            "Epoch 143/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.5931 - val_loss: 0.5277 - val_accuracy: 0.5375\n",
            "Epoch 144/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.6417 - val_loss: 0.5241 - val_accuracy: 0.5000\n",
            "Epoch 145/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.6236 - val_loss: 0.5236 - val_accuracy: 0.5000\n",
            "Epoch 146/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.5847 - val_loss: 0.5232 - val_accuracy: 0.5000\n",
            "Epoch 147/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.6111 - val_loss: 0.5214 - val_accuracy: 0.5000\n",
            "Epoch 148/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.6139 - val_loss: 0.5203 - val_accuracy: 0.5000\n",
            "Epoch 149/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.6389 - val_loss: 0.5171 - val_accuracy: 0.4875\n",
            "Epoch 150/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.5889 - val_loss: 0.5172 - val_accuracy: 0.5000\n",
            "Epoch 151/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.6056 - val_loss: 0.5182 - val_accuracy: 0.5000\n",
            "Epoch 152/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.6153 - val_loss: 0.5178 - val_accuracy: 0.5000\n",
            "Epoch 153/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.6292 - val_loss: 0.5133 - val_accuracy: 0.4875\n",
            "Epoch 154/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.5403 - val_loss: 0.5151 - val_accuracy: 0.5000\n",
            "Epoch 155/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.6111 - val_loss: 0.5150 - val_accuracy: 0.5000\n",
            "Epoch 156/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.5806 - val_loss: 0.5151 - val_accuracy: 0.5250\n",
            "Epoch 157/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.6236 - val_loss: 0.5145 - val_accuracy: 0.5250\n",
            "Epoch 158/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.6139 - val_loss: 0.5136 - val_accuracy: 0.5250\n",
            "Epoch 159/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.6403 - val_loss: 0.5132 - val_accuracy: 0.5250\n",
            "Epoch 160/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.6333 - val_loss: 0.5109 - val_accuracy: 0.5000\n",
            "Epoch 161/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.6319 - val_loss: 0.5098 - val_accuracy: 0.5000\n",
            "Epoch 162/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.5889 - val_loss: 0.5113 - val_accuracy: 0.5375\n",
            "Epoch 163/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.6403 - val_loss: 0.5091 - val_accuracy: 0.5000\n",
            "Epoch 164/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.6389 - val_loss: 0.5058 - val_accuracy: 0.5000\n",
            "Epoch 165/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.5847 - val_loss: 0.5062 - val_accuracy: 0.5000\n",
            "Epoch 166/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.5847 - val_loss: 0.5079 - val_accuracy: 0.5250\n",
            "Epoch 167/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.6472 - val_loss: 0.5072 - val_accuracy: 0.5250\n",
            "Epoch 168/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.6361 - val_loss: 0.5056 - val_accuracy: 0.5000\n",
            "Epoch 169/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.6181 - val_loss: 0.5046 - val_accuracy: 0.5000\n",
            "Epoch 170/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.6278 - val_loss: 0.5019 - val_accuracy: 0.5000\n",
            "Epoch 171/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.5806 - val_loss: 0.5010 - val_accuracy: 0.5000\n",
            "Epoch 172/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.5903 - val_loss: 0.5002 - val_accuracy: 0.4875\n",
            "Epoch 173/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.5528 - val_loss: 0.5039 - val_accuracy: 0.5375\n",
            "Epoch 174/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.6458 - val_loss: 0.5029 - val_accuracy: 0.5375\n",
            "Epoch 175/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.6514 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 176/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.6042 - val_loss: 0.4983 - val_accuracy: 0.5000\n",
            "Epoch 177/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.5847 - val_loss: 0.4981 - val_accuracy: 0.5000\n",
            "Epoch 178/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.5792 - val_loss: 0.5000 - val_accuracy: 0.5250\n",
            "Epoch 179/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.6500 - val_loss: 0.4978 - val_accuracy: 0.5000\n",
            "Epoch 180/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.6292 - val_loss: 0.4966 - val_accuracy: 0.5000\n",
            "Epoch 181/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.6083 - val_loss: 0.4956 - val_accuracy: 0.5000\n",
            "Epoch 182/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.5958 - val_loss: 0.4968 - val_accuracy: 0.5000\n",
            "Epoch 183/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.5903 - val_loss: 0.4989 - val_accuracy: 0.5875\n",
            "Epoch 184/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.6556 - val_loss: 0.4969 - val_accuracy: 0.5375\n",
            "Epoch 185/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.6694 - val_loss: 0.4940 - val_accuracy: 0.5000\n",
            "Epoch 186/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.5889 - val_loss: 0.4939 - val_accuracy: 0.5000\n",
            "Epoch 187/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.6111 - val_loss: 0.4968 - val_accuracy: 0.5875\n",
            "Epoch 188/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.6764 - val_loss: 0.4968 - val_accuracy: 0.5875\n",
            "Epoch 189/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.6667 - val_loss: 0.4976 - val_accuracy: 0.6000\n",
            "Epoch 190/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.6819 - val_loss: 0.4954 - val_accuracy: 0.5875\n",
            "Epoch 191/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.6694 - val_loss: 0.4912 - val_accuracy: 0.5000\n",
            "Epoch 192/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.5931 - val_loss: 0.4887 - val_accuracy: 0.5000\n",
            "Epoch 193/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.5556 - val_loss: 0.4921 - val_accuracy: 0.5375\n",
            "Epoch 194/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.6333 - val_loss: 0.4929 - val_accuracy: 0.5875\n",
            "Epoch 195/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.6639 - val_loss: 0.4889 - val_accuracy: 0.5000\n",
            "Epoch 196/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.5986 - val_loss: 0.4880 - val_accuracy: 0.5000\n",
            "Epoch 197/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.6069 - val_loss: 0.4903 - val_accuracy: 0.5500\n",
            "Epoch 198/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6569 - val_loss: 0.4891 - val_accuracy: 0.5375\n",
            "Epoch 199/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.6319 - val_loss: 0.4913 - val_accuracy: 0.6000\n",
            "Epoch 200/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.6708 - val_loss: 0.4881 - val_accuracy: 0.5250\n",
            "Epoch 201/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.6514 - val_loss: 0.4866 - val_accuracy: 0.5000\n",
            "Epoch 202/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.5764 - val_loss: 0.4868 - val_accuracy: 0.5250\n",
            "Epoch 203/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.6500 - val_loss: 0.4847 - val_accuracy: 0.5000\n",
            "Epoch 204/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.6306 - val_loss: 0.4860 - val_accuracy: 0.5250\n",
            "Epoch 205/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.6444 - val_loss: 0.4875 - val_accuracy: 0.5875\n",
            "Epoch 206/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.6778 - val_loss: 0.4868 - val_accuracy: 0.5875\n",
            "Epoch 207/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.6722 - val_loss: 0.4847 - val_accuracy: 0.5375\n",
            "Epoch 208/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.6458 - val_loss: 0.4849 - val_accuracy: 0.5625\n",
            "Epoch 209/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.6514 - val_loss: 0.4843 - val_accuracy: 0.5500\n",
            "Epoch 210/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.6500 - val_loss: 0.4831 - val_accuracy: 0.5250\n",
            "Epoch 211/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.6528 - val_loss: 0.4840 - val_accuracy: 0.5750\n",
            "Epoch 212/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.6250 - val_loss: 0.4852 - val_accuracy: 0.6000\n",
            "Epoch 213/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.6736 - val_loss: 0.4837 - val_accuracy: 0.5875\n",
            "Epoch 214/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.6639 - val_loss: 0.4839 - val_accuracy: 0.6000\n",
            "Epoch 215/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.6722 - val_loss: 0.4863 - val_accuracy: 0.6000\n",
            "Epoch 216/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.6972 - val_loss: 0.4811 - val_accuracy: 0.5375\n",
            "Epoch 217/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.6292 - val_loss: 0.4829 - val_accuracy: 0.6000\n",
            "Epoch 218/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.6736 - val_loss: 0.4792 - val_accuracy: 0.5250\n",
            "Epoch 219/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.6444 - val_loss: 0.4789 - val_accuracy: 0.5250\n",
            "Epoch 220/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.6556 - val_loss: 0.4760 - val_accuracy: 0.5000\n",
            "Epoch 221/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.5472 - val_loss: 0.4808 - val_accuracy: 0.6000\n",
            "Epoch 222/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.6708 - val_loss: 0.4762 - val_accuracy: 0.5000\n",
            "Epoch 223/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.6347 - val_loss: 0.4769 - val_accuracy: 0.5125\n",
            "Epoch 224/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.6056 - val_loss: 0.4778 - val_accuracy: 0.5500\n",
            "Epoch 225/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.6458 - val_loss: 0.4756 - val_accuracy: 0.5000\n",
            "Epoch 226/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.6181 - val_loss: 0.4786 - val_accuracy: 0.6000\n",
            "Epoch 227/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.6861 - val_loss: 0.4769 - val_accuracy: 0.5750\n",
            "Epoch 228/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.6444 - val_loss: 0.4787 - val_accuracy: 0.6000\n",
            "Epoch 229/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.6847 - val_loss: 0.4780 - val_accuracy: 0.6000\n",
            "Epoch 230/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.6681 - val_loss: 0.4757 - val_accuracy: 0.5625\n",
            "Epoch 231/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.6194 - val_loss: 0.4813 - val_accuracy: 0.6000\n",
            "Epoch 232/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.6986 - val_loss: 0.4807 - val_accuracy: 0.6000\n",
            "Epoch 233/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7139 - val_loss: 0.4753 - val_accuracy: 0.5750\n",
            "Epoch 234/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.6472 - val_loss: 0.4757 - val_accuracy: 0.6000\n",
            "Epoch 235/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.6819 - val_loss: 0.4721 - val_accuracy: 0.5000\n",
            "Epoch 236/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.6111 - val_loss: 0.4726 - val_accuracy: 0.5250\n",
            "Epoch 237/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.6472 - val_loss: 0.4700 - val_accuracy: 0.5000\n",
            "Epoch 238/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.5653 - val_loss: 0.4733 - val_accuracy: 0.5750\n",
            "Epoch 239/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.6653 - val_loss: 0.4717 - val_accuracy: 0.5250\n",
            "Epoch 240/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.6458 - val_loss: 0.4717 - val_accuracy: 0.5375\n",
            "Epoch 241/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.6306 - val_loss: 0.4753 - val_accuracy: 0.6000\n",
            "Epoch 242/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7028 - val_loss: 0.4709 - val_accuracy: 0.5250\n",
            "Epoch 243/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.6625 - val_loss: 0.4690 - val_accuracy: 0.5000\n",
            "Epoch 244/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.6306 - val_loss: 0.4675 - val_accuracy: 0.5000\n",
            "Epoch 245/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.6181 - val_loss: 0.4655 - val_accuracy: 0.4875\n",
            "Epoch 246/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.5486 - val_loss: 0.4663 - val_accuracy: 0.4875\n",
            "Epoch 247/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.6056 - val_loss: 0.4673 - val_accuracy: 0.5000\n",
            "Epoch 248/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.6125 - val_loss: 0.4707 - val_accuracy: 0.6000\n",
            "Epoch 249/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.6750 - val_loss: 0.4712 - val_accuracy: 0.6000\n",
            "Epoch 250/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.6875 - val_loss: 0.4696 - val_accuracy: 0.5750\n",
            "Epoch 251/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.6819 - val_loss: 0.4677 - val_accuracy: 0.5250\n",
            "Epoch 252/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.6625 - val_loss: 0.4686 - val_accuracy: 0.5750\n",
            "Epoch 253/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.6611 - val_loss: 0.4677 - val_accuracy: 0.5625\n",
            "Epoch 254/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.6569 - val_loss: 0.4689 - val_accuracy: 0.6000\n",
            "Epoch 255/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.6611 - val_loss: 0.4709 - val_accuracy: 0.6000\n",
            "Epoch 256/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.6681 - val_loss: 0.4695 - val_accuracy: 0.6000\n",
            "Epoch 257/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.6889 - val_loss: 0.4687 - val_accuracy: 0.6000\n",
            "Epoch 258/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.6694 - val_loss: 0.4702 - val_accuracy: 0.6000\n",
            "Epoch 259/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.6944 - val_loss: 0.4674 - val_accuracy: 0.6000\n",
            "Epoch 260/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.6931 - val_loss: 0.4656 - val_accuracy: 0.5375\n",
            "Epoch 261/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.6333 - val_loss: 0.4696 - val_accuracy: 0.6000\n",
            "Epoch 262/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7069 - val_loss: 0.4674 - val_accuracy: 0.6000\n",
            "Epoch 263/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.6986 - val_loss: 0.4639 - val_accuracy: 0.5125\n",
            "Epoch 264/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.6028 - val_loss: 0.4669 - val_accuracy: 0.6000\n",
            "Epoch 265/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.6708 - val_loss: 0.4649 - val_accuracy: 0.5750\n",
            "Epoch 266/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.6528 - val_loss: 0.4684 - val_accuracy: 0.6000\n",
            "Epoch 267/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.6931 - val_loss: 0.4660 - val_accuracy: 0.6000\n",
            "Epoch 268/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7014 - val_loss: 0.4633 - val_accuracy: 0.5375\n",
            "Epoch 269/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.6833 - val_loss: 0.4621 - val_accuracy: 0.5000\n",
            "Epoch 270/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.6583 - val_loss: 0.4625 - val_accuracy: 0.5250\n",
            "Epoch 271/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.6472 - val_loss: 0.4663 - val_accuracy: 0.6000\n",
            "Epoch 272/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.6819 - val_loss: 0.4628 - val_accuracy: 0.5625\n",
            "Epoch 273/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.6306 - val_loss: 0.4665 - val_accuracy: 0.6000\n",
            "Epoch 274/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7042 - val_loss: 0.4674 - val_accuracy: 0.6000\n",
            "Epoch 275/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7097 - val_loss: 0.4645 - val_accuracy: 0.6000\n",
            "Epoch 276/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.6917 - val_loss: 0.4656 - val_accuracy: 0.6000\n",
            "Epoch 277/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7069 - val_loss: 0.4641 - val_accuracy: 0.6000\n",
            "Epoch 278/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.6944 - val_loss: 0.4663 - val_accuracy: 0.6000\n",
            "Epoch 279/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7181 - val_loss: 0.4595 - val_accuracy: 0.5000\n",
            "Epoch 280/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.6569 - val_loss: 0.4600 - val_accuracy: 0.5375\n",
            "Epoch 281/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.6472 - val_loss: 0.4596 - val_accuracy: 0.5250\n",
            "Epoch 282/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.6542 - val_loss: 0.4581 - val_accuracy: 0.5000\n",
            "Epoch 283/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.6431 - val_loss: 0.4575 - val_accuracy: 0.5000\n",
            "Epoch 284/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.5986 - val_loss: 0.4607 - val_accuracy: 0.6000\n",
            "Epoch 285/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7042 - val_loss: 0.4592 - val_accuracy: 0.5625\n",
            "Epoch 286/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.6903 - val_loss: 0.4573 - val_accuracy: 0.5000\n",
            "Epoch 287/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.6111 - val_loss: 0.4615 - val_accuracy: 0.6000\n",
            "Epoch 288/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.6806 - val_loss: 0.4627 - val_accuracy: 0.6000\n",
            "Epoch 289/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7097 - val_loss: 0.4623 - val_accuracy: 0.6000\n",
            "Epoch 290/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.6944 - val_loss: 0.4599 - val_accuracy: 0.6000\n",
            "Epoch 291/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.6931 - val_loss: 0.4584 - val_accuracy: 0.5875\n",
            "Epoch 292/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.6653 - val_loss: 0.4583 - val_accuracy: 0.5875\n",
            "Epoch 293/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.6611 - val_loss: 0.4598 - val_accuracy: 0.6000\n",
            "Epoch 294/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.6903 - val_loss: 0.4584 - val_accuracy: 0.6000\n",
            "Epoch 295/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.6792 - val_loss: 0.4575 - val_accuracy: 0.5750\n",
            "Epoch 296/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.6500 - val_loss: 0.4605 - val_accuracy: 0.6000\n",
            "Epoch 297/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7056 - val_loss: 0.4579 - val_accuracy: 0.6000\n",
            "Epoch 298/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.6847 - val_loss: 0.4570 - val_accuracy: 0.5875\n",
            "Epoch 299/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.6611 - val_loss: 0.4572 - val_accuracy: 0.6000\n",
            "Epoch 300/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.6681 - val_loss: 0.4579 - val_accuracy: 0.6000\n",
            "Epoch 301/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.6625 - val_loss: 0.4595 - val_accuracy: 0.6000\n",
            "Epoch 302/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.6958 - val_loss: 0.4551 - val_accuracy: 0.5500\n",
            "Epoch 303/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.6708 - val_loss: 0.4527 - val_accuracy: 0.5000\n",
            "Epoch 304/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.6347 - val_loss: 0.4541 - val_accuracy: 0.5250\n",
            "Epoch 305/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.6444 - val_loss: 0.4534 - val_accuracy: 0.5000\n",
            "Epoch 306/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.6111 - val_loss: 0.4527 - val_accuracy: 0.5000\n",
            "Epoch 307/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.6042 - val_loss: 0.4552 - val_accuracy: 0.6000\n",
            "Epoch 308/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.6778 - val_loss: 0.4545 - val_accuracy: 0.5750\n",
            "Epoch 309/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.6764 - val_loss: 0.4593 - val_accuracy: 0.6000\n",
            "Epoch 310/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.7139 - val_loss: 0.4550 - val_accuracy: 0.6000\n",
            "Epoch 311/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.6681 - val_loss: 0.4557 - val_accuracy: 0.6000\n",
            "Epoch 312/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.7042 - val_loss: 0.4558 - val_accuracy: 0.6000\n",
            "Epoch 313/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.6875 - val_loss: 0.4547 - val_accuracy: 0.6000\n",
            "Epoch 314/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.6694 - val_loss: 0.4522 - val_accuracy: 0.5375\n",
            "Epoch 315/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.6792 - val_loss: 0.4519 - val_accuracy: 0.5375\n",
            "Epoch 316/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.6278 - val_loss: 0.4529 - val_accuracy: 0.5750\n",
            "Epoch 317/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.6806 - val_loss: 0.4550 - val_accuracy: 0.6000\n",
            "Epoch 318/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.6764 - val_loss: 0.4561 - val_accuracy: 0.6000\n",
            "Epoch 319/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.7028 - val_loss: 0.4554 - val_accuracy: 0.6000\n",
            "Epoch 320/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.6986 - val_loss: 0.4543 - val_accuracy: 0.6000\n",
            "Epoch 321/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.7000 - val_loss: 0.4531 - val_accuracy: 0.6000\n",
            "Epoch 322/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.6486 - val_loss: 0.4562 - val_accuracy: 0.6000\n",
            "Epoch 323/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.6944 - val_loss: 0.4532 - val_accuracy: 0.6000\n",
            "Epoch 324/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.6653 - val_loss: 0.4538 - val_accuracy: 0.6000\n",
            "Epoch 325/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.6792 - val_loss: 0.4543 - val_accuracy: 0.6000\n",
            "Epoch 326/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.6931 - val_loss: 0.4572 - val_accuracy: 0.6000\n",
            "Epoch 327/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.7056 - val_loss: 0.4538 - val_accuracy: 0.6000\n",
            "Epoch 328/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.7139 - val_loss: 0.4522 - val_accuracy: 0.6000\n",
            "Epoch 329/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.6722 - val_loss: 0.4526 - val_accuracy: 0.6000\n",
            "Epoch 330/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7014 - val_loss: 0.4543 - val_accuracy: 0.6000\n",
            "Epoch 331/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.7111 - val_loss: 0.4545 - val_accuracy: 0.6000\n",
            "Epoch 332/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7028 - val_loss: 0.4525 - val_accuracy: 0.6000\n",
            "Epoch 333/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.7028 - val_loss: 0.4502 - val_accuracy: 0.5875\n",
            "Epoch 334/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.6792 - val_loss: 0.4487 - val_accuracy: 0.5375\n",
            "Epoch 335/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.6292 - val_loss: 0.4459 - val_accuracy: 0.4875\n",
            "Epoch 336/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.5708 - val_loss: 0.4495 - val_accuracy: 0.5875\n",
            "Epoch 337/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.6694 - val_loss: 0.4508 - val_accuracy: 0.6000\n",
            "Epoch 338/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.6917 - val_loss: 0.4494 - val_accuracy: 0.5875\n",
            "Epoch 339/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.6792 - val_loss: 0.4468 - val_accuracy: 0.5000\n",
            "Epoch 340/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.6125 - val_loss: 0.4477 - val_accuracy: 0.5375\n",
            "Epoch 341/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.6708 - val_loss: 0.4464 - val_accuracy: 0.5000\n",
            "Epoch 342/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.6097 - val_loss: 0.4479 - val_accuracy: 0.5750\n",
            "Epoch 343/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.6958 - val_loss: 0.4463 - val_accuracy: 0.5000\n",
            "Epoch 344/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.5819 - val_loss: 0.4523 - val_accuracy: 0.6000\n",
            "Epoch 345/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.7208 - val_loss: 0.4476 - val_accuracy: 0.5750\n",
            "Epoch 346/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.6625 - val_loss: 0.4478 - val_accuracy: 0.5875\n",
            "Epoch 347/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.6347 - val_loss: 0.4556 - val_accuracy: 0.6625\n",
            "Epoch 348/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.7278 - val_loss: 0.4496 - val_accuracy: 0.6000\n",
            "Epoch 349/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.6972 - val_loss: 0.4501 - val_accuracy: 0.6000\n",
            "Epoch 350/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.7097 - val_loss: 0.4498 - val_accuracy: 0.6000\n",
            "Epoch 351/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.6875 - val_loss: 0.4511 - val_accuracy: 0.6000\n",
            "Epoch 352/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.7194 - val_loss: 0.4487 - val_accuracy: 0.6000\n",
            "Epoch 353/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.6931 - val_loss: 0.4470 - val_accuracy: 0.5875\n",
            "Epoch 354/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.6764 - val_loss: 0.4451 - val_accuracy: 0.5375\n",
            "Epoch 355/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.6389 - val_loss: 0.4483 - val_accuracy: 0.6000\n",
            "Epoch 356/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.6903 - val_loss: 0.4484 - val_accuracy: 0.6000\n",
            "Epoch 357/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.6875 - val_loss: 0.4486 - val_accuracy: 0.6000\n",
            "Epoch 358/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.7000 - val_loss: 0.4477 - val_accuracy: 0.6000\n",
            "Epoch 359/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.6736 - val_loss: 0.4495 - val_accuracy: 0.6000\n",
            "Epoch 360/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.7125 - val_loss: 0.4486 - val_accuracy: 0.6000\n",
            "Epoch 361/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.7000 - val_loss: 0.4457 - val_accuracy: 0.5875\n",
            "Epoch 362/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.6778 - val_loss: 0.4465 - val_accuracy: 0.6000\n",
            "Epoch 363/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.6875 - val_loss: 0.4453 - val_accuracy: 0.5875\n",
            "Epoch 364/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.6861 - val_loss: 0.4452 - val_accuracy: 0.5875\n",
            "Epoch 365/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.6861 - val_loss: 0.4468 - val_accuracy: 0.6000\n",
            "Epoch 366/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.7139 - val_loss: 0.4441 - val_accuracy: 0.5750\n",
            "Epoch 367/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.6833 - val_loss: 0.4443 - val_accuracy: 0.5875\n",
            "Epoch 368/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.6778 - val_loss: 0.4419 - val_accuracy: 0.5000\n",
            "Epoch 369/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.6194 - val_loss: 0.4442 - val_accuracy: 0.5875\n",
            "Epoch 370/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.6556 - val_loss: 0.4457 - val_accuracy: 0.6000\n",
            "Epoch 371/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.7014 - val_loss: 0.4431 - val_accuracy: 0.5500\n",
            "Epoch 372/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.6625 - val_loss: 0.4446 - val_accuracy: 0.6000\n",
            "Epoch 373/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.6819 - val_loss: 0.4440 - val_accuracy: 0.5875\n",
            "Epoch 374/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.6750 - val_loss: 0.4490 - val_accuracy: 0.6000\n",
            "Epoch 375/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.7153 - val_loss: 0.4492 - val_accuracy: 0.6125\n",
            "Epoch 376/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.7194 - val_loss: 0.4449 - val_accuracy: 0.6000\n",
            "Epoch 377/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.6917 - val_loss: 0.4426 - val_accuracy: 0.5500\n",
            "Epoch 378/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.6306 - val_loss: 0.4457 - val_accuracy: 0.6000\n",
            "Epoch 379/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.7139 - val_loss: 0.4432 - val_accuracy: 0.5875\n",
            "Epoch 380/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.7042 - val_loss: 0.4414 - val_accuracy: 0.5000\n",
            "Epoch 381/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.6597 - val_loss: 0.4421 - val_accuracy: 0.5500\n",
            "Epoch 382/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.6722 - val_loss: 0.4417 - val_accuracy: 0.5500\n",
            "Epoch 383/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.6153 - val_loss: 0.4441 - val_accuracy: 0.6000\n",
            "Epoch 384/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.6847 - val_loss: 0.4466 - val_accuracy: 0.6000\n",
            "Epoch 385/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.7167 - val_loss: 0.4457 - val_accuracy: 0.6000\n",
            "Epoch 386/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.7083 - val_loss: 0.4460 - val_accuracy: 0.6000\n",
            "Epoch 387/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.7097 - val_loss: 0.4445 - val_accuracy: 0.6000\n",
            "Epoch 388/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.6889 - val_loss: 0.4455 - val_accuracy: 0.6000\n",
            "Epoch 389/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.7028 - val_loss: 0.4447 - val_accuracy: 0.6000\n",
            "Epoch 390/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.7028 - val_loss: 0.4459 - val_accuracy: 0.6000\n",
            "Epoch 391/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.7167 - val_loss: 0.4434 - val_accuracy: 0.6000\n",
            "Epoch 392/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.6958 - val_loss: 0.4396 - val_accuracy: 0.5000\n",
            "Epoch 393/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.6764 - val_loss: 0.4405 - val_accuracy: 0.5500\n",
            "Epoch 394/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.6542 - val_loss: 0.4392 - val_accuracy: 0.5000\n",
            "Epoch 395/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.6014 - val_loss: 0.4408 - val_accuracy: 0.5875\n",
            "Epoch 396/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.6889 - val_loss: 0.4429 - val_accuracy: 0.6000\n",
            "Epoch 397/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.7069 - val_loss: 0.4432 - val_accuracy: 0.6000\n",
            "Epoch 398/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.7097 - val_loss: 0.4417 - val_accuracy: 0.6000\n",
            "Epoch 399/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.7028 - val_loss: 0.4411 - val_accuracy: 0.6000\n",
            "Epoch 400/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.6681 - val_loss: 0.4432 - val_accuracy: 0.6000\n",
            "Epoch 401/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.7167 - val_loss: 0.4390 - val_accuracy: 0.5500\n",
            "Epoch 402/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.6792 - val_loss: 0.4384 - val_accuracy: 0.5000\n",
            "Epoch 403/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.6653 - val_loss: 0.4385 - val_accuracy: 0.5125\n",
            "Epoch 404/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.6542 - val_loss: 0.4390 - val_accuracy: 0.5500\n",
            "Epoch 405/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.6361 - val_loss: 0.4424 - val_accuracy: 0.6000\n",
            "Epoch 406/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.7000 - val_loss: 0.4421 - val_accuracy: 0.6000\n",
            "Epoch 407/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.7125 - val_loss: 0.4386 - val_accuracy: 0.5500\n",
            "Epoch 408/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.6778 - val_loss: 0.4398 - val_accuracy: 0.6000\n",
            "Epoch 409/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.6611 - val_loss: 0.4410 - val_accuracy: 0.6000\n",
            "Epoch 410/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.7042 - val_loss: 0.4345 - val_accuracy: 0.4875\n",
            "Epoch 411/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.5667 - val_loss: 0.4377 - val_accuracy: 0.5375\n",
            "Epoch 412/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.6806 - val_loss: 0.4374 - val_accuracy: 0.5250\n",
            "Epoch 413/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.6750 - val_loss: 0.4373 - val_accuracy: 0.5250\n",
            "Epoch 414/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.6458 - val_loss: 0.4383 - val_accuracy: 0.5875\n",
            "Epoch 415/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.6694 - val_loss: 0.4400 - val_accuracy: 0.6000\n",
            "Epoch 416/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.6931 - val_loss: 0.4425 - val_accuracy: 0.6000\n",
            "Epoch 417/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.7292 - val_loss: 0.4397 - val_accuracy: 0.6000\n",
            "Epoch 418/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.6972 - val_loss: 0.4412 - val_accuracy: 0.6000\n",
            "Epoch 419/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.7000 - val_loss: 0.4428 - val_accuracy: 0.6125\n",
            "Epoch 420/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.7236 - val_loss: 0.4451 - val_accuracy: 0.6625\n",
            "Epoch 421/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.7306 - val_loss: 0.4431 - val_accuracy: 0.6250\n",
            "Epoch 422/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.7069 - val_loss: 0.4485 - val_accuracy: 0.6625\n",
            "Epoch 423/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.7347 - val_loss: 0.4452 - val_accuracy: 0.6625\n",
            "Epoch 424/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.7222 - val_loss: 0.4412 - val_accuracy: 0.6000\n",
            "Epoch 425/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.7222 - val_loss: 0.4396 - val_accuracy: 0.6000\n",
            "Epoch 426/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.6903 - val_loss: 0.4391 - val_accuracy: 0.6000\n",
            "Epoch 427/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.6931 - val_loss: 0.4364 - val_accuracy: 0.5500\n",
            "Epoch 428/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.6778 - val_loss: 0.4374 - val_accuracy: 0.5875\n",
            "Epoch 429/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.6625 - val_loss: 0.4363 - val_accuracy: 0.5500\n",
            "Epoch 430/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.7000 - val_loss: 0.4351 - val_accuracy: 0.5000\n",
            "Epoch 431/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.6569 - val_loss: 0.4359 - val_accuracy: 0.5500\n",
            "Epoch 432/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.6306 - val_loss: 0.4389 - val_accuracy: 0.6000\n",
            "Epoch 433/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.7014 - val_loss: 0.4380 - val_accuracy: 0.6000\n",
            "Epoch 434/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.6764 - val_loss: 0.4379 - val_accuracy: 0.6000\n",
            "Epoch 435/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.7069 - val_loss: 0.4357 - val_accuracy: 0.5500\n",
            "Epoch 436/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.6611 - val_loss: 0.4387 - val_accuracy: 0.6000\n",
            "Epoch 437/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.7000 - val_loss: 0.4390 - val_accuracy: 0.6000\n",
            "Epoch 438/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.7139 - val_loss: 0.4361 - val_accuracy: 0.5875\n",
            "Epoch 439/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.6847 - val_loss: 0.4348 - val_accuracy: 0.5500\n",
            "Epoch 440/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.6528 - val_loss: 0.4368 - val_accuracy: 0.6000\n",
            "Epoch 441/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.6986 - val_loss: 0.4360 - val_accuracy: 0.5875\n",
            "Epoch 442/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.6500 - val_loss: 0.4405 - val_accuracy: 0.6125\n",
            "Epoch 443/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.7236 - val_loss: 0.4399 - val_accuracy: 0.6000\n",
            "Epoch 444/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.7236 - val_loss: 0.4363 - val_accuracy: 0.6000\n",
            "Epoch 445/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.6750 - val_loss: 0.4344 - val_accuracy: 0.5500\n",
            "Epoch 446/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.6681 - val_loss: 0.4341 - val_accuracy: 0.5375\n",
            "Epoch 447/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.6556 - val_loss: 0.4339 - val_accuracy: 0.5250\n",
            "Epoch 448/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.6694 - val_loss: 0.4352 - val_accuracy: 0.5875\n",
            "Epoch 449/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.6514 - val_loss: 0.4379 - val_accuracy: 0.6000\n",
            "Epoch 450/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.7014 - val_loss: 0.4375 - val_accuracy: 0.6000\n",
            "Epoch 451/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.7194 - val_loss: 0.4329 - val_accuracy: 0.5000\n",
            "Epoch 452/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.6208 - val_loss: 0.4347 - val_accuracy: 0.5875\n",
            "Epoch 453/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.6694 - val_loss: 0.4353 - val_accuracy: 0.6000\n",
            "Epoch 454/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.6986 - val_loss: 0.4346 - val_accuracy: 0.5875\n",
            "Epoch 455/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.6306 - val_loss: 0.4403 - val_accuracy: 0.6375\n",
            "Epoch 456/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.7097 - val_loss: 0.4417 - val_accuracy: 0.6625\n",
            "Epoch 457/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.7208 - val_loss: 0.4393 - val_accuracy: 0.6250\n",
            "Epoch 458/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.7111 - val_loss: 0.4384 - val_accuracy: 0.6125\n",
            "Epoch 459/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.7139 - val_loss: 0.4359 - val_accuracy: 0.6000\n",
            "Epoch 460/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.7167 - val_loss: 0.4354 - val_accuracy: 0.6000\n",
            "Epoch 461/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.6958 - val_loss: 0.4385 - val_accuracy: 0.6125\n",
            "Epoch 462/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.7181 - val_loss: 0.4366 - val_accuracy: 0.6000\n",
            "Epoch 463/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.6847 - val_loss: 0.4376 - val_accuracy: 0.6000\n",
            "Epoch 464/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.7139 - val_loss: 0.4387 - val_accuracy: 0.6250\n",
            "Epoch 465/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.7194 - val_loss: 0.4393 - val_accuracy: 0.6250\n",
            "Epoch 466/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.7292 - val_loss: 0.4380 - val_accuracy: 0.6125\n",
            "Epoch 467/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.7153 - val_loss: 0.4363 - val_accuracy: 0.6000\n",
            "Epoch 468/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.6986 - val_loss: 0.4366 - val_accuracy: 0.6000\n",
            "Epoch 469/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.7000 - val_loss: 0.4357 - val_accuracy: 0.6000\n",
            "Epoch 470/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.6931 - val_loss: 0.4370 - val_accuracy: 0.6000\n",
            "Epoch 471/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.7264 - val_loss: 0.4344 - val_accuracy: 0.6000\n",
            "Epoch 472/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.6819 - val_loss: 0.4373 - val_accuracy: 0.6125\n",
            "Epoch 473/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.7236 - val_loss: 0.4348 - val_accuracy: 0.6000\n",
            "Epoch 474/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.7153 - val_loss: 0.4331 - val_accuracy: 0.5875\n",
            "Epoch 475/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.6972 - val_loss: 0.4302 - val_accuracy: 0.5000\n",
            "Epoch 476/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.6625 - val_loss: 0.4295 - val_accuracy: 0.4875\n",
            "Epoch 477/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.5750 - val_loss: 0.4352 - val_accuracy: 0.6000\n",
            "Epoch 478/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.6819 - val_loss: 0.4431 - val_accuracy: 0.6625\n",
            "Epoch 479/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.7417 - val_loss: 0.4410 - val_accuracy: 0.6625\n",
            "Epoch 480/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.7292 - val_loss: 0.4373 - val_accuracy: 0.6250\n",
            "Epoch 481/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.7347 - val_loss: 0.4358 - val_accuracy: 0.6000\n",
            "Epoch 482/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.7222 - val_loss: 0.4346 - val_accuracy: 0.6000\n",
            "Epoch 483/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.7000 - val_loss: 0.4331 - val_accuracy: 0.6000\n",
            "Epoch 484/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.6903 - val_loss: 0.4354 - val_accuracy: 0.6000\n",
            "Epoch 485/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.7264 - val_loss: 0.4371 - val_accuracy: 0.6250\n",
            "Epoch 486/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.7181 - val_loss: 0.4368 - val_accuracy: 0.6250\n",
            "Epoch 487/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.6833 - val_loss: 0.4402 - val_accuracy: 0.6625\n",
            "Epoch 488/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.7306 - val_loss: 0.4350 - val_accuracy: 0.6000\n",
            "Epoch 489/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.7167 - val_loss: 0.4376 - val_accuracy: 0.6625\n",
            "Epoch 490/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.7361 - val_loss: 0.4318 - val_accuracy: 0.5875\n",
            "Epoch 491/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.6778 - val_loss: 0.4333 - val_accuracy: 0.6000\n",
            "Epoch 492/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.7014 - val_loss: 0.4308 - val_accuracy: 0.5750\n",
            "Epoch 493/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.6347 - val_loss: 0.4345 - val_accuracy: 0.6000\n",
            "Epoch 494/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.7361 - val_loss: 0.4285 - val_accuracy: 0.5000\n",
            "Epoch 495/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.6000 - val_loss: 0.4351 - val_accuracy: 0.6125\n",
            "Epoch 496/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.7208 - val_loss: 0.4313 - val_accuracy: 0.5875\n",
            "Epoch 497/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.6986 - val_loss: 0.4319 - val_accuracy: 0.6000\n",
            "Epoch 498/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.6736 - val_loss: 0.4346 - val_accuracy: 0.6125\n",
            "Epoch 499/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.7278 - val_loss: 0.4311 - val_accuracy: 0.5875\n",
            "Epoch 500/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.7028 - val_loss: 0.4323 - val_accuracy: 0.6000\n",
            "Epoch 501/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.6931 - val_loss: 0.4315 - val_accuracy: 0.6000\n",
            "Epoch 502/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.6917 - val_loss: 0.4326 - val_accuracy: 0.6000\n",
            "Epoch 503/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.7139 - val_loss: 0.4307 - val_accuracy: 0.5875\n",
            "Epoch 504/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.6722 - val_loss: 0.4281 - val_accuracy: 0.5000\n",
            "Epoch 505/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.6653 - val_loss: 0.4287 - val_accuracy: 0.5000\n",
            "Epoch 506/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.6556 - val_loss: 0.4348 - val_accuracy: 0.6250\n",
            "Epoch 507/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.7319 - val_loss: 0.4315 - val_accuracy: 0.6000\n",
            "Epoch 508/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.6792 - val_loss: 0.4348 - val_accuracy: 0.6250\n",
            "Epoch 509/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.7194 - val_loss: 0.4334 - val_accuracy: 0.6000\n",
            "Epoch 510/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.7097 - val_loss: 0.4313 - val_accuracy: 0.6000\n",
            "Epoch 511/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.6736 - val_loss: 0.4339 - val_accuracy: 0.6125\n",
            "Epoch 512/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.7139 - val_loss: 0.4318 - val_accuracy: 0.6000\n",
            "Epoch 513/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.7139 - val_loss: 0.4281 - val_accuracy: 0.5000\n",
            "Epoch 514/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.6889 - val_loss: 0.4280 - val_accuracy: 0.5000\n",
            "Epoch 515/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.6931 - val_loss: 0.4273 - val_accuracy: 0.5000\n",
            "Epoch 516/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.6153 - val_loss: 0.4267 - val_accuracy: 0.4875\n",
            "Epoch 517/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.6083 - val_loss: 0.4296 - val_accuracy: 0.5875\n",
            "Epoch 518/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.6486 - val_loss: 0.4329 - val_accuracy: 0.6000\n",
            "Epoch 519/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.7181 - val_loss: 0.4326 - val_accuracy: 0.6000\n",
            "Epoch 520/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.7028 - val_loss: 0.4326 - val_accuracy: 0.6000\n",
            "Epoch 521/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.7083 - val_loss: 0.4344 - val_accuracy: 0.6500\n",
            "Epoch 522/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.7250 - val_loss: 0.4317 - val_accuracy: 0.6000\n",
            "Epoch 523/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.7194 - val_loss: 0.4325 - val_accuracy: 0.6000\n",
            "Epoch 524/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.7153 - val_loss: 0.4334 - val_accuracy: 0.6250\n",
            "Epoch 525/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.7306 - val_loss: 0.4298 - val_accuracy: 0.6000\n",
            "Epoch 526/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.7014 - val_loss: 0.4323 - val_accuracy: 0.6125\n",
            "Epoch 527/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.7208 - val_loss: 0.4304 - val_accuracy: 0.6000\n",
            "Epoch 528/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.6681 - val_loss: 0.4298 - val_accuracy: 0.6000\n",
            "Epoch 529/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.7000 - val_loss: 0.4256 - val_accuracy: 0.4750\n",
            "Epoch 530/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.5625 - val_loss: 0.4305 - val_accuracy: 0.6000\n",
            "Epoch 531/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.7056 - val_loss: 0.4253 - val_accuracy: 0.4625\n",
            "Epoch 532/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.6139 - val_loss: 0.4269 - val_accuracy: 0.5000\n",
            "Epoch 533/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.6597 - val_loss: 0.4322 - val_accuracy: 0.6125\n",
            "Epoch 534/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.7208 - val_loss: 0.4321 - val_accuracy: 0.6125\n",
            "Epoch 535/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.6986 - val_loss: 0.4331 - val_accuracy: 0.6375\n",
            "Epoch 536/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.7278 - val_loss: 0.4335 - val_accuracy: 0.6625\n",
            "Epoch 537/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.7292 - val_loss: 0.4299 - val_accuracy: 0.6000\n",
            "Epoch 538/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.7111 - val_loss: 0.4278 - val_accuracy: 0.5875\n",
            "Epoch 539/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.6681 - val_loss: 0.4309 - val_accuracy: 0.6000\n",
            "Epoch 540/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.7139 - val_loss: 0.4270 - val_accuracy: 0.5500\n",
            "Epoch 541/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.6792 - val_loss: 0.4299 - val_accuracy: 0.6000\n",
            "Epoch 542/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.7264 - val_loss: 0.4254 - val_accuracy: 0.5000\n",
            "Epoch 543/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.6708 - val_loss: 0.4294 - val_accuracy: 0.6000\n",
            "Epoch 544/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.7153 - val_loss: 0.4280 - val_accuracy: 0.6000\n",
            "Epoch 545/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.7000 - val_loss: 0.4322 - val_accuracy: 0.6375\n",
            "Epoch 546/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.7236 - val_loss: 0.4300 - val_accuracy: 0.6000\n",
            "Epoch 547/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.7139 - val_loss: 0.4260 - val_accuracy: 0.5250\n",
            "Epoch 548/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.6097 - val_loss: 0.4343 - val_accuracy: 0.6625\n",
            "Epoch 549/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.7278 - val_loss: 0.4348 - val_accuracy: 0.6625\n",
            "Epoch 550/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.7375 - val_loss: 0.4289 - val_accuracy: 0.6000\n",
            "Epoch 551/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.7222 - val_loss: 0.4257 - val_accuracy: 0.5125\n",
            "Epoch 552/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.6458 - val_loss: 0.4243 - val_accuracy: 0.4875\n",
            "Epoch 553/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.6042 - val_loss: 0.4308 - val_accuracy: 0.6125\n",
            "Epoch 554/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.7222 - val_loss: 0.4314 - val_accuracy: 0.6250\n",
            "Epoch 555/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.7153 - val_loss: 0.4330 - val_accuracy: 0.6625\n",
            "Epoch 556/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.7306 - val_loss: 0.4300 - val_accuracy: 0.6000\n",
            "Epoch 557/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.7167 - val_loss: 0.4315 - val_accuracy: 0.6375\n",
            "Epoch 558/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.7361 - val_loss: 0.4308 - val_accuracy: 0.6250\n",
            "Epoch 559/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.7167 - val_loss: 0.4308 - val_accuracy: 0.6250\n",
            "Epoch 560/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.7208 - val_loss: 0.4307 - val_accuracy: 0.6250\n",
            "Epoch 561/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.7250 - val_loss: 0.4276 - val_accuracy: 0.6000\n",
            "Epoch 562/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.7083 - val_loss: 0.4285 - val_accuracy: 0.6000\n",
            "Epoch 563/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.7042 - val_loss: 0.4296 - val_accuracy: 0.6125\n",
            "Epoch 564/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.7153 - val_loss: 0.4334 - val_accuracy: 0.6625\n",
            "Epoch 565/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.7417 - val_loss: 0.4290 - val_accuracy: 0.6000\n",
            "Epoch 566/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.7264 - val_loss: 0.4303 - val_accuracy: 0.6250\n",
            "Epoch 567/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.7111 - val_loss: 0.4305 - val_accuracy: 0.6250\n",
            "Epoch 568/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.7181 - val_loss: 0.4326 - val_accuracy: 0.6625\n",
            "Epoch 569/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.6986 - val_loss: 0.4374 - val_accuracy: 0.6625\n",
            "Epoch 570/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.7389 - val_loss: 0.4324 - val_accuracy: 0.6625\n",
            "Epoch 571/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.7236 - val_loss: 0.4331 - val_accuracy: 0.6625\n",
            "Epoch 572/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.7264 - val_loss: 0.4317 - val_accuracy: 0.6625\n",
            "Epoch 573/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.7208 - val_loss: 0.4325 - val_accuracy: 0.6625\n",
            "Epoch 574/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.7417 - val_loss: 0.4277 - val_accuracy: 0.6000\n",
            "Epoch 575/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.7167 - val_loss: 0.4288 - val_accuracy: 0.6000\n",
            "Epoch 576/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.7069 - val_loss: 0.4301 - val_accuracy: 0.6250\n",
            "Epoch 577/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.7333 - val_loss: 0.4259 - val_accuracy: 0.5875\n",
            "Epoch 578/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.6806 - val_loss: 0.4311 - val_accuracy: 0.6625\n",
            "Epoch 579/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.7319 - val_loss: 0.4274 - val_accuracy: 0.6000\n",
            "Epoch 580/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.6931 - val_loss: 0.4304 - val_accuracy: 0.6500\n",
            "Epoch 581/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.7306 - val_loss: 0.4265 - val_accuracy: 0.6000\n",
            "Epoch 582/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.7222 - val_loss: 0.4255 - val_accuracy: 0.5875\n",
            "Epoch 583/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.6722 - val_loss: 0.4309 - val_accuracy: 0.6625\n",
            "Epoch 584/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.7278 - val_loss: 0.4320 - val_accuracy: 0.6625\n",
            "Epoch 585/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.7361 - val_loss: 0.4292 - val_accuracy: 0.6250\n",
            "Epoch 586/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.7167 - val_loss: 0.4296 - val_accuracy: 0.6375\n",
            "Epoch 587/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.7306 - val_loss: 0.4270 - val_accuracy: 0.6000\n",
            "Epoch 588/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.7139 - val_loss: 0.4304 - val_accuracy: 0.6625\n",
            "Epoch 589/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.7389 - val_loss: 0.4275 - val_accuracy: 0.6000\n",
            "Epoch 590/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.7139 - val_loss: 0.4259 - val_accuracy: 0.6000\n",
            "Epoch 591/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.7042 - val_loss: 0.4253 - val_accuracy: 0.6000\n",
            "Epoch 592/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.7181 - val_loss: 0.4242 - val_accuracy: 0.5875\n",
            "Epoch 593/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.6944 - val_loss: 0.4233 - val_accuracy: 0.5250\n",
            "Epoch 594/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.6736 - val_loss: 0.4247 - val_accuracy: 0.5875\n",
            "Epoch 595/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.7167 - val_loss: 0.4240 - val_accuracy: 0.5750\n",
            "Epoch 596/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.6597 - val_loss: 0.4223 - val_accuracy: 0.5000\n",
            "Epoch 597/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.5958 - val_loss: 0.4254 - val_accuracy: 0.6000\n",
            "Epoch 598/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.7194 - val_loss: 0.4228 - val_accuracy: 0.5000\n",
            "Epoch 599/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.6222 - val_loss: 0.4235 - val_accuracy: 0.5500\n",
            "Epoch 600/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.6986 - val_loss: 0.4214 - val_accuracy: 0.4875\n",
            "Epoch 601/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.6222 - val_loss: 0.4237 - val_accuracy: 0.5875\n",
            "Epoch 602/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.6764 - val_loss: 0.4263 - val_accuracy: 0.6000\n",
            "Epoch 603/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.7153 - val_loss: 0.4218 - val_accuracy: 0.5000\n",
            "Epoch 604/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.6486 - val_loss: 0.4229 - val_accuracy: 0.5500\n",
            "Epoch 605/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.6486 - val_loss: 0.4258 - val_accuracy: 0.6000\n",
            "Epoch 606/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.7014 - val_loss: 0.4268 - val_accuracy: 0.6125\n",
            "Epoch 607/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.7222 - val_loss: 0.4253 - val_accuracy: 0.6000\n",
            "Epoch 608/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.7125 - val_loss: 0.4275 - val_accuracy: 0.6250\n",
            "Epoch 609/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.7306 - val_loss: 0.4280 - val_accuracy: 0.6375\n",
            "Epoch 610/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.7319 - val_loss: 0.4244 - val_accuracy: 0.6000\n",
            "Epoch 611/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.6958 - val_loss: 0.4293 - val_accuracy: 0.6625\n",
            "Epoch 612/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.7347 - val_loss: 0.4250 - val_accuracy: 0.6000\n",
            "Epoch 613/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.7000 - val_loss: 0.4225 - val_accuracy: 0.5500\n",
            "Epoch 614/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.7125 - val_loss: 0.4213 - val_accuracy: 0.5000\n",
            "Epoch 615/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.6250 - val_loss: 0.4229 - val_accuracy: 0.5750\n",
            "Epoch 616/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.6722 - val_loss: 0.4249 - val_accuracy: 0.6000\n",
            "Epoch 617/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.6722 - val_loss: 0.4287 - val_accuracy: 0.6625\n",
            "Epoch 618/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.7264 - val_loss: 0.4295 - val_accuracy: 0.6625\n",
            "Epoch 619/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.7250 - val_loss: 0.4255 - val_accuracy: 0.6000\n",
            "Epoch 620/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.7167 - val_loss: 0.4209 - val_accuracy: 0.5000\n",
            "Epoch 621/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.6042 - val_loss: 0.4256 - val_accuracy: 0.6000\n",
            "Epoch 622/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.7097 - val_loss: 0.4273 - val_accuracy: 0.6375\n",
            "Epoch 623/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.7292 - val_loss: 0.4238 - val_accuracy: 0.6000\n",
            "Epoch 624/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.7153 - val_loss: 0.4253 - val_accuracy: 0.6000\n",
            "Epoch 625/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.7028 - val_loss: 0.4273 - val_accuracy: 0.6375\n",
            "Epoch 626/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.7153 - val_loss: 0.4254 - val_accuracy: 0.6000\n",
            "Epoch 627/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.7250 - val_loss: 0.4253 - val_accuracy: 0.6000\n",
            "Epoch 628/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.6847 - val_loss: 0.4265 - val_accuracy: 0.6250\n",
            "Epoch 629/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.7125 - val_loss: 0.4224 - val_accuracy: 0.5875\n",
            "Epoch 630/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.6986 - val_loss: 0.4224 - val_accuracy: 0.5875\n",
            "Epoch 631/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.6917 - val_loss: 0.4275 - val_accuracy: 0.6625\n",
            "Epoch 632/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.7306 - val_loss: 0.4263 - val_accuracy: 0.6250\n",
            "Epoch 633/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.7125 - val_loss: 0.4317 - val_accuracy: 0.6625\n",
            "Epoch 634/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.7403 - val_loss: 0.4284 - val_accuracy: 0.6625\n",
            "Epoch 635/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.7278 - val_loss: 0.4263 - val_accuracy: 0.6250\n",
            "Epoch 636/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.7306 - val_loss: 0.4235 - val_accuracy: 0.6000\n",
            "Epoch 637/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.7194 - val_loss: 0.4218 - val_accuracy: 0.5750\n",
            "Epoch 638/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.6986 - val_loss: 0.4221 - val_accuracy: 0.5875\n",
            "Epoch 639/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.6361 - val_loss: 0.4258 - val_accuracy: 0.6250\n",
            "Epoch 640/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.7306 - val_loss: 0.4255 - val_accuracy: 0.6250\n",
            "Epoch 641/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.7278 - val_loss: 0.4254 - val_accuracy: 0.6125\n",
            "Epoch 642/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.7264 - val_loss: 0.4226 - val_accuracy: 0.6000\n",
            "Epoch 643/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.7028 - val_loss: 0.4259 - val_accuracy: 0.6250\n",
            "Epoch 644/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.7306 - val_loss: 0.4217 - val_accuracy: 0.5875\n",
            "Epoch 645/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.6431 - val_loss: 0.4304 - val_accuracy: 0.6625\n",
            "Epoch 646/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.7444 - val_loss: 0.4290 - val_accuracy: 0.6625\n",
            "Epoch 647/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.7431 - val_loss: 0.4236 - val_accuracy: 0.6000\n",
            "Epoch 648/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.7319 - val_loss: 0.4188 - val_accuracy: 0.4875\n",
            "Epoch 649/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.5931 - val_loss: 0.4235 - val_accuracy: 0.6000\n",
            "Epoch 650/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.7028 - val_loss: 0.4249 - val_accuracy: 0.6125\n",
            "Epoch 651/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.7111 - val_loss: 0.4245 - val_accuracy: 0.6125\n",
            "Epoch 652/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.7194 - val_loss: 0.4211 - val_accuracy: 0.5875\n",
            "Epoch 653/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.6694 - val_loss: 0.4229 - val_accuracy: 0.6000\n",
            "Epoch 654/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.6917 - val_loss: 0.4229 - val_accuracy: 0.6000\n",
            "Epoch 655/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.7264 - val_loss: 0.4165 - val_accuracy: 0.6750\n",
            "Epoch 656/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.6389 - val_loss: 0.4202 - val_accuracy: 0.5375\n",
            "Epoch 657/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.6833 - val_loss: 0.4239 - val_accuracy: 0.6000\n",
            "Epoch 658/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.7042 - val_loss: 0.4262 - val_accuracy: 0.6625\n",
            "Epoch 659/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.7250 - val_loss: 0.4235 - val_accuracy: 0.6000\n",
            "Epoch 660/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.7042 - val_loss: 0.4232 - val_accuracy: 0.6000\n",
            "Epoch 661/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.6917 - val_loss: 0.4233 - val_accuracy: 0.6000\n",
            "Epoch 662/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.7153 - val_loss: 0.4267 - val_accuracy: 0.6625\n",
            "Epoch 663/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.7208 - val_loss: 0.4262 - val_accuracy: 0.6625\n",
            "Epoch 664/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.7319 - val_loss: 0.4294 - val_accuracy: 0.6625\n",
            "Epoch 665/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.7389 - val_loss: 0.4236 - val_accuracy: 0.6000\n",
            "Epoch 666/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.6917 - val_loss: 0.4248 - val_accuracy: 0.6250\n",
            "Epoch 667/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.7264 - val_loss: 0.4226 - val_accuracy: 0.6000\n",
            "Epoch 668/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.7139 - val_loss: 0.4297 - val_accuracy: 0.6625\n",
            "Epoch 669/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.7403 - val_loss: 0.4239 - val_accuracy: 0.6125\n",
            "Epoch 670/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.7069 - val_loss: 0.4253 - val_accuracy: 0.6500\n",
            "Epoch 671/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.7069 - val_loss: 0.4251 - val_accuracy: 0.6375\n",
            "Epoch 672/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.7181 - val_loss: 0.4296 - val_accuracy: 0.6625\n",
            "Epoch 673/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.7306 - val_loss: 0.4306 - val_accuracy: 0.6625\n",
            "Epoch 674/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.7458 - val_loss: 0.4261 - val_accuracy: 0.6625\n",
            "Epoch 675/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.7347 - val_loss: 0.4252 - val_accuracy: 0.6500\n",
            "Epoch 676/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.7181 - val_loss: 0.4293 - val_accuracy: 0.6625\n",
            "Epoch 677/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.7403 - val_loss: 0.4229 - val_accuracy: 0.6000\n",
            "Epoch 678/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.7236 - val_loss: 0.4237 - val_accuracy: 0.6125\n",
            "Epoch 679/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.7194 - val_loss: 0.4310 - val_accuracy: 0.6625\n",
            "Epoch 680/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.7361 - val_loss: 0.4295 - val_accuracy: 0.6625\n",
            "Epoch 681/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.7431 - val_loss: 0.4318 - val_accuracy: 0.6625\n",
            "Epoch 682/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.7417 - val_loss: 0.4270 - val_accuracy: 0.6625\n",
            "Epoch 683/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.7375 - val_loss: 0.4209 - val_accuracy: 0.6000\n",
            "Epoch 684/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.7111 - val_loss: 0.4233 - val_accuracy: 0.6125\n",
            "Epoch 685/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.7125 - val_loss: 0.4247 - val_accuracy: 0.6500\n",
            "Epoch 686/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.7264 - val_loss: 0.4274 - val_accuracy: 0.6625\n",
            "Epoch 687/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.7319 - val_loss: 0.4220 - val_accuracy: 0.6000\n",
            "Epoch 688/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.7167 - val_loss: 0.4248 - val_accuracy: 0.6625\n",
            "Epoch 689/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.7278 - val_loss: 0.4211 - val_accuracy: 0.6000\n",
            "Epoch 690/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.7167 - val_loss: 0.4196 - val_accuracy: 0.5750\n",
            "Epoch 691/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.7014 - val_loss: 0.4202 - val_accuracy: 0.5875\n",
            "Epoch 692/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.6653 - val_loss: 0.4269 - val_accuracy: 0.6625\n",
            "Epoch 693/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.7375 - val_loss: 0.4189 - val_accuracy: 0.5500\n",
            "Epoch 694/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.6778 - val_loss: 0.4195 - val_accuracy: 0.5875\n",
            "Epoch 695/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.6181 - val_loss: 0.4225 - val_accuracy: 0.6125\n",
            "Epoch 696/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.7292 - val_loss: 0.4230 - val_accuracy: 0.6250\n",
            "Epoch 697/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.7250 - val_loss: 0.4238 - val_accuracy: 0.6375\n",
            "Epoch 698/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.7417 - val_loss: 0.4229 - val_accuracy: 0.6250\n",
            "Epoch 699/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.7194 - val_loss: 0.4239 - val_accuracy: 0.6375\n",
            "Epoch 700/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.7236 - val_loss: 0.4225 - val_accuracy: 0.6125\n",
            "Epoch 701/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.7347 - val_loss: 0.4197 - val_accuracy: 0.5875\n",
            "Epoch 702/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.7083 - val_loss: 0.4186 - val_accuracy: 0.5500\n",
            "Epoch 703/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.6569 - val_loss: 0.4198 - val_accuracy: 0.6000\n",
            "Epoch 704/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.6653 - val_loss: 0.4187 - val_accuracy: 0.5500\n",
            "Epoch 705/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.6944 - val_loss: 0.4172 - val_accuracy: 0.5000\n",
            "Epoch 706/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.6958 - val_loss: 0.4151 - val_accuracy: 0.6125\n",
            "Epoch 707/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.5917 - val_loss: 0.4189 - val_accuracy: 0.5875\n",
            "Epoch 708/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.6972 - val_loss: 0.4233 - val_accuracy: 0.6375\n",
            "Epoch 709/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.7250 - val_loss: 0.4265 - val_accuracy: 0.6625\n",
            "Epoch 710/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.7403 - val_loss: 0.4228 - val_accuracy: 0.6375\n",
            "Epoch 711/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.7333 - val_loss: 0.4167 - val_accuracy: 0.4875\n",
            "Epoch 712/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.6278 - val_loss: 0.4203 - val_accuracy: 0.6000\n",
            "Epoch 713/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.7028 - val_loss: 0.4220 - val_accuracy: 0.6250\n",
            "Epoch 714/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.7347 - val_loss: 0.4204 - val_accuracy: 0.6000\n",
            "Epoch 715/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.7250 - val_loss: 0.4215 - val_accuracy: 0.6125\n",
            "Epoch 716/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.7014 - val_loss: 0.4266 - val_accuracy: 0.6625\n",
            "Epoch 717/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.7403 - val_loss: 0.4215 - val_accuracy: 0.6125\n",
            "Epoch 718/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.7292 - val_loss: 0.4162 - val_accuracy: 0.4750\n",
            "Epoch 719/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.6500 - val_loss: 0.4208 - val_accuracy: 0.6000\n",
            "Epoch 720/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.7181 - val_loss: 0.4218 - val_accuracy: 0.6250\n",
            "Epoch 721/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.7167 - val_loss: 0.4186 - val_accuracy: 0.5875\n",
            "Epoch 722/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.7167 - val_loss: 0.4180 - val_accuracy: 0.5750\n",
            "Epoch 723/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.6611 - val_loss: 0.4211 - val_accuracy: 0.6125\n",
            "Epoch 724/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.7264 - val_loss: 0.4185 - val_accuracy: 0.5875\n",
            "Epoch 725/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.7042 - val_loss: 0.4208 - val_accuracy: 0.6125\n",
            "Epoch 726/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.7264 - val_loss: 0.4175 - val_accuracy: 0.5500\n",
            "Epoch 727/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.6458 - val_loss: 0.4185 - val_accuracy: 0.5875\n",
            "Epoch 728/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.6833 - val_loss: 0.4151 - val_accuracy: 0.5375\n",
            "Epoch 729/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.6347 - val_loss: 0.4191 - val_accuracy: 0.6000\n",
            "Epoch 730/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.6917 - val_loss: 0.4219 - val_accuracy: 0.6375\n",
            "Epoch 731/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.7278 - val_loss: 0.4216 - val_accuracy: 0.6250\n",
            "Epoch 732/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.7069 - val_loss: 0.4223 - val_accuracy: 0.6375\n",
            "Epoch 733/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.7125 - val_loss: 0.4223 - val_accuracy: 0.6375\n",
            "Epoch 734/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.7250 - val_loss: 0.4226 - val_accuracy: 0.6625\n",
            "Epoch 735/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.7361 - val_loss: 0.4207 - val_accuracy: 0.6125\n",
            "Epoch 736/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.7083 - val_loss: 0.4219 - val_accuracy: 0.6375\n",
            "Epoch 737/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.7250 - val_loss: 0.4236 - val_accuracy: 0.6625\n",
            "Epoch 738/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.7250 - val_loss: 0.4237 - val_accuracy: 0.6625\n",
            "Epoch 739/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.7236 - val_loss: 0.4200 - val_accuracy: 0.6000\n",
            "Epoch 740/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.7111 - val_loss: 0.4237 - val_accuracy: 0.6625\n",
            "Epoch 741/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.7375 - val_loss: 0.4203 - val_accuracy: 0.6125\n",
            "Epoch 742/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.7181 - val_loss: 0.4221 - val_accuracy: 0.6500\n",
            "Epoch 743/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.7264 - val_loss: 0.4205 - val_accuracy: 0.6125\n",
            "Epoch 744/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.7208 - val_loss: 0.4238 - val_accuracy: 0.6625\n",
            "Epoch 745/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.7333 - val_loss: 0.4271 - val_accuracy: 0.6625\n",
            "Epoch 746/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.7153 - val_loss: 0.4312 - val_accuracy: 0.6625\n",
            "Epoch 747/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.7458 - val_loss: 0.4283 - val_accuracy: 0.6625\n",
            "Epoch 748/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.7458 - val_loss: 0.4185 - val_accuracy: 0.6000\n",
            "Epoch 749/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.7153 - val_loss: 0.4184 - val_accuracy: 0.6000\n",
            "Epoch 750/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.7000 - val_loss: 0.4220 - val_accuracy: 0.6625\n",
            "Epoch 751/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.7264 - val_loss: 0.4214 - val_accuracy: 0.6375\n",
            "Epoch 752/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.7278 - val_loss: 0.4243 - val_accuracy: 0.6625\n",
            "Epoch 753/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.7375 - val_loss: 0.4203 - val_accuracy: 0.6125\n",
            "Epoch 754/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.7292 - val_loss: 0.4162 - val_accuracy: 0.5000\n",
            "Epoch 755/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.6500 - val_loss: 0.4170 - val_accuracy: 0.5875\n",
            "Epoch 756/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.7028 - val_loss: 0.4164 - val_accuracy: 0.5500\n",
            "Epoch 757/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.6583 - val_loss: 0.4200 - val_accuracy: 0.6125\n",
            "Epoch 758/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.7028 - val_loss: 0.4182 - val_accuracy: 0.6000\n",
            "Epoch 759/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.7167 - val_loss: 0.4216 - val_accuracy: 0.6625\n",
            "Epoch 760/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.7347 - val_loss: 0.4196 - val_accuracy: 0.6125\n",
            "Epoch 761/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.7278 - val_loss: 0.4186 - val_accuracy: 0.6000\n",
            "Epoch 762/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.6819 - val_loss: 0.4234 - val_accuracy: 0.6625\n",
            "Epoch 763/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.7236 - val_loss: 0.4203 - val_accuracy: 0.6250\n",
            "Epoch 764/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.7306 - val_loss: 0.4202 - val_accuracy: 0.6250\n",
            "Epoch 765/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.7153 - val_loss: 0.4213 - val_accuracy: 0.6625\n",
            "Epoch 766/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.7375 - val_loss: 0.4211 - val_accuracy: 0.6500\n",
            "Epoch 767/800\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.7264 - val_loss: 0.4193 - val_accuracy: 0.6125\n",
            "Epoch 768/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.7236 - val_loss: 0.4173 - val_accuracy: 0.6000\n",
            "Epoch 769/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.7000 - val_loss: 0.4210 - val_accuracy: 0.6500\n",
            "Epoch 770/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.7181 - val_loss: 0.4205 - val_accuracy: 0.6375\n",
            "Epoch 771/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.7083 - val_loss: 0.4226 - val_accuracy: 0.6625\n",
            "Epoch 772/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.7208 - val_loss: 0.4235 - val_accuracy: 0.6625\n",
            "Epoch 773/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.7319 - val_loss: 0.4239 - val_accuracy: 0.6625\n",
            "Epoch 774/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.7361 - val_loss: 0.4202 - val_accuracy: 0.6375\n",
            "Epoch 775/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.7347 - val_loss: 0.4189 - val_accuracy: 0.6000\n",
            "Epoch 776/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.7236 - val_loss: 0.4201 - val_accuracy: 0.6375\n",
            "Epoch 777/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.7236 - val_loss: 0.4225 - val_accuracy: 0.6625\n",
            "Epoch 778/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.7431 - val_loss: 0.4184 - val_accuracy: 0.6000\n",
            "Epoch 779/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.7278 - val_loss: 0.4173 - val_accuracy: 0.6000\n",
            "Epoch 780/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.7153 - val_loss: 0.4176 - val_accuracy: 0.6000\n",
            "Epoch 781/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.7042 - val_loss: 0.4174 - val_accuracy: 0.6000\n",
            "Epoch 782/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.7042 - val_loss: 0.4177 - val_accuracy: 0.6000\n",
            "Epoch 783/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.7111 - val_loss: 0.4213 - val_accuracy: 0.6625\n",
            "Epoch 784/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.7278 - val_loss: 0.4191 - val_accuracy: 0.6125\n",
            "Epoch 785/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.7139 - val_loss: 0.4203 - val_accuracy: 0.6375\n",
            "Epoch 786/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.7375 - val_loss: 0.4205 - val_accuracy: 0.6625\n",
            "Epoch 787/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.7347 - val_loss: 0.4211 - val_accuracy: 0.6625\n",
            "Epoch 788/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.7333 - val_loss: 0.4196 - val_accuracy: 0.6375\n",
            "Epoch 789/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.7194 - val_loss: 0.4195 - val_accuracy: 0.6250\n",
            "Epoch 790/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.7306 - val_loss: 0.4215 - val_accuracy: 0.6625\n",
            "Epoch 791/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.7236 - val_loss: 0.4197 - val_accuracy: 0.6375\n",
            "Epoch 792/800\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.7292 - val_loss: 0.4218 - val_accuracy: 0.6625\n",
            "Epoch 793/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.7458 - val_loss: 0.4239 - val_accuracy: 0.6625\n",
            "Epoch 794/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.7444 - val_loss: 0.4235 - val_accuracy: 0.6625\n",
            "Epoch 795/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.7417 - val_loss: 0.4214 - val_accuracy: 0.6625\n",
            "Epoch 796/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.7361 - val_loss: 0.4179 - val_accuracy: 0.6000\n",
            "Epoch 797/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.7319 - val_loss: 0.4147 - val_accuracy: 0.5000\n",
            "Epoch 798/800\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.6736 - val_loss: 0.4137 - val_accuracy: 0.4625\n",
            "Epoch 799/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.6306 - val_loss: 0.4219 - val_accuracy: 0.6625\n",
            "Epoch 800/800\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.7361 - val_loss: 0.4167 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36b0a81ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2-YIcXYc96V"
      },
      "source": [
        "## Reflection\n",
        "Write at least a paragraph answering these prompts: How did your own network perform? Is there any major differences between the implementations? Finally, reflecting on your experience implementing a learning algorithm for this assignment (Was it hard/easy/fun?, From which part did you learn the most?)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vhvnlAQcKsH"
      },
      "source": [
        "For all three of the models generated using my own network, I was able to yield a performance of above ~93-97% accuracy on the test set.  Of course, this was after fine tuning the number of nodes in the hidden layers, the number of epochs, and the learning rate.  In comparison to the standard library, the validation accuracies were consistent where the corresponding standard library implementations, which also yielded accuracies around ~90-94%.  The minor differences could be attributed to the fact that the standard library uses a different loss function (*sparse_categorical_crossentropy*), an optimizer, and potentially a different batch size.  Initially, I was using the RELU activation function for my standard library implementations and found larger discrepancies switching to the tanh activation function.  Overall, I found implementing the learning algorithm for this assignment valuable, and learned the most from implementing the fit() and predict() functions as they helped me understand the reasoning behind the dimensions for the matrices involved(ex. Z1, A1, B1, etc.).  I also found tuning the hyperparameters interesting because by doing so, I was able to visualize the relationship between epochs and learning rate and saw that a low learning late w/ large number of epochs generally yielded the best performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0vuIEBDAGGa"
      },
      "source": [
        "---\n",
        "# Get Help?\n",
        "In case you get stuck in any step in the process, you may find some useful information from:\n",
        "\n",
        " * Consult my [lecture 13](https://docs.google.com/presentation/d/1otQfmMomWctLZKI3hHKAA4lLkbXFtagLaQov8gNh4LI/edit?usp=sharing) and [Colab Notebook 10](https://colab.research.google.com/drive/1x5biI3dP5YvvDEI0wapJcSgQNnATDzNe)\n",
        " * Talk to the TA, they are available and there to help you during office hour.\n",
        " * Come talk to me or email me <nn4pj@virginia.edu> with subject starting \"CS4774 Assignment 4:...\".\n",
        "\n",
        "Part of the codes used in this assignment is modified from Konstantinos Kitsios under the 3-Clause BSD License. Best of luck and have fun!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH_mulWEAGGb"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}